---
authors:
- xtsong:
  name: "Xintong Song"
date: "2024-10-01T08:00:00Z"
subtitle: ""
title: Preview Release of Apache Flink 2.0
aliases:
- /news/2024/10/01/release-2.0-preview.html
---

The Apache Flink community is actively preparing Flink 2.0, the first major release since Flink 1.0 launched 8 years ago. As a significant milestone, Flink 2.0 is set to introduce numerous innovative features and improvements, along with some compabitiliby-breaking changes. To facilitate early adaption of these changes for our users and partner projects (e.g., connectors), and to offer a sneak peek into the exciting new features while gathering feedback, we are now providing a preview release of Flink 2.0.

**NOTICE:** Flink 2.0 Preview is not a stable release and should not be used in production environments. While this preview includes most of the breaking changes planned for Flink 2.0, the final release may still subject to additional modifications.

# Breaking Changes

## API

The following sets of APIs have been completely removed.
- **DataSet API.** Please migrate to [DataStream API](https://nightlies.apache.org/flink/flink-docs-master/docs/dev/datastream/overview/), or [Table API/SQL](https://nightlies.apache.org/flink/flink-docs-master/docs/dev/table/overview/) if applicable. See also [How to Migrate from DataSet to DataStream](https://nightlies.apache.org/flink/flink-docs-master/docs/dev/datastream/dataset_migration).
- **Scala DataStream and DataSet API.** Please migrate to the Java [DataStream API](https://nightlies.apache.org/flink/flink-docs-master/docs/dev/datastream/overview/).
- **SourceFuction, SinkFunction and Sink V1.** Please migrate to [Source](https://github.com/apache/flink/blob/master/flink-core/src/main/java/org/apache/flink/api/connector/source/Source.java) and [Sink V2](https://github.com/apache/flink/blob/master/flink-core/src/main/java/org/apache/flink/api/connector/sink2/Sink.java).
- **TableSoure and TableSink.** Please migrate to [DynamicTableSource](https://github.com/apache/flink/blob/master/flink-table/flink-table-common/src/main/java/org/apache/flink/table/connector/source/DynamicTableSource.java) and [DynamicTableSink](https://github.com/apache/flink/blob/master/flink-table/flink-table-common/src/main/java/org/apache/flink/table/connector/sink/DynamicTableSink.java). See also [User-defined Sources & Sinks](https://nightlies.apache.org/flink/flink-docs-master/docs/dev/table/sourcessinks/).
- **TableSchema, TableColumn and Types.** Please migrate to [Schema](https://github.com/apache/flink/blob/master/flink-table/flink-table-common/src/main/java/org/apache/flink/table/api/Schema.java), [Column](https://github.com/apache/flink/blob/master/flink-table/flink-table-common/src/main/java/org/apache/flink/table/catalog/Column.java) and [DataTypes](https://github.com/apache/flink/blob/master/flink-table/flink-table-common/src/main/java/org/apache/flink/table/api/DataTypes.java) respectively.

Some deprecated methods have been removed from **DataStream API**. See also the list of [removed programming APIs](#list-of-removed-programming-apis).

Some deprecated fields have been removed from **REST API**. See also the list of [removed REST APIs](#list-of-removed-rest-apis).

**NOTICE:** You may find some of the removed APIs still exist in the code base, usually in a different package. They are for internal usages only and can be changed / removed anytime without notifications. Please **DO NOT USE** them.

## Configuration

Configuration options meet the following criteria are removed. See also the list of [removed configuration options](#list-of-removed-configuration-options).
- Annotated as `@Public` and have been deprecated for at least 2 minor releases.
- Annotated as `@PublicEvolving` and have been deprecated for at least 1 minor releases.

The legacy configuration file `flink-conf.yaml` is no longer supported. Please use `config.yaml` with standard YAML format instead. A migration tool is provided to convert a legacy `flink-conf.yaml` into a new `config.yaml`. See [Migrate from flink-conf.yaml to config.yaml](https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/config/#migrate-from-flink-confyaml-to-configyaml) for more details.

Dedicated APIs for configuring specific options are removed from `StreamExecutionEnvironment` and `ExecutionConfig`. All options should now be set via `Configuration` and `ConfigOption`. See also the list of [removed programming APIs](#list-of-removed-programming-apis).

To avoid exposing internal interfaces, User-Defined Functions no longer have full access to `ExecutionConfig`. Instead, necessary functions such as `createSerializer()`, `getGlobalJobParameters()` and `isObjectReuseEnabled()` can now be accessed from `RuntimeContext` directly.

## Misc

**State Compatibility** is not guaranteed between 1.x and 2.x. 

**Java 8** is no longer supported. The minimum Java version supported by Flink now is Java 11.

**Per-Job Deployment Mode** is removed. Please use [Application Mode](https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/overview/#application-mode) instead.

**Legacy Mode of Hybrid Shuffle** is removed.

# Highlights of New Features

## Disaggregated State Storage and Management

The past decade has witnessed a dramatic shift in Flink's deployment mode, workload patterns, and hardware improvements. We've moved from the map-reduce era where workers are computation-storage tightly coupled nodes to a cloud-native world where containerized deployments on Kubernetes become standard. To enable Flink's Cloud-Native future, we introduce Disaggregated State Storage and Management that uses Distributed File Systems (DFS) as primary storage in Flink 2.0.

This new architecture solves the following challenges brought in the cloud-native era for Flink. 
1. Local Disk Constraints in containerization 
2. Spiky Resource Usage caused by compaction in the current state model 
3. Fast Rescaling for jobs with large states (hundreds of Terabytes) 
4. Light and Fast Checkpoint in a native way 

However, simply extending the state store to read/write from remote DFS is insufficient due to the existing blocking execution model in Flink. In Flink 2.0, we propose asynchronous execution model and introduce ForStDB, a disaggregated statebackend solution for this purpose.

In the preview version, we offer a complete end-to-end trial using Nexmark Q20 (SQL Filter Join). This includes: 
- Asynchronous execution: Full support for asynchronous state APIs and checkpointing. 
- Asynchronous SQL Join operator: Rewrite SQL Join operators to enable asynchronous join execution.
- Hybrid Async & Sync Execution: Hybrid SQL Plan + Runtime Execution + State Access
- Performance: Demonstrate performance results directly writing to DFS in async execution mode

## Materialized Table

In Flink 1.20, we introduced Materialized Table as a MVP feature. Materialized Table is an innovative table type in Flink SQL, designed to further streamlining batch and stream data processing while providing a unified developement experience. In the upcoming Flink 2.0 release, we are enhancing operational supports for Materialized Tables, including connector integration with cutting-edge lake formats and production-ready schedulers.

## Adaptive Batch Execution

In addition, Flink is countinuously enhancing its adaptive batch execution capabilities. The upcoming Flink 2.0 release will introduce dynamic optimization of logical plans, in addition to physical plans, based on insights gained from the execution of previous stages. The initial set of optimization strategies includes the dynamic application of broadcast joins and skewed joins.

## Streaming Lakehouse

Represented by the integration of Apache Flink and Apache Paimon, the Streaming Lakehouse architecture has extended the unified data storage, open format and cost-effectiveness of the Lakehouse paradigm to the real-time area. The upcoming Flink 2.0 release marks another significant step in enhancing the integration between Flink and Paimon. The Flink and Paimon communities are collaborating closely to adapt to each other's strengths and fully leverage their cutting-edge features, yielding various improvements including SQL plan optimization ultilizing Paimon's rich merge engines, enhanced bucket-aware lookup join performance, and Paimon support for Flink's Materialized Table, Adaptive Batch Execution and Speculative Execution.

# Appendix

## List of removed programming APIs

To be added.

## List of removed configuration options.

To be added.

## List of removed REST APIs

To be added.
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Apache Flink: Pravega Flink Connector 101</title>
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">

    <!-- Bootstrap -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">
    <link rel="stylesheet" href="/css/flink.css">
    <link rel="stylesheet" href="/css/syntax.css">

    <!-- Blog RSS feed -->
    <link href="/blog/feed.xml" rel="alternate" type="application/rss+xml" title="Apache Flink Blog: RSS feed" />

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <!-- We need to load Jquery in the header for custom google analytics event tracking-->
    <script src="/js/jquery.min.js"></script>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- Matomo -->
    <script>
      var _paq = window._paq = window._paq || [];
      /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
      /* We explicitly disable cookie tracking to avoid privacy issues */
      _paq.push(['disableCookies']);
      /* Measure a visit to flink.apache.org and nightlies.apache.org/flink as the same visit */
      _paq.push(["setDomains", ["*.flink.apache.org","*.nightlies.apache.org/flink"]]);
      _paq.push(['trackPageView']);
      _paq.push(['enableLinkTracking']);
      (function() {
        var u="//matomo.privacy.apache.org/";
        _paq.push(['setTrackerUrl', u+'matomo.php']);
        _paq.push(['setSiteId', '1']);
        var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
        g.async=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);
      })();
    </script>
    <!-- End Matomo Code -->
  </head>
  <body>  
    

    <!-- Main content. -->
    <div class="container">
    <div class="row">

      
     <div id="sidebar" class="col-sm-3">
        

<!-- Top navbar. -->
    <nav class="navbar navbar-default">
        <!-- The logo. -->
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <div class="navbar-logo">
            <a href="/">
              <img alt="Apache Flink" src="/img/flink-header-logo.svg" width="147px" height="73px">
            </a>
          </div>
        </div><!-- /.navbar-header -->

        <!-- The navigation links. -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
          <ul class="nav navbar-nav navbar-main">

            <!-- First menu section explains visitors what Flink is -->

            <!-- What is Stream Processing? -->
            <!--
            <li><a href="/streamprocessing1.html">What is Stream Processing?</a></li>
            -->

            <!-- What is Flink? -->
            <li><a href="/flink-architecture.html">What is Apache Flink?</a></li>

            

            <!-- Stateful Functions? -->

            <li><a href="https://nightlies.apache.org/flink/flink-statefun-docs-stable/">What is Stateful Functions?</a></li>

            <!-- Flink ML? -->

            <li><a href="https://nightlies.apache.org/flink/flink-ml-docs-stable/">What is Flink ML?</a></li>

            <!-- Use cases -->
            <li><a href="/usecases.html">Use Cases</a></li>

            <!-- Powered by -->
            <li><a href="/poweredby.html">Powered By</a></li>


            &nbsp;
            <!-- Second menu section aims to support Flink users -->

            <!-- Downloads -->
            <li><a href="/downloads.html">Downloads</a></li>

            <!-- Getting Started -->
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#">Getting Started<span class="caret"></span></a>
              <ul class="dropdown-menu">
                <li><a href="https://nightlies.apache.org/flink/flink-docs-release-1.14//docs/try-flink/local_installation/" target="_blank">With Flink <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-statefun-docs-release-3.2/getting-started/project-setup.html" target="_blank">With Flink Stateful Functions <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-ml-docs-release-2.0/try-flink-ml/quick-start.html" target="_blank">With Flink ML <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="/training.html">Training Course</a></li>
              </ul>
            </li>

            <!-- Documentation -->
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#">Documentation<span class="caret"></span></a>
              <ul class="dropdown-menu">
                <li><a href="https://nightlies.apache.org/flink/flink-docs-release-1.14" target="_blank">Flink 1.14 (Latest stable release) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-docs-master" target="_blank">Flink Master (Latest Snapshot) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-statefun-docs-release-3.2" target="_blank">Flink Stateful Functions 3.2 (Latest stable release) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-statefun-docs-master" target="_blank">Flink Stateful Functions Master (Latest Snapshot) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-ml-docs-release-2.0" target="_blank">Flink ML 2.0 (Latest stable release) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-ml-docs-master" target="_blank">Flink ML Master (Latest Snapshot) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
              </ul>
            </li>

            <!-- getting help -->
            <li><a href="/gettinghelp.html">Getting Help</a></li>

            <!-- Blog -->
            <li><a href="/blog/"><b>Flink Blog</b></a></li>


            <!-- Flink-packages -->
            <li>
              <a href="https://flink-packages.org" target="_blank">flink-packages.org <small><span class="glyphicon glyphicon-new-window"></span></small></a>
            </li>
            &nbsp;

            <!-- Third menu section aim to support community and contributors -->

            <!-- Community -->
            <li><a href="/community.html">Community &amp; Project Info</a></li>

            <!-- Roadmap -->
            <li><a href="/roadmap.html">Roadmap</a></li>

            <!-- Contribute -->
            <li><a href="/contributing/how-to-contribute.html">How to Contribute</a></li>
            

            <!-- GitHub -->
            <li>
              <a href="https://github.com/apache/flink" target="_blank">Flink on GitHub <small><span class="glyphicon glyphicon-new-window"></span></small></a>
            </li>

            &nbsp;

            <!-- Language Switcher -->
            <li>
              
                
                  <a href="/zh/2022/01/20/pravega-connector-101.html">中文版</a>
                
              
            </li>

          </ul>

          <style>
            .smalllinks:link {
              display: inline-block !important; background: none; padding-top: 0px; padding-bottom: 0px; padding-right: 0px; min-width: 75px;
            }
          </style>

          <ul class="nav navbar-nav navbar-bottom">
          <hr />

            <!-- Twitter -->
            <li><a href="https://twitter.com/apacheflink" target="_blank">@ApacheFlink <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

            <!-- Visualizer -->
            <li class=" hidden-md hidden-sm"><a href="/visualizer/" target="_blank">Plan Visualizer <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

            <li >
                  <a href="/security.html">Flink Security</a>
            </li>

          <hr />

            <li><a href="https://apache.org" target="_blank">Apache Software Foundation <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

            <li>

              <a class="smalllinks" href="https://www.apache.org/licenses/" target="_blank">License</a> <small><span class="glyphicon glyphicon-new-window"></span></small>

              <a class="smalllinks" href="https://www.apache.org/security/" target="_blank">Security</a> <small><span class="glyphicon glyphicon-new-window"></span></small>

              <a class="smalllinks" href="https://www.apache.org/foundation/sponsorship.html" target="_blank">Donate</a> <small><span class="glyphicon glyphicon-new-window"></span></small>

              <a class="smalllinks" href="https://www.apache.org/foundation/thanks.html" target="_blank">Thanks</a> <small><span class="glyphicon glyphicon-new-window"></span></small>
            </li>

          </ul>
        </div><!-- /.navbar-collapse -->
    </nav>

      </div>
      <div class="col-sm-9">
      <div class="row-fluid">
  <div class="col-sm-12">
    <div class="row">
      <h1>Pravega Flink Connector 101</h1>
      <p><i></i></p>

      <article>
        <p>20 Jan 2022 Yumin Zhou (Brian) (<a href="https://twitter.com/crazy__zhou">@crazy__zhou</a>)</p>

<p><a href="https://cncf.pravega.io/">Pravega</a>, which is now a CNCF sandbox project, is a cloud-native storage system based on abstractions for both batch and streaming data consumption. Pravega streams (a new storage abstraction) are durable, consistent, and elastic, while natively supporting long-term data retention. In comparison, <a href="https://flink.apache.org/">Apache Flink</a> is a popular real-time computing engine that provides unified batch and stream processing. Flink provides high-throughput, low-latency computation, as well as support for complex event processing and state management. Both Pravega and Flink share the same design philosophy and treat data streams as primitives. This makes them a great match when constructing storage+computing data pipelines which can unify batch and streaming use cases.</p>

<p>That’s also the main reason why Pravega has chosen to use Flink as the first integrated execution engine among the various distributed computing engines on the market. With the help of Flink, users can use flexible APIs for windowing, complex event processing (CEP), or table abstractions to process streaming data easily and enrich the data being stored. Since its inception in 2016, Pravega has established communication with Flink PMC members and developed the connector together.</p>

<p>In 2017, the Pravega Flink connector module started to move out of the Pravega main repository and has been maintained in a new separate <a href="https://github.com/pravega/flink-connectors">repository</a> since then. During years of development, many features have been implemented, including:</p>

<ul>
  <li>exactly-once processing guarantees for both Reader and Writer, supporting end-to-end exactly-once processing pipelines</li>
  <li>seamless integration with Flink’s checkpoints and savepoints</li>
  <li>parallel Readers and Writers supporting high throughput and low latency processing</li>
  <li>support for Batch, Streaming, and Table API to access Pravega Streams</li>
</ul>

<p>These key features make streaming pipeline applications easier to develop without worrying about performance and correctness which are the common pain points for many streaming use cases.</p>

<p>In this blog post, we will discuss how to use this connector to read and write Pravega streams with the Flink DataStream API.</p>

<div class="page-toc">
<ul id="markdown-toc">
  <li><a href="#basic-usages" id="markdown-toc-basic-usages">Basic usages</a>    <ul>
      <li><a href="#dependency" id="markdown-toc-dependency">Dependency</a></li>
      <li><a href="#api-introduction" id="markdown-toc-api-introduction">API introduction</a>        <ul>
          <li><a href="#configurations" id="markdown-toc-configurations">Configurations</a></li>
          <li><a href="#serializationdeserialization" id="markdown-toc-serializationdeserialization">Serialization/Deserialization</a></li>
          <li><a href="#flinkpravegareader" id="markdown-toc-flinkpravegareader"><code>FlinkPravegaReader</code></a></li>
          <li><a href="#flinkpravegawriter" id="markdown-toc-flinkpravegawriter"><code>FlinkPravegaWriter</code></a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#internals-of-reader-and-writer" id="markdown-toc-internals-of-reader-and-writer">Internals of reader and writer</a>    <ul>
      <li><a href="#checkpoint-integration" id="markdown-toc-checkpoint-integration">Checkpoint integration</a></li>
      <li><a href="#end-to-end-exactly-once-semantics" id="markdown-toc-end-to-end-exactly-once-semantics">End-to-end exactly-once semantics</a></li>
    </ul>
  </li>
  <li><a href="#summary" id="markdown-toc-summary">Summary</a></li>
  <li><a href="#future-plans" id="markdown-toc-future-plans">Future plans</a></li>
</ul>

</div>

<h1 id="basic-usages">Basic usages</h1>

<h2 id="dependency">Dependency</h2>
<p>To use this connector in your application, add the dependency to your project:</p>

<div class="highlight"><pre><code class="language-xml"><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>io.pravega<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>pravega-connectors-flink-1.13_2.12<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>0.10.1<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span></code></pre></div>

<p>In the above example,</p>

<p><code>1.13</code> is the Flink major version which is put in the middle of the artifact name. The Pravega Flink connector maintains compatibility for the <em>three</em> most recent major versions of Flink.</p>

<p><code>0.10.1</code> is the version that aligns with the Pravega version.</p>

<p>You can find the latest release with a support matrix on the <a href="https://github.com/pravega/flink-connectors/releases">GitHub Releases page</a>.</p>

<h2 id="api-introduction">API introduction</h2>

<h3 id="configurations">Configurations</h3>

<p>The connector provides a common top-level object <code>PravegaConfig</code> for Pravega connection configurations. The config object automatically configures itself from <em>environment variables</em>, <em>system properties</em> and <em>program arguments</em>.</p>

<p>The basic controller URI and the default scope can be set like this:</p>

<table>
  <thead>
    <tr>
      <th>Setting</th>
      <th>Environment Variable /<br />System Property /<br />Program Argument</th>
      <th>Default Value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Controller URI</td>
      <td><code>PRAVEGA_CONTROLLER_URI</code><br /><code>pravega.controller.uri</code><br /><code>--controller</code></td>
      <td><code>tcp://localhost:9090</code></td>
    </tr>
    <tr>
      <td>Default Scope</td>
      <td><code>PRAVEGA_SCOPE</code><br /><code>pravega.scope</code><br /><code>--scope</code></td>
      <td>-</td>
    </tr>
  </tbody>
</table>

<p>The recommended way to create an instance of <code>PravegaConfig</code> is the following:</p>

<div class="highlight"><pre><code class="language-java"><span class="c1">// From default environment</span>
<span class="n">PravegaConfig</span> <span class="n">config</span> <span class="o">=</span> <span class="n">PravegaConfig</span><span class="o">.</span><span class="na">fromDefaults</span><span class="o">();</span>

<span class="c1">// From program arguments</span>
<span class="n">ParameterTool</span> <span class="n">params</span> <span class="o">=</span> <span class="n">ParameterTool</span><span class="o">.</span><span class="na">fromArgs</span><span class="o">(</span><span class="n">args</span><span class="o">);</span>
<span class="n">PravegaConfig</span> <span class="n">config</span> <span class="o">=</span> <span class="n">PravegaConfig</span><span class="o">.</span><span class="na">fromParams</span><span class="o">(</span><span class="n">params</span><span class="o">);</span>

<span class="c1">// From user specification</span>
<span class="n">PravegaConfig</span> <span class="n">config</span> <span class="o">=</span> <span class="n">PravegaConfig</span><span class="o">.</span><span class="na">fromDefaults</span><span class="o">()</span>
    <span class="o">.</span><span class="na">withControllerURI</span><span class="o">(</span><span class="s">&quot;tcp://...&quot;</span><span class="o">)</span>
    <span class="o">.</span><span class="na">withDefaultScope</span><span class="o">(</span><span class="s">&quot;SCOPE-NAME&quot;</span><span class="o">)</span>
    <span class="o">.</span><span class="na">withCredentials</span><span class="o">(</span><span class="n">credentials</span><span class="o">)</span>
    <span class="o">.</span><span class="na">withHostnameValidation</span><span class="o">(</span><span class="kc">false</span><span class="o">);</span></code></pre></div>

<h3 id="serializationdeserialization">Serialization/Deserialization</h3>

<p>Pravega has defined <a href="http://pravega.io/docs/latest/javadoc/clients/io/pravega/client/stream/Serializer.html"><code>io.pravega.client.stream.Serializer</code></a> for the serialization/deserialization, while Flink has also defined standard interfaces for the purpose.</p>

<ul>
  <li><a href="https://ci.apache.org/projects/flink/flink-docs-stable/api/java/org/apache/flink/api/common/serialization/SerializationSchema.html"><code>org.apache.flink.api.common.serialization.SerializationSchema</code></a></li>
  <li><a href="https://ci.apache.org/projects/flink/flink-docs-stable/api/java/org/apache/flink/api/common/serialization/DeserializationSchema.html"><code>org.apache.flink.api.common.serialization.DeserializationSchema</code></a></li>
</ul>

<p>For interoperability with other pravega client applications, we have built-in adapters <code>PravegaSerializationSchema</code> and <code>PravegaDeserializationSchema</code> to support processing Pravega stream data produced by a non-Flink application.</p>

<p>Here is the adapter for Pravega Java serializer:</p>

<div class="highlight"><pre><code class="language-java"><span class="kn">import</span> <span class="nn">io.pravega.client.stream.impl.JavaSerializer</span><span class="o">;</span>
<span class="o">...</span>
<span class="n">DeserializationSchema</span><span class="o">&lt;</span><span class="n">MyEvent</span><span class="o">&gt;</span> <span class="n">adapter</span> <span class="o">=</span> <span class="k">new</span> <span class="n">PravegaDeserializationSchema</span><span class="o">&lt;&gt;(</span>
    <span class="n">MyEvent</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="k">new</span> <span class="n">JavaSerializer</span><span class="o">&lt;</span><span class="n">MyEvent</span><span class="o">&gt;());</span></code></pre></div>

<h3 id="flinkpravegareader"><code>FlinkPravegaReader</code></h3>

<p><code>FlinkPravegaReader</code> is a Flink <code>SourceFunction</code> implementation which supports parallel reads from one or more Pravega streams. Internally, it initiates a Pravega reader group and creates Pravega <code>EventStreamReader</code> instances to read the data from the stream(s). It provides a builder-style API to construct, and can allow streamcuts to mark the start and end of the read.</p>

<p>You can use it like this:</p>

<div class="highlight"><pre><code class="language-java"><span class="kd">final</span> <span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>

<span class="c1">// Enable Flink checkpoint to make state fault tolerant</span>
<span class="n">env</span><span class="o">.</span><span class="na">enableCheckpointing</span><span class="o">(</span><span class="mi">60000</span><span class="o">);</span>

<span class="c1">// Define the Pravega configuration</span>
<span class="n">ParameterTool</span> <span class="n">params</span> <span class="o">=</span> <span class="n">ParameterTool</span><span class="o">.</span><span class="na">fromArgs</span><span class="o">(</span><span class="n">args</span><span class="o">);</span>
<span class="n">PravegaConfig</span> <span class="n">config</span> <span class="o">=</span> <span class="n">PravegaConfig</span><span class="o">.</span><span class="na">fromParams</span><span class="o">(</span><span class="n">params</span><span class="o">);</span>

<span class="c1">// Define the event deserializer</span>
<span class="n">DeserializationSchema</span><span class="o">&lt;</span><span class="n">MyClass</span><span class="o">&gt;</span> <span class="n">deserializer</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// Define the data stream</span>
<span class="n">FlinkPravegaReader</span><span class="o">&lt;</span><span class="n">MyClass</span><span class="o">&gt;</span> <span class="n">pravegaSource</span> <span class="o">=</span> <span class="n">FlinkPravegaReader</span><span class="o">.&lt;</span><span class="n">MyClass</span><span class="o">&gt;</span><span class="n">builder</span><span class="o">()</span>
    <span class="o">.</span><span class="na">forStream</span><span class="o">(...)</span>
    <span class="o">.</span><span class="na">withPravegaConfig</span><span class="o">(</span><span class="n">config</span><span class="o">)</span>
    <span class="o">.</span><span class="na">withDeserializationSchema</span><span class="o">(</span><span class="n">deserializer</span><span class="o">)</span>
    <span class="o">.</span><span class="na">build</span><span class="o">();</span>
<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">MyClass</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">addSource</span><span class="o">(</span><span class="n">pravegaSource</span><span class="o">)</span>
    <span class="o">.</span><span class="na">setParallelism</span><span class="o">(</span><span class="mi">4</span><span class="o">)</span>
    <span class="o">.</span><span class="na">uid</span><span class="o">(</span><span class="s">&quot;pravega-source&quot;</span><span class="o">);</span></code></pre></div>

<h3 id="flinkpravegawriter"><code>FlinkPravegaWriter</code></h3>

<p><code>FlinkPravegaWriter</code> is a Flink <code>SinkFunction</code> implementation which supports parallel writes to Pravega streams.</p>

<p>It supports three writer modes that relate to guarantees about the persistence of events emitted by the sink to a Pravega Stream:</p>

<ol>
  <li><strong>Best-effort</strong> - Any write failures will be ignored and there could be data loss.</li>
  <li><strong>At-least-once</strong>(default) - All events are persisted in Pravega. Duplicate events are possible, due to retries or in case of failure and subsequent recovery.</li>
  <li><strong>Exactly-once</strong> - All events are persisted in Pravega using a transactional approach integrated with the Flink checkpointing feature.</li>
</ol>

<p>Internally, it will initiate several Pravega <code>EventStreamWriter</code> or <code>TransactionalEventStreamWriter</code> (depends on the writer mode) instances to write data to the stream. It provides a builder-style API to construct.</p>

<p>A basic usage looks like this:</p>

<div class="highlight"><pre><code class="language-java"><span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>

<span class="c1">// Define the Pravega configuration</span>
<span class="n">PravegaConfig</span> <span class="n">config</span> <span class="o">=</span> <span class="n">PravegaConfig</span><span class="o">.</span><span class="na">fromParams</span><span class="o">(</span><span class="n">params</span><span class="o">);</span>

<span class="c1">// Define the event serializer</span>
<span class="n">SerializationSchema</span><span class="o">&lt;</span><span class="n">MyClass</span><span class="o">&gt;</span> <span class="n">serializer</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// Define the event router for selecting the Routing Key</span>
<span class="n">PravegaEventRouter</span><span class="o">&lt;</span><span class="n">MyClass</span><span class="o">&gt;</span> <span class="n">router</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1">// Define the sink function</span>
<span class="n">FlinkPravegaWriter</span><span class="o">&lt;</span><span class="n">MyClass</span><span class="o">&gt;</span> <span class="n">pravegaSink</span> <span class="o">=</span> <span class="n">FlinkPravegaWriter</span><span class="o">.&lt;</span><span class="n">MyClass</span><span class="o">&gt;</span><span class="n">builder</span><span class="o">()</span>
   <span class="o">.</span><span class="na">forStream</span><span class="o">(...)</span>
   <span class="o">.</span><span class="na">withPravegaConfig</span><span class="o">(</span><span class="n">config</span><span class="o">)</span>
   <span class="o">.</span><span class="na">withSerializationSchema</span><span class="o">(</span><span class="n">serializer</span><span class="o">)</span>
   <span class="o">.</span><span class="na">withEventRouter</span><span class="o">(</span><span class="n">router</span><span class="o">)</span>
   <span class="o">.</span><span class="na">withWriterMode</span><span class="o">(</span><span class="n">EXACTLY_ONCE</span><span class="o">)</span>
   <span class="o">.</span><span class="na">build</span><span class="o">();</span>

<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">MyClass</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">stream</span><span class="o">.</span><span class="na">addSink</span><span class="o">(</span><span class="n">pravegaSink</span><span class="o">)</span>
    <span class="o">.</span><span class="na">setParallelism</span><span class="o">(</span><span class="mi">4</span><span class="o">)</span>
    <span class="o">.</span><span class="na">uid</span><span class="o">(</span><span class="s">&quot;pravega-sink&quot;</span><span class="o">);</span></code></pre></div>

<p>You can see some more examples <a href="https://github.com/pravega/pravega-samples">here</a>.</p>

<h1 id="internals-of-reader-and-writer">Internals of reader and writer</h1>

<h2 id="checkpoint-integration">Checkpoint integration</h2>

<p>Flink has periodic checkpoints based on the Chandy-Lamport algorithm to make state in Flink fault-tolerant. By allowing state and the corresponding stream positions to be recovered, the application is given the same semantics as a failure-free execution.</p>

<p>Pravega also has its own Checkpoint concept which is to create a consistent “point in time” persistence of the state of each Reader in the Reader Group, by using a specialized Event (<em>Checkpoint Event</em>) to signal each Reader to preserve its state. Once a Checkpoint has been completed, the application can use the Checkpoint to reset all the Readers in the Reader Group to the known consistent state represented by the Checkpoint.</p>

<p>This means that our end-to-end recovery story is not like other messaging systems such as Kafka, which uses a more coupled method and persists its offset in the Flink task state and lets Flink do the coordination. Flink delegates the Pravega source recovery completely to the Pravega server and uses only a lightweight hook to connect. We collaborated with the Flink community and added a new interface <code>ExternallyInducedSource</code> (<a href="https://issues.apache.org/jira/browse/FLINK-6390">FLINK-6390</a>) to allow such external calls for checkpointing. The connector integrated this interface to guarantee exactly-once semantics during a failure recovery.</p>

<p>The checkpoint mechanism works as a two-step process:</p>

<ul>
  <li>
    <p>The <a href="https://ci.apache.org/projects/flink/flink-docs-stable/api/java/org/apache/flink/runtime/checkpoint/MasterTriggerRestoreHook.html">master hook</a> handler from the JobManager initiates the <a href="https://ci.apache.org/projects/flink/flink-docs-stable/api/java/org/apache/flink/runtime/checkpoint/MasterTriggerRestoreHook.html#triggerCheckpoint-long-long-java.util.concurrent.Executor-"><code>triggerCheckpoint</code></a> request to the <code>ReaderCheckpointHook</code> that was registered with the JobManager during <code>FlinkPravegaReader</code> source initialization. The <code>ReaderCheckpointHook</code> handler notifies Pravega to checkpoint the current reader state. This is a non-blocking call that returns a <code>future</code> once Pravega readers are done with the checkpointing. Once the <code>future</code> completes, the Pravega checkpoint will be persisted in a “master state” of a Flink checkpoint.</p>
  </li>
  <li>
    <p>A <code>Checkpoint</code> event will be sent by Pravega as part of the data stream flow and, upon receiving the event, the <code>FlinkPravegaReader</code> will initiate a <a href="https://github.com/apache/flink/blob/master/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/checkpoint/ExternallyInducedSource.java#L73"><code>triggerCheckpoint</code></a> request to effectively let Flink continue and complete the checkpoint process.</p>
  </li>
</ul>

<h2 id="end-to-end-exactly-once-semantics">End-to-end exactly-once semantics</h2>

<p>In the early years of big data processing, results from real-time stream processing were always considered inaccurate/approximate/speculative. However, this correctness is extremely important for some use cases and in some industries such as finance.</p>

<p>This constraint stems mainly from two issues:</p>

<ul>
  <li>unordered data source in event time</li>
  <li>end-to-end exactly-once semantics guarantee</li>
</ul>

<p>During recent years of development, watermarking has been introduced as a tradeoff between correctness and latency, which is now considered a good solution for unordered data sources in event time.</p>

<p>The guarantee of end-to-end exactly-once semantics is more tricky. When we say “exactly-once semantics”, what we mean is that each incoming event affects the final results exactly once. Even in the event of a machine or software failure, there is no duplicate data and no data that goes unprocessed. This is quite difficult because of the demands of message acknowledgment and recovery during such fast processing and is also why some early distributed streaming engines like Storm(without Trident) chose to support “at-least-once” guarantees.</p>

<p>Flink is one of the first streaming systems that was able to provide exactly-once semantics due to its delicate <a href="https://www.ververica.com/blog/high-throughput-low-latency-and-exactly-once-stream-processing-with-apache-flink">checkpoint mechanism</a>. But to make it work end-to-end, the final stage needs to apply the semantic to external message system sinks that support commits and rollbacks.</p>

<p>To work around this problem, Pravega introduced <a href="https://cncf.pravega.io/docs/latest/transactions/">transactional writes</a>. A Pravega transaction allows an application to prepare a set of events that can be written “all at once” to a Stream. This allows an application to “commit” a bunch of events atomically. When writes are idempotent, it is possible to implement end-to-end exactly-once pipelines together with Flink.</p>

<p>To build such an end-to-end solution requires coordination between Flink and the Pravega sink, which is still challenging. A common approach for coordinating commits and rollbacks in a distributed system is the two-phase commit protocol. We used this protocol and, together with the Flink community, implemented the sink function in a two-phase commit way coordinated with Flink checkpoints.</p>

<p>The Flink community then extracted the common logic from the two-phase commit protocol and provided a general interface <code>TwoPhaseCommitSinkFunction</code> (<a href="https://issues.apache.org/jira/browse/FLINK-7210">FLINK-7210</a>) to make it possible to build end-to-end exactly-once applications with other message systems that have transaction support. This includes Apache Kafka versions 0.11 and above. There is an official Flink <a href="https://flink.apache.org/features/2018/03/01/end-to-end-exactly-once-apache-flink.html">blog post</a> that describes this feature in detail.</p>

<h1 id="summary">Summary</h1>
<p>The Pravega Flink connector enables Pravega to connect to Flink and allows Pravega to act as a key data store in a streaming pipeline. Both projects share a common design philosophy and can integrate well with each other. Pravega has its own concept of checkpointing and has implemented transactional writes to support end-to-end exactly-once guarantees.</p>

<h1 id="future-plans">Future plans</h1>

<p><code>FlinkPravegaInputFormat</code> and <code>FlinkPravegaOutputFormat</code> are now provided to support batch reads and writes in Flink, but these are under the legacy DataSet API. Since Flink is now making efforts to unify batch and streaming, it is improving its APIs and providing new interfaces for the <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-27%3A+Refactor+Source+Interface">source</a> and <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-143%3A+Unified+Sink+API">sink</a> APIs in the Flink 1.11 and 1.12 releases. We will continue to work with the Flink community and integrate with the new APIs.</p>

<p>We will also put more effort into SQL / Table API support in order to provide a better user experience since it is simpler to understand and even more powerful to use in some cases.</p>

<p><strong>Note:</strong> the original blog post can be found <a href="https://cncf.pravega.io/blog/2021/11/01/pravega-flink-connector-101/">here</a>.</p>

      </article>
    </div>

    <div class="row">
      <div id="disqus_thread"></div>
      <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'stratosphere-eu'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
             (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
      </script>
    </div>
  </div>
</div>
      </div>
    </div>

    <hr />

    <div class="row">
      <div class="footer text-center col-sm-12">
        <p>Copyright © 2014-2022 <a href="http://apache.org">The Apache Software Foundation</a>. All Rights Reserved.</p>
        <p>Apache Flink, Flink®, Apache®, the squirrel logo, and the Apache feather logo are either registered trademarks or trademarks of The Apache Software Foundation.</p>
        <p><a href="/privacy-policy.html">Privacy Policy</a> &middot; <a href="/blog/feed.xml">RSS feed</a></p>
      </div>
    </div>
    </div><!-- /.container -->

    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="/js/jquery.matchHeight-min.js"></script>
    <script src="/js/bootstrap.min.js"></script>
    <script src="/js/codetabs.js"></script>
    <script src="/js/stickysidebar.js"></script>
  </body>
</html>

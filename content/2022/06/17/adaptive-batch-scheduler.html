<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Apache Flink: Adaptive Batch Scheduler: Automatically Decide Parallelism of Flink Batch Jobs</title>
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">

    <!-- Bootstrap -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">
    <link rel="stylesheet" href="/css/flink.css">
    <link rel="stylesheet" href="/css/syntax.css">

    <!-- Blog RSS feed -->
    <link href="/blog/feed.xml" rel="alternate" type="application/rss+xml" title="Apache Flink Blog: RSS feed" />

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <!-- We need to load Jquery in the header for custom google analytics event tracking-->
    <script src="/js/jquery.min.js"></script>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- Matomo -->
    <script>
      var _paq = window._paq = window._paq || [];
      /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
      /* We explicitly disable cookie tracking to avoid privacy issues */
      _paq.push(['disableCookies']);
      /* Measure a visit to flink.apache.org and nightlies.apache.org/flink as the same visit */
      _paq.push(["setDomains", ["*.flink.apache.org","*.nightlies.apache.org/flink"]]);
      _paq.push(['trackPageView']);
      _paq.push(['enableLinkTracking']);
      (function() {
        var u="//matomo.privacy.apache.org/";
        _paq.push(['setTrackerUrl', u+'matomo.php']);
        _paq.push(['setSiteId', '1']);
        var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
        g.async=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);
      })();
    </script>
    <!-- End Matomo Code -->
  </head>
  <body>  
    

    <!-- Main content. -->
    <div class="container">
    <div class="row">

      
     <div id="sidebar" class="col-sm-3">
        

<!-- Top navbar. -->
    <nav class="navbar navbar-default">
        <!-- The logo. -->
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <div class="navbar-logo">
            <a href="/">
              <img alt="Apache Flink" src="/img/flink-header-logo.svg" width="147px" height="73px">
            </a>
          </div>
        </div><!-- /.navbar-header -->

        <!-- The navigation links. -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
          <ul class="nav navbar-nav navbar-main">

            <!-- First menu section explains visitors what Flink is -->

            <!-- What is Stream Processing? -->
            <!--
            <li><a href="/streamprocessing1.html">What is Stream Processing?</a></li>
            -->

            <!-- What is Flink? -->
            <li><a href="/flink-architecture.html">What is Apache Flink?</a></li>

            

            <!-- Stateful Functions? -->

            <li><a href="https://nightlies.apache.org/flink/flink-statefun-docs-stable/">What is Stateful Functions?</a></li>

            <!-- Flink ML? -->

            <li><a href="https://nightlies.apache.org/flink/flink-ml-docs-stable/">What is Flink ML?</a></li>

            <!-- Flink Kubernetes Operator? -->

            <li><a href="https://nightlies.apache.org/flink/flink-kubernetes-operator-docs-stable/">What is the Flink Kubernetes Operator?</a></li>

            <!-- Use cases -->
            <li><a href="/usecases.html">Use Cases</a></li>

            <!-- Powered by -->
            <li><a href="/poweredby.html">Powered By</a></li>


            &nbsp;
            <!-- Second menu section aims to support Flink users -->

            <!-- Downloads -->
            <li><a href="/downloads.html">Downloads</a></li>

            <!-- Getting Started -->
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#">Getting Started<span class="caret"></span></a>
              <ul class="dropdown-menu">
                <li><a href="https://nightlies.apache.org/flink/flink-docs-release-1.15//docs/try-flink/local_installation/" target="_blank">With Flink <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-statefun-docs-release-3.2/getting-started/project-setup.html" target="_blank">With Flink Stateful Functions <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-ml-docs-release-2.1/try-flink-ml/quick-start.html" target="_blank">With Flink ML <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-kubernetes-operator-docs-release-1.0/try-flink-kubernetes-operator/quick-start.html" target="_blank">With Flink Kubernetes Operator <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-table-store-docs-release-0.1/try-table-store/quick-start.html" target="_blank">With Flink Table Store <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="/training.html">Training Course</a></li>
              </ul>
            </li>

            <!-- Documentation -->
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#">Documentation<span class="caret"></span></a>
              <ul class="dropdown-menu">
                <li><a href="https://nightlies.apache.org/flink/flink-docs-release-1.15" target="_blank">Flink 1.15 (Latest stable release) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-docs-master" target="_blank">Flink Master (Latest Snapshot) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-statefun-docs-release-3.2" target="_blank">Flink Stateful Functions 3.2 (Latest stable release) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-statefun-docs-master" target="_blank">Flink Stateful Functions Master (Latest Snapshot) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-ml-docs-release-2.1" target="_blank">Flink ML 2.1 (Latest stable release) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-ml-docs-master" target="_blank">Flink ML Master (Latest Snapshot) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-kubernetes-operator-docs-release-1.0" target="_blank">Flink Kubernetes Operator 1.0 (Latest stable release) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-kubernetes-operator-docs-main" target="_blank">Flink Kubernetes Operator Main (Latest Snapshot) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-table-store-docs-release-0.1" target="_blank">Flink Table Store 0.1 (Latest stable release) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-table-store-docs-master" target="_blank">Flink Table Store Master (Latest Snapshot) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
              </ul>
            </li>

            <!-- getting help -->
            <li><a href="/gettinghelp.html">Getting Help</a></li>

            <!-- Blog -->
            <li><a href="/blog/"><b>Flink Blog</b></a></li>


            <!-- Flink-packages -->
            <li>
              <a href="https://flink-packages.org" target="_blank">flink-packages.org <small><span class="glyphicon glyphicon-new-window"></span></small></a>
            </li>
            &nbsp;

            <!-- Third menu section aim to support community and contributors -->

            <!-- Community -->
            <li><a href="/community.html">Community &amp; Project Info</a></li>

            <!-- Roadmap -->
            <li><a href="/roadmap.html">Roadmap</a></li>

            <!-- Contribute -->
            <li><a href="/contributing/how-to-contribute.html">How to Contribute</a></li>
            

            <!-- GitHub -->
            <li>
              <a href="https://github.com/apache/flink" target="_blank">Flink on GitHub <small><span class="glyphicon glyphicon-new-window"></span></small></a>
            </li>

            &nbsp;

            <!-- Language Switcher -->
            <li>
              
                
                  <a href="/zh/2022/06/17/adaptive-batch-scheduler.html">中文版</a>
                
              
            </li>

          </ul>

          <style>
            .smalllinks:link {
              display: inline-block !important; background: none; padding-top: 0px; padding-bottom: 0px; padding-right: 0px; min-width: 75px;
            }
          </style>

          <ul class="nav navbar-nav navbar-bottom">
          <hr />

            <!-- Twitter -->
            <li><a href="https://twitter.com/apacheflink" target="_blank">@ApacheFlink <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

            <!-- Visualizer -->
            <li class=" hidden-md hidden-sm"><a href="/visualizer/" target="_blank">Plan Visualizer <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

            <li >
                  <a href="/security.html">Flink Security</a>
            </li>

          <hr />

            <li><a href="https://apache.org" target="_blank">Apache Software Foundation <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

            <li>

              <a class="smalllinks" href="https://www.apache.org/licenses/" target="_blank">License</a> <small><span class="glyphicon glyphicon-new-window"></span></small>

              <a class="smalllinks" href="https://www.apache.org/security/" target="_blank">Security</a> <small><span class="glyphicon glyphicon-new-window"></span></small>

              <a class="smalllinks" href="https://www.apache.org/foundation/sponsorship.html" target="_blank">Donate</a> <small><span class="glyphicon glyphicon-new-window"></span></small>

              <a class="smalllinks" href="https://www.apache.org/foundation/thanks.html" target="_blank">Thanks</a> <small><span class="glyphicon glyphicon-new-window"></span></small>
            </li>

          </ul>
        </div><!-- /.navbar-collapse -->
    </nav>

      </div>
      <div class="col-sm-9">
      <div class="row-fluid">
  <div class="col-sm-12">
    <div class="row">
      <h1>Adaptive Batch Scheduler: Automatically Decide Parallelism of Flink Batch Jobs</h1>
      <p><i></i></p>

      <article>
        <p>17 Jun 2022 Lijie Wang  &amp; Zhu Zhu </p>

<div class="page-toc">
<ul id="markdown-toc">
  <li><a href="#introduction" id="markdown-toc-introduction">Introduction</a></li>
  <li><a href="#get-started" id="markdown-toc-get-started">Get Started</a>    <ul>
      <li><a href="#configure-to-use-adaptive-batch-scheduler" id="markdown-toc-configure-to-use-adaptive-batch-scheduler">Configure to use adaptive batch scheduler</a></li>
      <li><a href="#set-the-parallelism-of-operators-to--1" id="markdown-toc-set-the-parallelism-of-operators-to--1">Set the parallelism of operators to -1</a></li>
    </ul>
  </li>
  <li><a href="#implementation-details" id="markdown-toc-implementation-details">Implementation Details</a>    <ul>
      <li><a href="#collect-sizes-of-consumed-datasets" id="markdown-toc-collect-sizes-of-consumed-datasets">Collect sizes of consumed datasets</a></li>
      <li><a href="#decide-proper-parallelisms-of-job-vertices" id="markdown-toc-decide-proper-parallelisms-of-job-vertices">Decide proper parallelisms of job vertices</a>        <ul>
          <li><a href="#limit-the-maximum-ratio-of-broadcast-bytes" id="markdown-toc-limit-the-maximum-ratio-of-broadcast-bytes">Limit the maximum ratio of broadcast bytes</a></li>
          <li><a href="#normalize-the-parallelism-to-the-closest-power-of-2" id="markdown-toc-normalize-the-parallelism-to-the-closest-power-of-2">Normalize the parallelism to the closest power of 2</a></li>
        </ul>
      </li>
      <li><a href="#build-up-execution-graph-dynamically" id="markdown-toc-build-up-execution-graph-dynamically">Build up execution graph dynamically</a>        <ul>
          <li><a href="#create-execution-vertices-and-execution-edges-lazily" id="markdown-toc-create-execution-vertices-and-execution-edges-lazily">Create execution vertices and execution edges lazily</a></li>
          <li><a href="#flexible-subpartition-mapping" id="markdown-toc-flexible-subpartition-mapping">Flexible subpartition mapping</a></li>
        </ul>
      </li>
      <li><a href="#update-and-schedule-the-dynamic-execution-graph" id="markdown-toc-update-and-schedule-the-dynamic-execution-graph">Update and schedule the dynamic execution graph</a></li>
    </ul>
  </li>
  <li><a href="#future-improvement" id="markdown-toc-future-improvement">Future improvement</a>    <ul>
      <li><a href="#auto-rebalancing-of-workloads" id="markdown-toc-auto-rebalancing-of-workloads">Auto-rebalancing of workloads</a></li>
    </ul>
  </li>
</ul>

</div>

<h1 id="introduction">Introduction</h1>

<p>Deciding proper parallelisms of operators is not an easy work for many users. For batch jobs, a small parallelism may result in long execution time and big failover regression. While an unnecessary large parallelism may result in resource waste and more overhead cost in task deployment and network shuffling.</p>

<p>To decide a proper parallelism, one needs to know how much data each operator needs to process. However, It can be hard to predict data volume to be processed by a job because it can be different everyday. And it can be harder or even impossible (due to complex operators or UDFs) to predict data volume to be processed by each operator.</p>

<p>To solve this problem, we introduced the adaptive batch scheduler in Flink 1.15. The adaptive batch scheduler can automatically decide parallelism of an operator according to the size of its consumed datasets. Here are the benefits the adaptive batch scheduler can bring:</p>

<ol>
  <li>Batch job users can be relieved from parallelism tuning.</li>
  <li>Parallelism tuning is fine grained considering different operators. This is particularly beneficial for SQL jobs which can only be set with a global parallelism previously.</li>
  <li>Parallelism tuning can better fit consumed datasets which have a varying volume size every day.</li>
</ol>

<h1 id="get-started">Get Started</h1>

<p>To automatically decide parallelism of operators, you need to:</p>

<ol>
  <li>Configure to use adaptive batch scheduler.</li>
  <li>Set the parallelism of operators to -1.</li>
</ol>

<h2 id="configure-to-use-adaptive-batch-scheduler">Configure to use adaptive batch scheduler</h2>

<p>To use adaptive batch scheduler, you need to set configurations as below:</p>

<ul>
  <li>Set <code>jobmanager.scheduler: AdaptiveBatch</code>.</li>
  <li>Leave the <a href="https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/deployment/config/#execution-batch-shuffle-mode">execution.batch-shuffle-mode</a> unset or explicitly set it to <code>ALL-EXCHANGES-BLOCKING</code> (default value). Currently, the adaptive batch scheduler only supports batch jobs whose shuffle mode is <code>ALL-EXCHANGES-BLOCKING</code>.</li>
</ul>

<p>In addition, there are several related configuration options to control the upper bounds and lower bounds of tuned parallelisms, to specify expected data volume to process by each operator, and to specify the default parallelism of sources. More details can be found in the <a href="https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/deployment/elastic_scaling/#configure-to-use-adaptive-batch-scheduler">feature documentation page</a>.</p>

<h2 id="set-the-parallelism-of-operators-to--1">Set the parallelism of operators to -1</h2>

<p>The adaptive batch scheduler only automatically decides parallelism of operators whose parallelism is not set (which means the parallelism is -1). To leave parallelism unset, you should configure as follows:</p>

<ul>
  <li>Set <code>parallelism.default: -1</code> for all jobs.</li>
  <li>Set <code>table.exec.resource.default-parallelism: -1</code> for SQL jobs.</li>
  <li>Don’t call <code>setParallelism()</code> for operators in DataStream/DataSet jobs.</li>
  <li>Don’t call <code>setParallelism()</code> on <code>StreamExecutionEnvironment/ExecutionEnvironment</code> in DataStream/DataSet jobs.</li>
</ul>

<h1 id="implementation-details">Implementation Details</h1>

<p>In this section, we will elaborate the details of the implementation. Before that, we need to briefly introduce some concepts involved:</p>

<ul>
  <li><a href="https://github.com/apache/flink/blob/release-1.15/flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/JobVertex.java">JobVertex</a> and <a href="https://github.com/apache/flink/blob/release-1.15/flink-runtime/src/main/java/org/apache/flink/runtime/jobgraph/JobGraph.java">JobGraph</a>: A job vertex is an operator chain formed by chaining several operators together for better performance. The job graph is a data flow consisting of job vertices.</li>
  <li><a href="https://github.com/apache/flink/blob/release-1.15/flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionVertex.java">ExecutionVertex</a> and <a href="https://github.com/apache/flink/blob/release-1.15/flink-runtime/src/main/java/org/apache/flink/runtime/executiongraph/ExecutionGraph.java">ExecutionGraph</a>: An execution vertex represents a parallel subtask of a job vertex, which will eventually be instantiated as a physical task. For example, a job vertex with a parallelism of 100 will generate 100 execution vertices. The execution graph is the physical execution topology consisting of all execution vertices.</li>
</ul>

<p>More details about the above concepts can be found in the <a href="https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/internals/job_scheduling/#jobmanager-data-structures">Flink documentation</a>. Note that the adaptive batch scheduler decides the parallelism of operators by deciding the parallelism of the job vertices which consist of these operators. To automatically decide parallelism of job vertices, we introduced the following changes:</p>

<ol>
  <li>Enabled the scheduler to collect sizes of finished datasets.</li>
  <li>Introduced a new component <a href="https://github.com/apache/flink/blob/release-1.15/flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/adaptivebatch/VertexParallelismDecider.java">VertexParallelismDecider</a> to compute proper parallelisms of job vertices according to the sizes of their consumed results.</li>
  <li>Enabled to dynamically build up execution graph to allow the parallelisms of job vertices to be decided lazily. The execution graph starts with an empty execution topology and then gradually attaches the vertices during job execution.</li>
  <li>Introduced the adaptive batch scheduler to update and schedule the dynamic execution graph.</li>
</ol>

<p>The details will be introduced in the following sections.</p>

<center>
<br />
<img src="/img/blog/2022-06-17-adaptive-batch-scheduler/1-overall-structure.png" width="60%" />
<br />
Fig. 1 - The overall structure of automatically deciding parallelism
</center>

<p><br /></p>

<h2 id="collect-sizes-of-consumed-datasets">Collect sizes of consumed datasets</h2>

<p>The adaptive batch scheduler decides the parallelism of vertices by the size of input results, so the scheduler needs to know the sizes of result partitions produced by tasks. We introduced a numBytesProduced counter to record the size of each produced result partition, the accumulated result of the counter will be sent to the scheduler when tasks finish.</p>

<h2 id="decide-proper-parallelisms-of-job-vertices">Decide proper parallelisms of job vertices</h2>

<p>We introduced a new component <a href="https://github.com/apache/flink/blob/release-1.15/flink-runtime/src/main/java/org/apache/flink/runtime/scheduler/adaptivebatch/VertexParallelismDecider.java">VertexParallelismDecider</a> to compute proper parallelisms of job vertices according to the sizes of their consumed results. The computation algorithm is as follows:</p>

<p>Suppose</p>

<ul>
  <li><strong><em>V</em></strong> is the bytes of data the user expects to be processed by each task.</li>
  <li><strong><em>totalBytes<sub>non-broadcast</sub></em></strong> is the sum of the non-broadcast result sizes consumed by this job vertex.</li>
  <li><strong><em>totalBytes<sub>broadcast</sub></em></strong> is the sum of the broadcast result sizes consumed by this job vertex.</li>
  <li><strong><em>maxBroadcastRatio</em></strong> is the maximum ratio of broadcast bytes that affects the parallelism calculation.</li>
  <li><strong><em>normalize(</em></strong>x<strong><em>)</em></strong> is a function that round <strong><em>x</em></strong> to the closest power of 2.</li>
</ul>

<p>then the parallelism of this job vertex <strong><em>P</em></strong> will be:</p>
<center>
<img src="/img/blog/2022-06-17-adaptive-batch-scheduler/parallelism-formula.png" width="60%" />
</center>

<p>Note that we introduced two special treatment in the above formula :</p>

<ul>
  <li><a href="#limit-the-maximum-ratio-of-broadcast-bytes">Limit the maximum ratio of broadcast bytes</a></li>
  <li><a href="#normalize-the-parallelism-to-the-closest-power-of-2">Normalize the parallelism to the closest power of 2</a></li>
</ul>

<p>However, the above formula cannot be used to decide the parallelism of the source vertices, because the source vertices have no input. To solve it, we introduced the configuration option <code>jobmanager.adaptive-batch-scheduler.default-source-parallelism</code> to allow users to manually configure the parallelism of source vertices. Note that not all data sources need this option, because some data sources can automatically infer parallelism (For example, HiveTableSource, see <a href="https://github.com/apache/flink/blob/release-1.15/flink-connectors/flink-connector-hive/src/main/java/org/apache/flink/connectors/hive/HiveParallelismInference.java">HiveParallelismInference</a> for more detail). For these sources, it is recommended to decide parallelism by themselves.</p>

<h3 id="limit-the-maximum-ratio-of-broadcast-bytes">Limit the maximum ratio of broadcast bytes</h3>
<p>As you can see, we limit the maximum ratio of broadcast bytes that affects the parallelism calculation to <strong><em>maxBroadcastRatio</em></strong>. That is, the non-broadcast bytes processed by each task is at least <strong><em>(1-maxBroadcastRatio) * V</em></strong>. If not so，when the total broadcast bytes is close to <strong><em>V</em></strong>, even if the total non-broadcast bytes is very small, it may cause a large parallelism, which is unnecessary and may lead to resource waste and large task deployment overhead.</p>

<p>Generally, the broadcast dataset is usually relatively small against the other co-processed datasets, so we set the maximum ratio to 0.5 by default. The value is hard coded in the first version, and we may make it configurable later.</p>

<h3 id="normalize-the-parallelism-to-the-closest-power-of-2">Normalize the parallelism to the closest power of 2</h3>
<p>The normalize is to avoid introducing data skew. To better understand this section, we suggest you read the <a href="#flexible-subpartition-mapping">Flexible subpartition mapping</a> section first.</p>

<p>Taking Fig. 4 (b) as example, A1/A2 produces 4 subpartitions, and the decided parallelism of B is 3. In this case, B1 will consume 1 subpartition, B2 will consume 1 subpartition, and B3 will consume 2 subpartitions. We assume that subpartitions have the same amount of data, which means B3 will consume twice the data of other tasks, data skew is introduced due to the subpartition mapping.</p>

<p>To solve this problem, we need to make the subpartitions evenly consumed by downstream tasks, which means the number of subpartitions should be a multiple of the number of downstream tasks. For simplicity, we require the user-specified max parallelism to be 2<sup>N</sup>, and then adjust the calculated parallelism to a closest 2<sup>M</sup> (M &lt;= N), so that we can guarantee that subpartitions will be evenly consumed by downstream tasks.</p>

<p>Note that this is a temporary solution, the ultimate solution would be the <a href="#auto-rebalancing-of-workloads">Auto-rebalancing of workloads</a>, which may come soon.</p>

<h2 id="build-up-execution-graph-dynamically">Build up execution graph dynamically</h2>
<p>Before the adaptive batch scheduler was introduced to Flink, the execution graph was fully built in a static way before starting scheduling. To allow parallelisms of job vertices to be decided lazily, the execution graph must be able to be built up dynamically.</p>

<h3 id="create-execution-vertices-and-execution-edges-lazily">Create execution vertices and execution edges lazily</h3>
<p>A dynamic execution graph means that a Flink job starts with an empty execution topology, and then gradually attaches vertices during job execution, as shown in Fig. 2.</p>

<p>The execution topology consists of execution vertices and execution edges. The execution vertices will be created and attached to the execution topology only when:</p>

<ul>
  <li>The parallelism of the corresponding job vertex is decided.</li>
  <li>All upstream execution vertices are already attached.</li>
</ul>

<p>The parallelism of the job vertex needs to be decided first so that Flink knows how many execution vertices should be created. Upstream execution vertices need to be attached first so that Flink can connect the newly created execution vertices to the upstream vertices with execution edges.</p>

<center>
<br />
<img src="/img/blog/2022-06-17-adaptive-batch-scheduler/2-dynamic-graph.png" width="90%" />
<br />
Fig. 2 - Build up execution graph dynamically
</center>

<p><br /></p>

<h3 id="flexible-subpartition-mapping">Flexible subpartition mapping</h3>
<p>Before the adaptive batch scheduler was introduced to Flink, when deploying a task, Flink needed to know the parallelism of its consumer job vertex. This is because consumer vertex parallelism is used to decide the number of subpartitions produced by each upstream task. The reason behind that is, for one result partition, different subpartitions serve different consumer execution vertices. More specifically, one consumer execution vertex only consumes data from subpartition with the same index.</p>

<p>Taking Fig. 3 as example, parallelism of the consumer B is 2, so the result partition produced by A1/A2 should contain 2 subpartitions, the subpartition with index 0 serves B1, and the subpartition with index 1 serves B2.</p>

<center>
<br />
<img src="/img/blog/2022-06-17-adaptive-batch-scheduler/3-static-graph-subpartition-mapping.png" width="30%" />
<br />
Fig. 3 - How subpartitions serve consumer execution vertices with static execution graph
</center>

<p><br /></p>

<p>But obviously, this doesn’t work for dynamic graphs, because when a job vertex is deployed, the parallelism of its consumer job vertices may not have been decided yet. To enable Flink to work in this case, we need a way to allow a job vertex to run without knowing the parallelism of its consumer job vertices.</p>

<p>To achieve this goal, we can set the number of subpartitions to be the max parallelism of the consumer job vertex. Then when the consumer execution vertices are deployed, they should be assigned with a subpartition range to consume. Suppose N is the number of consumer execution vertices and P is the number of subpartitions. For the kth consumer execution vertex, the consumed subpartition range should be:</p>

<center>
<img src="/img/blog/2022-06-17-adaptive-batch-scheduler/range-formula.png" width="55%" />
</center>

<p>Taking Fig. 4 as example, the max parallelism of B is 4, so A1/A2 have 4 subpartitions. And then if the decided parallelism of B is 2, then the subpartitions mapping will be Fig. 4 (a), if the decided parallelism of B is 3, then the subpartitions mapping will be  Fig. 4 (b).</p>

<center>
<br />
<img src="/img/blog/2022-06-17-adaptive-batch-scheduler/4-dynamic-graph-subpartition-mapping.png" width="75%" />
<br />
Fig. 4 - How subpartitions serve consumer execution vertices with dynamic graph
</center>

<p><br /></p>

<h2 id="update-and-schedule-the-dynamic-execution-graph">Update and schedule the dynamic execution graph</h2>
<p>The adaptive batch scheduler scheduling is similar to the default scheduler, the only difference is that an empty dynamic execution graph will be generated initially and vertices will be attached later. Before handling any scheduling event, the scheduler will try deciding the parallelisms of job vertices, and then initialize them to generate execution vertices, connecting execution edges, and update the execution graph.</p>

<p>The scheduler will try to decide the parallelism of all job vertices before handling each scheduling event, and the parallelism decision will be made for each job vertex in topological order:</p>

<ul>
  <li>For source vertices, the parallelism should have been decided before starting scheduling.</li>
  <li>For non-source vertices, the parallelism can be decided only when all its consumed results are fully produced.</li>
</ul>

<p>After deciding the parallelism, the scheduler will try to initialize the job vertices in topological order. A job vertex that can be initialized should meet the following conditions:</p>

<ul>
  <li>The parallelism of the job vertex has been decided and the job vertex has not been initialized yet.</li>
  <li>All upstream job vertices have been initialized.</li>
</ul>

<h1 id="future-improvement">Future improvement</h1>

<h2 id="auto-rebalancing-of-workloads">Auto-rebalancing of workloads</h2>

<p>When running batch jobs, data skew may occur (a task needs to process much larger data than other tasks), which leads to long-tail tasks and further slows down the finish of jobs. Users usually hope that the system can automatically solve this problem. 
One typical data skew case is that some subpartitions have a significantly larger amount of data than others. This case can be solved by finer grained subpartitions and auto-rebalancing of workload. The work of the adaptive batch scheduler can be considered as the first step towards it, because the requirements of auto-rebalancing are similar to adaptive batch scheduler, they both need the support of dynamic graphs and the collection of result partitions size.
Based on the implementation of adaptive batch scheduler, we can solve the above problem by increasing max parallelism (for finer grained subpartitions) and simply changing the subpartition range division algorithm (for auto-rebalancing). In the current design, the subpartition range is divided according to the number of subpartitions, we can change it to divide according to the amount of data in subpartitions, so that the amount of data within each subpartition range can be approximately the same. In this way, workloads of downstream tasks can be balanced.</p>

<center>
<br />
<img src="/img/blog/2022-06-17-adaptive-batch-scheduler/5-auto-rebalance.png" width="75%" />
<br />
Fig. 5 - Auto-rebalance with finer grained subpartitions
</center>

      </article>
    </div>

    <div class="row">
      <div id="disqus_thread"></div>
      <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'stratosphere-eu'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
             (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
      </script>
    </div>
  </div>
</div>
      </div>
    </div>

    <hr />

    <div class="row">
      <div class="footer text-center col-sm-12">
        <p>Copyright © 2014-2022 <a href="http://apache.org">The Apache Software Foundation</a>. All Rights Reserved.</p>
        <p>Apache Flink, Flink®, Apache®, the squirrel logo, and the Apache feather logo are either registered trademarks or trademarks of The Apache Software Foundation.</p>
        <p><a href="https://privacy.apache.org/policies/privacy-policy-public.html">Privacy Policy</a> &middot; <a href="/blog/feed.xml">RSS feed</a></p>
      </div>
    </div>
    </div><!-- /.container -->

    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="/js/jquery.matchHeight-min.js"></script>
    <script src="/js/bootstrap.min.js"></script>
    <script src="/js/codetabs.js"></script>
    <script src="/js/stickysidebar.js"></script>
  </body>
</html>

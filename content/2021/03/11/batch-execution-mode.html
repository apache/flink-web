<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Apache Flink: A Rundown of Batch Execution Mode in the DataStream API</title>
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">

    <!-- Bootstrap -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">
    <link rel="stylesheet" href="/css/flink.css">
    <link rel="stylesheet" href="/css/syntax.css">

    <!-- Blog RSS feed -->
    <link href="/blog/feed.xml" rel="alternate" type="application/rss+xml" title="Apache Flink Blog: RSS feed" />

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <!-- We need to load Jquery in the header for custom google analytics event tracking-->
    <script src="/js/jquery.min.js"></script>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- Matomo -->
    <script>
      var _paq = window._paq = window._paq || [];
      /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
      /* We explicitly disable cookie tracking to avoid privacy issues */
      _paq.push(['disableCookies']);
      /* Measure a visit to flink.apache.org and nightlies.apache.org/flink as the same visit */
      _paq.push(["setDomains", ["*.flink.apache.org","*.nightlies.apache.org/flink"]]);
      _paq.push(['trackPageView']);
      _paq.push(['enableLinkTracking']);
      (function() {
        var u="//matomo.privacy.apache.org/";
        _paq.push(['setTrackerUrl', u+'matomo.php']);
        _paq.push(['setSiteId', '1']);
        var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
        g.async=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);
      })();
    </script>
    <!-- End Matomo Code -->
  </head>
  <body>  
    

    <!-- Main content. -->
    <div class="container">
    <div class="row">

      
     <div id="sidebar" class="col-sm-3">
        

<!-- Top navbar. -->
    <nav class="navbar navbar-default">
        <!-- The logo. -->
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <div class="navbar-logo">
            <a href="/">
              <img alt="Apache Flink" src="/img/flink-header-logo.svg" width="147px" height="73px">
            </a>
          </div>
        </div><!-- /.navbar-header -->

        <!-- The navigation links. -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
          <ul class="nav navbar-nav navbar-main">

            <!-- First menu section explains visitors what Flink is -->

            <!-- What is Stream Processing? -->
            <!--
            <li><a href="/streamprocessing1.html">What is Stream Processing?</a></li>
            -->

            <!-- What is Flink? -->
            <li><a href="/flink-architecture.html">What is Apache Flink?</a></li>

            

            <!-- Stateful Functions? -->

            <li><a href="https://nightlies.apache.org/flink/flink-statefun-docs-stable/">What is Stateful Functions?</a></li>

            <!-- Flink ML? -->

            <li><a href="https://nightlies.apache.org/flink/flink-ml-docs-stable/">What is Flink ML?</a></li>

            <!-- Use cases -->
            <li><a href="/usecases.html">Use Cases</a></li>

            <!-- Powered by -->
            <li><a href="/poweredby.html">Powered By</a></li>


            &nbsp;
            <!-- Second menu section aims to support Flink users -->

            <!-- Downloads -->
            <li><a href="/downloads.html">Downloads</a></li>

            <!-- Getting Started -->
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#">Getting Started<span class="caret"></span></a>
              <ul class="dropdown-menu">
                <li><a href="https://nightlies.apache.org/flink/flink-docs-release-1.14//docs/try-flink/local_installation/" target="_blank">With Flink <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-statefun-docs-release-3.2/getting-started/project-setup.html" target="_blank">With Flink Stateful Functions <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-ml-docs-release-2.0/try-flink-ml/quick-start.html" target="_blank">With Flink ML <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-kubernetes-operator-docs-release-0.1/try-flink-kubernetes-operator/quick-start.html" target="_blank">With Flink Kubernetes Operator <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-table-store-docs-release-0.1/try-table-store/quick-start.html" target="_blank">With Flink Table Store <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="/training.html">Training Course</a></li>
              </ul>
            </li>

            <!-- Documentation -->
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#">Documentation<span class="caret"></span></a>
              <ul class="dropdown-menu">
                <li><a href="https://nightlies.apache.org/flink/flink-docs-release-1.14" target="_blank">Flink 1.15 (Latest stable release) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-docs-master" target="_blank">Flink Master (Latest Snapshot) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-statefun-docs-release-3.2" target="_blank">Flink Stateful Functions 3.2 (Latest stable release) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-statefun-docs-master" target="_blank">Flink Stateful Functions Master (Latest Snapshot) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-ml-docs-release-2.0" target="_blank">Flink ML 2.0 (Latest stable release) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-ml-docs-master" target="_blank">Flink ML Master (Latest Snapshot) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-kubernetes-operator-docs-release-0.1" target="_blank">Flink Kubernetes Operator 0.1 (Latest stable release) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-kubernetes-operator-docs-main" target="_blank">Flink Kubernetes Operator Main (Latest Snapshot) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-table-store-docs-release-0.1" target="_blank">Flink Table Store 0.1 (Latest stable release) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-table-store-docs-master" target="_blank">Flink Table Store Master (Latest Snapshot) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
              </ul>
            </li>

            <!-- getting help -->
            <li><a href="/gettinghelp.html">Getting Help</a></li>

            <!-- Blog -->
            <li><a href="/blog/"><b>Flink Blog</b></a></li>


            <!-- Flink-packages -->
            <li>
              <a href="https://flink-packages.org" target="_blank">flink-packages.org <small><span class="glyphicon glyphicon-new-window"></span></small></a>
            </li>
            &nbsp;

            <!-- Third menu section aim to support community and contributors -->

            <!-- Community -->
            <li><a href="/community.html">Community &amp; Project Info</a></li>

            <!-- Roadmap -->
            <li><a href="/roadmap.html">Roadmap</a></li>

            <!-- Contribute -->
            <li><a href="/contributing/how-to-contribute.html">How to Contribute</a></li>
            

            <!-- GitHub -->
            <li>
              <a href="https://github.com/apache/flink" target="_blank">Flink on GitHub <small><span class="glyphicon glyphicon-new-window"></span></small></a>
            </li>

            &nbsp;

            <!-- Language Switcher -->
            <li>
              
                
                  <a href="/zh/2021/03/11/batch-execution-mode.html">中文版</a>
                
              
            </li>

          </ul>

          <style>
            .smalllinks:link {
              display: inline-block !important; background: none; padding-top: 0px; padding-bottom: 0px; padding-right: 0px; min-width: 75px;
            }
          </style>

          <ul class="nav navbar-nav navbar-bottom">
          <hr />

            <!-- Twitter -->
            <li><a href="https://twitter.com/apacheflink" target="_blank">@ApacheFlink <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

            <!-- Visualizer -->
            <li class=" hidden-md hidden-sm"><a href="/visualizer/" target="_blank">Plan Visualizer <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

            <li >
                  <a href="/security.html">Flink Security</a>
            </li>

          <hr />

            <li><a href="https://apache.org" target="_blank">Apache Software Foundation <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

            <li>

              <a class="smalllinks" href="https://www.apache.org/licenses/" target="_blank">License</a> <small><span class="glyphicon glyphicon-new-window"></span></small>

              <a class="smalllinks" href="https://www.apache.org/security/" target="_blank">Security</a> <small><span class="glyphicon glyphicon-new-window"></span></small>

              <a class="smalllinks" href="https://www.apache.org/foundation/sponsorship.html" target="_blank">Donate</a> <small><span class="glyphicon glyphicon-new-window"></span></small>

              <a class="smalllinks" href="https://www.apache.org/foundation/thanks.html" target="_blank">Thanks</a> <small><span class="glyphicon glyphicon-new-window"></span></small>
            </li>

          </ul>
        </div><!-- /.navbar-collapse -->
    </nav>

      </div>
      <div class="col-sm-9">
      <div class="row-fluid">
  <div class="col-sm-12">
    <div class="row">
      <h1>A Rundown of Batch Execution Mode in the DataStream API</h1>
      <p><i></i></p>

      <article>
        <p>11 Mar 2021 Dawid Wysakowicz (<a href="https://twitter.com/dwysakowicz">@dwysakowicz</a>)</p>

<div class="page-toc">
<ul id="markdown-toc">
  <li><a href="#which-api-and-execution-mode-should-i-use" id="markdown-toc-which-api-and-execution-mode-should-i-use">Which API and execution mode should I use?</a></li>
  <li><a href="#how-to-use-the-batch-execution" id="markdown-toc-how-to-use-the-batch-execution">How to use the <em>batch</em> execution</a>    <ul>
      <li><a href="#hello-batch-mode" id="markdown-toc-hello-batch-mode">Hello <em>batch</em> mode</a></li>
      <li><a href="#example-two-input-operators" id="markdown-toc-example-two-input-operators">Example: Two input operators</a></li>
    </ul>
  </li>
  <li><a href="#looking-into-the-future" id="markdown-toc-looking-into-the-future">Looking into the future</a></li>
</ul>

</div>

<p>Flink has been following the mantra that <a href="https://flink.apache.org/news/2019/02/13/unified-batch-streaming-blink.html">Batch is a Special Case of Streaming</a> since the very early days. As the project evolved to address specific uses cases, different core APIs ended up being implemented for <em>batch</em> (DataSet API) and <em>streaming</em> execution (DataStream API), but the higher-level Table API/SQL was subsequently designed following this mantra of <em>unification</em>. With Flink 1.12, the community worked on bringing a similarly unified behaviour to the DataStream API, and took the first steps towards enabling efficient <a href="https://cwiki.apache.org/confluence/x/4i94CQ">batch execution in the DataStream API</a>.</p>

<p>The idea behind making the DataStream API a unified abstraction for <em>batch</em> and <em>streaming</em> execution instead of maintaining separate APIs is two-fold:</p>

<ul>
  <li>
    <p>Reusability: efficient batch and stream processing under the same API would allow you to easily switch between both execution modes without rewriting any code. So, a job could be easily reused to process real-time and historical data.</p>
  </li>
  <li>
    <p>Operational simplicity: providing a unified API would mean using a single set of connectors, maintaining a single codebase and being able to easily implement mixed execution pipelines e.g. for use cases like backfilling.</p>
  </li>
</ul>
<hr />

<p>The difference between BATCH and STREAMING vs BOUNDED and UNBOUNDED is subtle, and a common source of confusion — so, let’s start by clarifying that. These terms might seem mostly interchangeable, but in reality serve different purposes:</p>

<p><em>Bounded</em> and <em>unbounded</em> refer to the <strong>characteristics</strong> of the streams you want to process: whether or not they are known to have an end. The terms are also sometimes applied to the applications processing these streams: an application that only processes bounded streams is a <em>bounded</em> stream processing application that eventually finishes; while an <em>unbounded</em> stream processing application processes an unbounded stream and runs forever (or until canceled).</p>

<p><em>Batch</em> and <em>streaming</em> are <strong>execution modes</strong>. Batch execution is only applicable to bounded streams/applications because it exploits the fact that it can process the whole data (e.g. from a partition) in a batch rather than event-by-event, and possibly execute different batches one after the other. Continuous streaming execution runs everything at the same time, continuously processes (small groups of) events and is applicable to both bounded and unbounded applications.</p>

<p>Based on that differentiation, there are two main scenarios that result of the combination of these properties:
1. A <em>bounded</em> Stream Processing Application that is executed in a <em>batch</em> mode, which you can call a Batch (Processing) Application.
2. An <em>unbounded</em> Stream Processing Application that is executed in a <em>streaming</em> mode. This is the combination that has been the primary use case for the DataStream API in Flink.</p>

<p>It’s also possible to have a <em>bounded</em> Stream Processing Application that is executed in <em>streaming</em> mode, but this combination is less significant and likely to be used e.g. in a test environment or in other rare corner cases.</p>

<h2 id="which-api-and-execution-mode-should-i-use">Which API and execution mode should I use?</h2>

<p>Before going into the choice of execution mode, try looking at your use case from a different angle: do you need to process structured data? Does your data have a schema of some sort? The Table API/SQL will most likely be the right choice. In fact, the majority of <em>batch</em> use cases should be expressed with the <a href="https://nightlies.apache.org/flink/flink-docs-stable/dev/table/">Table API/SQL</a>! Finite, bounded data can most often be organized, described with a schema and put into a catalog. This is where the SQL API shines, giving you a rich set of functions and operators out-of-the box with low-level optimizations and broad connector support, all supported by standard SQL. And it works for <em>streaming</em> use cases, as well!</p>

<p>However, if you need explicit control over the execution graph, you want to manually control the state of your operations, or you need to be able to upgrade Flink (which applies to <em>unbounded</em> applications), the <a href="https://nightlies.apache.org/flink/flink-docs-stable/dev/datastream_api.html">DataStream API</a> is the right choice.
If the DataStream API sounds like the best fit for your use cases, the next decision is what execution mode to run your program in.</p>

<p><strong>When should you use the <em>batch</em> mode, then?</strong></p>

<p>The simple answer is if you run your computation on <em>bounded</em>, historic data. The <em>batch</em> mode has a few benefits:
1. In <em>bounded</em> data there is no such thing as late data. You do not need to think how to adjust the watermarking logic that you use in your application. In a streaming case, you need to maintain the order in which the records were written - which is often not possible to recreate when reading from e.g. historic files. In <em>batch</em> mode you don’t need to care about that as the data will be sorted according to the timestamp and “perfect” watermarks will be injected automatically.
2. The way streaming applications are scheduled and react upon failure have significant performance implications that can be optimized when dealing with <em>bounded</em> data. We recommend reading through the blogposts on <a href="https://flink.apache.org/2020/12/15/pipelined-region-sheduling.html">pipelined region scheduling</a> and <a href="https://flink.apache.org/news/2021/01/11/batch-fine-grained-fault-tolerance.html">fine-grained fault tolerance</a> to better understand these performance implications.
3. It can simplify the operational overhead of setting up and maintaining your pipelines. For example, there is no need to configure checkpointing, which otherwise requires things like choosing a state backend or setting up distributed storage for checkpoints.</p>

<h2 id="how-to-use-the-batch-execution">How to use the <em>batch</em> execution</h2>

<p>Once you have a good understanding of which execution mode is better suited to your use case, you can configure it via the <code>execution.runtime-mode</code> setting. There are three possible values:</p>

<ul>
  <li><code>STREAMING</code>: The classic DataStream execution mode (default)</li>
  <li><code>BATCH</code>: Batch-style execution on the DataStream API</li>
  <li><code>AUTOMATIC</code>: Let the system decide based on the boundedness of the sources</li>
</ul>

<p>This can be configured via command line parameters of <code>bin/flink run ...</code> when submitting a job:</p>

<div class="highlight"><pre><code class="language-bash"><span class="nv">$ </span>bin/flink run -Dexecution.runtime-mode<span class="o">=</span>BATCH examples/streaming/WordCount.jar</code></pre></div>

<p>, or programmatically when creating/configuring the <code>StreamExecutionEnvironment</code></p>

<p><code>java
StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
env.setRuntimeMode(RuntimeExecutionMode.BATCH);
</code></p>

<p>We recommend passing the execution mode when submitting the job, in order to keep your code configuration-free and potentially be able to execute the same application in different execution modes.</p>

<h3 id="hello-batch-mode">Hello <em>batch</em> mode</h3>

<p>Now that you know how to set the execution mode, let’s try to write a simple word count program and see how it behaves depending on the chosen mode. The program is a variation of a standard word count, where we count number of orders placed
in a given currency. We derive the number in 1-day windows. We read the input data from a new <a href="https://nightlies.apache.org/flink/flink-docs-release-1.12/api/java/org/apache/flink/connector/file/src/FileSource.html">unified file source</a> and then apply a <a href="https://nightlies.apache.org/flink/flink-docs-release-1.12/dev/stream/operators/windows.html#windows">window aggregation</a>. Notice that we will be checking the side output for late arriving data, which can illustrate how watermarks behave differently in the two execution modes.</p>

<div class="highlight"><pre><code class="language-java"><span class="kd">public</span> <span class="kd">class</span> <span class="nc">WindowWordCount</span> <span class="o">{</span>
	<span class="kd">private</span> <span class="kd">static</span> <span class="kd">final</span> <span class="n">OutputTag</span><span class="o">&lt;</span><span class="n">String</span><span class="o">[]&gt;</span> <span class="n">LATE_DATA</span> <span class="o">=</span> <span class="k">new</span> <span class="n">OutputTag</span><span class="o">&lt;&gt;(</span>
		<span class="s">&quot;late-data&quot;</span><span class="o">,</span>
		<span class="n">BasicArrayTypeInfo</span><span class="o">.</span><span class="na">STRING_ARRAY_TYPE_INFO</span><span class="o">);</span>

	<span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">Exception</span> <span class="o">{</span>

		<span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
		<span class="n">ParameterTool</span> <span class="n">config</span> <span class="o">=</span> <span class="n">ParameterTool</span><span class="o">.</span><span class="na">fromArgs</span><span class="o">(</span><span class="n">args</span><span class="o">);</span>

		<span class="n">Path</span> <span class="n">path</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">Path</span><span class="o">(</span><span class="n">config</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="s">&quot;path&quot;</span><span class="o">));</span>
		<span class="n">SingleOutputStreamOperator</span><span class="o">&lt;</span><span class="n">Tuple4</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">,</span> <span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;</span> <span class="n">dataStream</span> <span class="o">=</span> <span class="n">env</span>
			<span class="o">.</span><span class="na">fromSource</span><span class="o">(</span>
				<span class="n">FileSource</span><span class="o">.</span><span class="na">forRecordStreamFormat</span><span class="o">(</span><span class="k">new</span> <span class="nf">TsvFormat</span><span class="o">(),</span> <span class="n">path</span><span class="o">).</span><span class="na">build</span><span class="o">(),</span>
				<span class="n">WatermarkStrategy</span><span class="o">.&lt;</span><span class="n">String</span><span class="o">[]&gt;</span><span class="n">forBoundedOutOfOrderness</span><span class="o">(</span><span class="n">Duration</span><span class="o">.</span><span class="na">ofDays</span><span class="o">(</span><span class="mi">1</span><span class="o">))</span>
					<span class="o">.</span><span class="na">withTimestampAssigner</span><span class="o">(</span><span class="k">new</span> <span class="nf">OrderTimestampAssigner</span><span class="o">()),</span>
				<span class="s">&quot;Text file&quot;</span>
			<span class="o">)</span>
			<span class="o">.</span><span class="na">keyBy</span><span class="o">(</span><span class="n">value</span> <span class="o">-&gt;</span> <span class="n">value</span><span class="o">[</span><span class="mi">4</span><span class="o">])</span> <span class="c1">// group by currency</span>
			<span class="o">.</span><span class="na">window</span><span class="o">(</span><span class="n">TumblingEventTimeWindows</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">Time</span><span class="o">.</span><span class="na">days</span><span class="o">(</span><span class="mi">1</span><span class="o">)))</span>
			<span class="o">.</span><span class="na">sideOutputLateData</span><span class="o">(</span><span class="n">LATE_DATA</span><span class="o">)</span>
			<span class="o">.</span><span class="na">aggregate</span><span class="o">(</span>
				<span class="k">new</span> <span class="nf">CountFunction</span><span class="o">(),</span> <span class="c1">// count number of orders in a given currency</span>
				<span class="k">new</span> <span class="nf">CombineWindow</span><span class="o">());</span>

		<span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span>
		<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">String</span><span class="o">[]&gt;</span> <span class="n">lateData</span> <span class="o">=</span> <span class="n">dataStream</span><span class="o">.</span><span class="na">getSideOutput</span><span class="o">(</span><span class="n">LATE_DATA</span><span class="o">);</span>
		<span class="k">try</span> <span class="o">(</span><span class="n">CloseableIterator</span><span class="o">&lt;</span><span class="n">String</span><span class="o">[]&gt;</span> <span class="n">results</span> <span class="o">=</span> <span class="n">lateData</span><span class="o">.</span><span class="na">executeAndCollect</span><span class="o">())</span> <span class="o">{</span>
			<span class="k">while</span> <span class="o">(</span><span class="n">results</span><span class="o">.</span><span class="na">hasNext</span><span class="o">())</span> <span class="o">{</span>
				<span class="n">String</span><span class="o">[]</span> <span class="n">late</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="na">next</span><span class="o">();</span>
				<span class="k">if</span> <span class="o">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="mi">100</span><span class="o">)</span> <span class="o">{</span>
					<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">Arrays</span><span class="o">.</span><span class="na">toString</span><span class="o">(</span><span class="n">late</span><span class="o">));</span>
				<span class="o">}</span>
				<span class="n">i</span><span class="o">++;</span>
			<span class="o">}</span>
		<span class="o">}</span>
		<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&quot;Number of late records: &quot;</span> <span class="o">+</span> <span class="n">i</span><span class="o">);</span>

		<span class="k">try</span> <span class="o">(</span><span class="n">CloseableIterator</span><span class="o">&lt;</span><span class="n">Tuple4</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">Integer</span><span class="o">,</span> <span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;</span> <span class="n">results</span> 
				<span class="o">=</span> <span class="n">dataStream</span><span class="o">.</span><span class="na">executeAndCollect</span><span class="o">())</span> <span class="o">{</span>
			<span class="k">while</span> <span class="o">(</span><span class="n">results</span><span class="o">.</span><span class="na">hasNext</span><span class="o">())</span> <span class="o">{</span>
				<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">results</span><span class="o">.</span><span class="na">next</span><span class="o">());</span>
			<span class="o">}</span>
		<span class="o">}</span>
	<span class="o">}</span>
<span class="o">}</span></code></pre></div>

<p>If we simply execute the above program with:</p>

<div class="highlight"><pre><code class="language-bash"><span class="nv">$ </span>bin/flink run examples/streaming/WindowWordCount.jar</code></pre></div>

<p>it will be executed in a <em>streaming</em> mode by default. Because of that, it will use the given watermarking strategy and produce windows based on it. In real-time scenarios, it might happen that records do not adhere to watermarks and
some records might actually be considered late, so you’ll get results like:</p>

<div class="highlight"><pre><code>...
[1431681, 130936, F, 135996.21, NOK, 2020-04-11 07:53:02.674, 2-HIGH, Clerk#000000922, 0, quests. slyly regular platelets cajole ironic deposits: blithely even depos]
[1431744, 143957, F, 36391.24, CHF, 2020-04-11 07:53:27.631, 2-HIGH, Clerk#000000406, 0, eans. blithely special instructions are quickly. q]
[1431812, 58096, F, 55292.05, CAD, 2020-04-11 07:54:16.956, 2-HIGH, Clerk#000000561, 0, , regular packages use. slyly even instr]
[1431844, 77335, O, 415443.20, CAD, 2020-04-11 07:54:40.967, 2-HIGH, Clerk#000000446, 0, unts across the courts wake after the accounts! ruthlessly]
[1431968, 122005, F, 44964.19, JPY, 2020-04-11 07:55:42.661, 1-URGENT, Clerk#000000001, 0, nal theodolites against the slyly special packages poach blithely special req]
[1432097, 26035, F, 42464.15, CAD, 2020-04-11 07:57:13.423, 5-LOW, Clerk#000000213, 0, l accounts hang blithely. carefully blithe dependencies ]
[1432193, 97537, F, 87856.63, NOK, 2020-04-11 07:58:06.862, 4-NOT SPECIFIED, Clerk#000000356, 0, furiously furiously brave foxes. bo]
[1432291, 112045, O, 114327.52, JPY, 2020-04-11 07:59:12.912, 1-URGENT, Clerk#000000732, 0, ding to the fluffily ironic requests haggle carefully alongsid]
Number of late records: 1514
(GBP,374,2020-03-31T00:00:00Z,2020-04-01T00:00:00Z)
(HKD,401,2020-03-31T00:00:00Z,2020-04-01T00:00:00Z)
(CNY,402,2020-03-31T00:00:00Z,2020-04-01T00:00:00Z)
(CAD,392,2020-03-31T00:00:00Z,2020-04-01T00:00:00Z)
(JPY,411,2020-03-31T00:00:00Z,2020-04-01T00:00:00Z)
(CHF,371,2020-03-31T00:00:00Z,2020-04-01T00:00:00Z)
(NOK,370,2020-03-31T00:00:00Z,2020-04-01T00:00:00Z)
(RUB,365,2020-03-31T00:00:00Z,2020-04-01T00:00:00Z)
...
</code></pre></div>

<p>However, if you execute the exact same code using the <em>batch</em> execution mode:</p>

<div class="highlight"><pre><code class="language-bash"><span class="nv">$ </span>bin/flink run -Dexecution.runtime-mode<span class="o">=</span>BATCH examples/streaming/WordCount.jar</code></pre></div>

<p>you’ll see that there won’t be any late records.</p>

<div class="highlight"><pre><code>Number of late records: 0
(GBP,374,2020-03-31T00:00:00Z,2020-04-01T00:00:00Z)
(HKD,401,2020-03-31T00:00:00Z,2020-04-01T00:00:00Z)
(CNY,402,2020-03-31T00:00:00Z,2020-04-01T00:00:00Z)
(CAD,392,2020-03-31T00:00:00Z,2020-04-01T00:00:00Z)
(JPY,411,2020-03-31T00:00:00Z,2020-04-01T00:00:00Z)
(CHF,371,2020-03-31T00:00:00Z,2020-04-01T00:00:00Z)
(NOK,370,2020-03-31T00:00:00Z,2020-04-01T00:00:00Z)
(RUB,365,2020-03-31T00:00:00Z,2020-04-01T00:00:00Z)
</code></pre></div>

<p>Also, if you compare the execution timelines of both runs, you’ll see that the jobs were scheduled differently. In the case of <em>batch</em> execution, the two stages were executed one after the other:</p>

<p><a href="/img/blog/2021-03-11-batch-execution-mode/batch-execution.png"><img src="/img/blog/2021-03-11-batch-execution-mode/batch-execution.png" alt="" /></a></p>

<p>whereas for <em>streaming</em> both stages started at the same time.</p>

<p><a href="/img/blog/2021-03-11-batch-execution-mode/stream-execution.png"><img src="/img/blog/2021-03-11-batch-execution-mode/stream-execution.png" alt="" /></a></p>

<h3 id="example-two-input-operators">Example: Two input operators</h3>

<p>Operators that process data from multiple inputs can be executed in both execution modes as well. Let’s see how we may implement a join of two data sets on a common key. (Disclaimer: Make sure to think first if you <a href="#which-api-and-execution-mode-should-i-use">should use the Table API/SQL</a> for your join!). We will enrich a stream of orders with information about the customer and we will make it run either of the two modes.</p>

<p>For this particular use case, the DataStream API provides a <code>DataStream#join</code> method that requires a window in which the join must happen; since we’ll process the data in bulk, we can use a <code>GlobalWindow</code> (that would otherwise not be very useful on its own in an <em>unbounded</em> case due to state size concerns):</p>

<div class="highlight"><pre><code class="language-java"><span class="n">DataStreamSource</span><span class="o">&lt;</span><span class="n">String</span><span class="o">[]&gt;</span> <span class="n">orders</span> <span class="o">=</span> <span class="n">env</span>
    <span class="o">.</span><span class="na">fromSource</span><span class="o">(</span>
        <span class="n">FileSource</span><span class="o">.</span><span class="na">forRecordStreamFormat</span><span class="o">(</span><span class="k">new</span> <span class="nf">TsvFormat</span><span class="o">(),</span> <span class="n">ordersPath</span><span class="o">).</span><span class="na">build</span><span class="o">(),</span>
        <span class="n">WatermarkStrategy</span><span class="o">.&lt;</span><span class="n">String</span><span class="o">[]&gt;</span><span class="n">noWatermarks</span><span class="o">()</span>
            <span class="o">.</span><span class="na">withTimestampAssigner</span><span class="o">((</span><span class="n">record</span><span class="o">,</span> <span class="n">previous</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="o">-</span><span class="mi">1</span><span class="o">),</span>
        <span class="s">&quot;Text file&quot;</span>
    <span class="o">);</span>

<span class="n">Path</span> <span class="n">customersPath</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">Path</span><span class="o">(</span><span class="n">config</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="s">&quot;customers&quot;</span><span class="o">));</span>
<span class="n">DataStreamSource</span><span class="o">&lt;</span><span class="n">String</span><span class="o">[]&gt;</span> <span class="n">customers</span> <span class="o">=</span> <span class="n">env</span>
    <span class="o">.</span><span class="na">fromSource</span><span class="o">(</span>
        <span class="n">FileSource</span><span class="o">.</span><span class="na">forRecordStreamFormat</span><span class="o">(</span><span class="k">new</span> <span class="nf">TsvFormat</span><span class="o">(),</span> <span class="n">customersPath</span><span class="o">).</span><span class="na">build</span><span class="o">(),</span>
        <span class="n">WatermarkStrategy</span><span class="o">.&lt;</span><span class="n">String</span><span class="o">[]&gt;</span><span class="n">noWatermarks</span><span class="o">()</span>
            <span class="o">.</span><span class="na">withTimestampAssigner</span><span class="o">((</span><span class="n">record</span><span class="o">,</span> <span class="n">previous</span><span class="o">)</span> <span class="o">-&gt;</span> <span class="o">-</span><span class="mi">1</span><span class="o">),</span>
        <span class="s">&quot;Text file&quot;</span>
    <span class="o">);</span>

<span class="n">DataStream</span><span class="o">&lt;</span><span class="n">Tuple2</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;&gt;</span> <span class="n">dataStream</span> <span class="o">=</span> <span class="n">orders</span><span class="o">.</span><span class="na">join</span><span class="o">(</span><span class="n">customers</span><span class="o">)</span>
    <span class="o">.</span><span class="na">where</span><span class="o">(</span><span class="n">order</span> <span class="o">-&gt;</span> <span class="n">order</span><span class="o">[</span><span class="mi">1</span><span class="o">]).</span><span class="na">equalTo</span><span class="o">(</span><span class="n">customer</span> <span class="o">-&gt;</span> <span class="n">customer</span><span class="o">[</span><span class="mi">0</span><span class="o">])</span> <span class="c1">// join on customer id</span>
    <span class="o">.</span><span class="na">window</span><span class="o">(</span><span class="n">GlobalWindows</span><span class="o">.</span><span class="na">create</span><span class="o">())</span>
    <span class="o">.</span><span class="na">trigger</span><span class="o">(</span><span class="n">ContinuousProcessingTimeTrigger</span><span class="o">.</span><span class="na">of</span><span class="o">(</span><span class="n">Time</span><span class="o">.</span><span class="na">seconds</span><span class="o">(</span><span class="mi">5</span><span class="o">)))</span>
    <span class="o">.</span><span class="na">apply</span><span class="o">(</span><span class="k">new</span> <span class="nf">ProjectFunction</span><span class="o">());</span></code></pre></div>

<p>You might notice the <code>ContinuousProcessingTimeTrigger</code>. It is there for the application to produce results in a <em>streaming</em> mode. In a <em>streaming</em> application the <code>GlobalWindow</code> never finishes so we need to add a processing time trigger to emit results from time to time. We believe triggers are a way to control when to emit results, but are not part of the logic what to emit. Therefore we think it is safe to ignore those in case of <em>batch</em> mode and that’s what we do. In <em>batch</em> mode you will just get one final result for the join.</p>

<h2 id="looking-into-the-future">Looking into the future</h2>

<p>Support for efficient <em>batch</em> execution in the DataStream API was introduced in Flink 1.12 as a first step towards achieving a truly unified runtime for both batch and stream processing. This is not the end of the story yet! The community is still working on some optimizations and exploring more use cases that can be enabled with this new mode.</p>

<p>One of the first efforts we want to finalize is providing world-class support for transactional sinks in both execution modes, for <em>bounded</em> and <em>unbounded</em> streams. An experimental API for <a href="https://cwiki.apache.org/confluence/x/KEJ4CQ">transactional sinks</a> was already introduced in Flink 1.12, so we’re working on stabilizing it and would be happy to hear feedback about its current state!</p>

<p>We are also thinking how the two modes can be brought closer together and benefit from each other. A common pattern that we hear from users is bootstrapping state of a streaming job from a batch one. There are two somewhat different approaches we are considering here:</p>

<ol>
  <li>
    <p>Having a mixed graph, where one of the branches would have only bounded sources and the other would reflect the unbounded part — you can think of such a graph as effectively two separate jobs. The bounded part would be executed first and sink into the state of a common vertex of the two parts. This jobs’ purpose would be to populate the state of the common operator. Once that job is done, we could proceed to running the unbounded part.</p>
  </li>
  <li>
    <p>Another approach is to run the exact same program first on the <em>bounded</em> data. However, this time we wouldn’t assume completeness of the job; instead, we would produce the state of all operators up to a certain point in time and store it as a savepoint. Later on, we could use the savepoint to start the application on the <em>unbounded</em> data.</p>
  </li>
</ol>

<p>Lastly, to achieve feature parity with the DataSet API (Flink’s legacy API for batch-style execution), we are looking into the topic of iterations and how to meet the different usage patterns depending on the mode. In STREAMING mode, iterations serve as a loopback edge, but we don’t necessarily need to keep track of the iteration step. On the other hand, the iteration generation is vital for Machine Learning (ML) algorithms, which are the primary use case for iterations in BATCH mode.</p>

<p>Have you tried the new BATCH execution mode in the DataStream API? How was your experience? We are happy to hear your feedback and stories!</p>

      </article>
    </div>

    <div class="row">
      <div id="disqus_thread"></div>
      <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'stratosphere-eu'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
             (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
      </script>
    </div>
  </div>
</div>
      </div>
    </div>

    <hr />

    <div class="row">
      <div class="footer text-center col-sm-12">
        <p>Copyright © 2014-2022 <a href="http://apache.org">The Apache Software Foundation</a>. All Rights Reserved.</p>
        <p>Apache Flink, Flink®, Apache®, the squirrel logo, and the Apache feather logo are either registered trademarks or trademarks of The Apache Software Foundation.</p>
        <p><a href="https://privacy.apache.org/policies/privacy-policy-public.html">Privacy Policy</a> &middot; <a href="/blog/feed.xml">RSS feed</a></p>
      </div>
    </div>
    </div><!-- /.container -->

    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="/js/jquery.matchHeight-min.js"></script>
    <script src="/js/bootstrap.min.js"></script>
    <script src="/js/codetabs.js"></script>
    <script src="/js/stickysidebar.js"></script>
  </body>
</html>

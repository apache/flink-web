<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Apache Flink: Blog</title>
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">

    <!-- Bootstrap -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">
    <link rel="stylesheet" href="/css/flink.css">
    <link rel="stylesheet" href="/css/syntax.css">

    <!-- Blog RSS feed -->
    <link href="/blog/feed.xml" rel="alternate" type="application/rss+xml" title="Apache Flink Blog: RSS feed" />

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <!-- We need to load Jquery in the header for custom google analytics event tracking-->
    <script src="/js/jquery.min.js"></script>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>  
    

    <!-- Main content. -->
    <div class="container">
    <div class="row">

      
     <div id="sidebar" class="col-sm-3">
        

<!-- Top navbar. -->
    <nav class="navbar navbar-default">
        <!-- The logo. -->
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <div class="navbar-logo">
            <a href="/">
              <img alt="Apache Flink" src="/img/flink-header-logo.svg" width="147px" height="73px">
            </a>
          </div>
        </div><!-- /.navbar-header -->

        <!-- The navigation links. -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
          <ul class="nav navbar-nav navbar-main">

            <!-- First menu section explains visitors what Flink is -->

            <!-- What is Stream Processing? -->
            <!--
            <li><a href="/streamprocessing1.html">What is Stream Processing?</a></li>
            -->

            <!-- What is Flink? -->
            <li><a href="/flink-architecture.html">What is Apache Flink?</a></li>

            

            <!-- What is Stateful Functions? -->

            <li><a href="/stateful-functions.html">What is Stateful Functions?</a></li>

            <!-- Use cases -->
            <li><a href="/usecases.html">Use Cases</a></li>

            <!-- Powered by -->
            <li><a href="/poweredby.html">Powered By</a></li>


            &nbsp;
            <!-- Second menu section aims to support Flink users -->

            <!-- Downloads -->
            <li><a href="/downloads.html">Downloads</a></li>

            <!-- Getting Started -->
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#">Getting Started<span class="caret"></span></a>
              <ul class="dropdown-menu">
                <li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/try-flink/index.html" target="_blank">With Flink <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2/getting-started/project-setup.html" target="_blank">With Flink Stateful Functions <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="/training.html">Training Course</a></li>
              </ul>
            </li>

            <!-- Documentation -->
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#">Documentation<span class="caret"></span></a>
              <ul class="dropdown-menu">
                <li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12" target="_blank">Flink 1.12 (Latest stable release) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://ci.apache.org/projects/flink/flink-docs-master" target="_blank">Flink Master (Latest Snapshot) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2" target="_blank">Flink Stateful Functions 2.2 (Latest stable release) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://ci.apache.org/projects/flink/flink-statefun-docs-master" target="_blank">Flink Stateful Functions Master (Latest Snapshot) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
              </ul>
            </li>

            <!-- getting help -->
            <li><a href="/gettinghelp.html">Getting Help</a></li>

            <!-- Blog -->
            <li class="active"><a href="/blog/"><b>Flink Blog</b></a></li>


            <!-- Flink-packages -->
            <li>
              <a href="https://flink-packages.org" target="_blank">flink-packages.org <small><span class="glyphicon glyphicon-new-window"></span></small></a>
            </li>
            &nbsp;

            <!-- Third menu section aim to support community and contributors -->

            <!-- Community -->
            <li><a href="/community.html">Community &amp; Project Info</a></li>

            <!-- Roadmap -->
            <li><a href="/roadmap.html">Roadmap</a></li>

            <!-- Contribute -->
            <li><a href="/contributing/how-to-contribute.html">How to Contribute</a></li>
            

            <!-- GitHub -->
            <li>
              <a href="https://github.com/apache/flink" target="_blank">Flink on GitHub <small><span class="glyphicon glyphicon-new-window"></span></small></a>
            </li>

            &nbsp;

            <!-- Language Switcher -->
            <li>
              
                
                  <!-- link to the Chinese home page when current is blog page -->
                  <a href="/zh">中文版</a>
                
              
            </li>

          </ul>

          <style>
            .smalllinks:link {
              display: inline-block !important; background: none; padding-top: 0px; padding-bottom: 0px; padding-right: 0px; min-width: 75px;
            }
          </style>

          <ul class="nav navbar-nav navbar-bottom">
          <hr />

            <!-- Twitter -->
            <li><a href="https://twitter.com/apacheflink" target="_blank">@ApacheFlink <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

            <!-- Visualizer -->
            <li class=" hidden-md hidden-sm"><a href="/visualizer/" target="_blank">Plan Visualizer <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

            <li >
                  <a href="/security.html">Flink Security</a>
            </li>

          <hr />

            <li><a href="https://apache.org" target="_blank">Apache Software Foundation <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

            <li>

              <a class="smalllinks" href="https://www.apache.org/licenses/" target="_blank">License</a> <small><span class="glyphicon glyphicon-new-window"></span></small>

              <a class="smalllinks" href="https://www.apache.org/security/" target="_blank">Security</a> <small><span class="glyphicon glyphicon-new-window"></span></small>

              <a class="smalllinks" href="https://www.apache.org/foundation/sponsorship.html" target="_blank">Donate</a> <small><span class="glyphicon glyphicon-new-window"></span></small>

              <a class="smalllinks" href="https://www.apache.org/foundation/thanks.html" target="_blank">Thanks</a> <small><span class="glyphicon glyphicon-new-window"></span></small>
            </li>

          </ul>
        </div><!-- /.navbar-collapse -->
    </nav>

      </div>
      <div class="col-sm-9">
      <h1>Blog</h1>
<hr />

<div class="row">
  <div class="col-sm-8">
    <!-- Blog posts -->
    
    <article>
      <h2 class="blog-title"><a href="/news/2016/09/05/release-1.1.2.html">Apache Flink 1.1.2 Released</a></h2>

      <p>05 Sep 2016
      </p>

      <p><p>The Apache Flink community released another bugfix version of the Apache Flink 1.1. series.</p>

<p>We recommend all users to upgrade to Flink 1.1.2.</p>

<div class="highlight"><pre><code class="language-xml"><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-java<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.1.2<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-streaming-java_2.10<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.1.2<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-clients_2.10<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.1.2<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span></code></pre></div>

<p>You can find the binaries on the updated <a href="http://flink.apache.org/downloads.html">Downloads page</a>.</p>

<h2>Release Notes - Flink - Version 1.1.2</h2>

<ul>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-4236">FLINK-4236</a>] -         Flink Dashboard stops showing list of uploaded jars if main method cannot be looked up
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-4309">FLINK-4309</a>] -         Potential null pointer dereference in DelegatingConfiguration#keySet()
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-4334">FLINK-4334</a>] -         Shaded Hadoop1 jar not fully excluded in Quickstart
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-4341">FLINK-4341</a>] -         Kinesis connector does not emit maximum watermark properly
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-4402">FLINK-4402</a>] -         Wrong metrics parameter names in documentation 
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-4409">FLINK-4409</a>] -         class conflict between jsr305-1.3.9.jar and flink-shaded-hadoop2-1.1.1.jar
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-4411">FLINK-4411</a>] -         [py] Chained dual input children are not properly propagated
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-4412">FLINK-4412</a>] -         [py] Chaining does not properly handle broadcast variables
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-4425">FLINK-4425</a>] -         &quot;Out Of Memory&quot; during savepoint deserialization
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-4454">FLINK-4454</a>] -         Lookups for JobManager address in config
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-4480">FLINK-4480</a>] -         Incorrect link to elastic.co in documentation
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-4486">FLINK-4486</a>] -         JobManager not fully running when yarn-session.sh finishes
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-4488">FLINK-4488</a>] -         Prevent cluster shutdown after job execution for non-detached jobs
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-4514">FLINK-4514</a>] -         ExpiredIteratorException in Kinesis Consumer on long catch-ups to head of stream
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-4526">FLINK-4526</a>] -         ApplicationClient: remove redundant proxy messages
</li>

<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3866">FLINK-3866</a>] -         StringArraySerializer claims type is immutable; shouldn&#39;t
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3899">FLINK-3899</a>] -         Document window processing with Reduce/FoldFunction + WindowFunction
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-4302">FLINK-4302</a>] -         Add JavaDocs to MetricConfig
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-4495">FLINK-4495</a>] -         Running multiple jobs on yarn (without yarn-session)
</li>
</ul>

</p>

      <p><a href="/news/2016/09/05/release-1.1.2.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    
    <article>
      <h2 class="blog-title"><a href="/news/2016/08/24/ff16-keynotes-panels.html">Flink Forward 2016: Announcing Schedule, Keynotes, and Panel Discussion</a></h2>

      <p>24 Aug 2016
      </p>

      <p><p>An update for the Flink community: the <a href="http://flink-forward.org/kb_day/day-1/">Flink Forward 2016 schedule</a> is now available online. This year's event will include 2 days of talks from stream processing experts at Google, MapR, Alibaba, Netflix, Cloudera, and more. Following the talks is a full day of hands-on Flink training.</p>

<p>Ted Dunning has been announced as a keynote speaker at the event. Ted is the VP of Incubator at <a href="http://www.apache.org">Apache Software Foundation</a>, the Chief Application Architect at <a href="http://www.mapr.com">MapR Technologies</a>, and a mentor on many recent projects. He'll present <a href="http://flink-forward.org/kb_sessions/keynote-tba/">"How Can We Take Flink Forward?"</a> on the second day of the conference.</p>

<p>Following Ted's keynote there will be a panel discussion on <a href="http://flink-forward.org/kb_sessions/panel-large-scale-streaming-in-production/">"Large Scale Streaming in Production"</a>. As stream processing systems become more mainstream, companies are looking to empower their users to take advantage of this technology. We welcome leading stream processing experts Xiaowei Jiang <a href="http://www.alibaba.com">(Alibaba)</a>, Monal Daxini <a href="http://www.netflix.com">(Netflix)</a>, Maxim Fateev <a href="http://www.uber.com">(Uber)</a>, and Ted Dunning <a href="http://www.mapr.com">(MapR Technologies)</a> on stage to talk about the challenges they have faced and the solutions they have discovered while implementing stream processing systems at very large scale. The panel will be moderated by Jamie Grier <a href="http://www.data-artisans.com">(data Artisans)</a>.</p>

<p>The welcome keynote on Monday, September 12, will be presented by data Artisans' co-founders Kostas Tzoumas and Stephan Ewen. They will talk about <a href="http://flink-forward.org/kb_sessions/keynote-tba-2/">"The maturing data streaming ecosystem and Apache Flink’s accelerated growth"</a>. In this talk, Kostas and Stephan discuss several large-scale stream processing use cases that the data Artisans team has seen over the past year.</p>

<p>And one more recent addition to the program: Maxim Fateev of Uber will present <a href="http://flink-forward.org/kb_sessions/beyond-the-watermark-on-demand-backfilling-in-flink/">"Beyond the Watermark: On-Demand Backfilling in Flink"</a>. Flink’s time-progress model is built around a single watermark, which is incompatible with Uber’s business need for generating aggregates retroactively. Maxim's talk covers Uber's solution for on-demand backfilling.</p>

<p>We hope to see many community members at Flink Forward 2016. Registration is available online: <a href="http://flink-forward.org/registration/">flink-forward.org/registration</a>
</p>
</p>

      <p><a href="/news/2016/08/24/ff16-keynotes-panels.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    
    <article>
      <h2 class="blog-title"><a href="/news/2016/08/11/release-1.1.1.html">Flink 1.1.1 Released</a></h2>

      <p>11 Aug 2016
      </p>

      <p><p>Today, the Flink community released Flink version 1.1.1.</p>

<p>The Maven artifacts published on Maven central for 1.1.0 had a Hadoop dependency issue: No Hadoop 1 specific version (with version 1.1.0-hadoop1) was deployed and 1.1.0 artifacts have a dependency on Hadoop 1 instead of Hadoop 2.</p>

<p>This was fixed with this release and we <strong>highly recommend</strong> all users to use this version of Flink by bumping your Flink dependencies to version 1.1.1:</p>

<div class="highlight"><pre><code class="language-xml"><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-java<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.1.1<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-streaming-java_2.10<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.1.1<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-clients_2.10<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.1.1<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span></code></pre></div>

<p>You can find the binaries on the updated <a href="http://flink.apache.org/downloads.html">Downloads page</a>.</p>
</p>

      <p><a href="/news/2016/08/11/release-1.1.1.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    
    <article>
      <h2 class="blog-title"><a href="/news/2016/08/08/release-1.1.0.html">Announcing Apache Flink 1.1.0</a></h2>

      <p>08 Aug 2016
      </p>

      <p><div class="alert alert-success"><strong>Important</strong>: The Maven artifacts published with version 1.1.0 on Maven central have a Hadoop dependency issue. It is highly recommended to use <strong>1.1.1</strong> or <strong>1.1.1-hadoop1</strong> as the Flink version.</div>

<p>The Apache Flink community is pleased to announce the availability of Flink 1.1.0.</p>

<p>This release is the first major release in the 1.X.X series of releases, which maintains API compatibility with 1.0.0. This means that your applications written against stable APIs of Flink 1.0.0 will compile and run with Flink 1.1.0. 95 contributors provided bug fixes, improvements, and new features such that in total more than 450 JIRA issues could be resolved. See the <a href="/blog/release_1.1.0-changelog.html">complete changelog</a> for more details.</p>

<p><strong>We encourage everyone to <a href="http://flink.apache.org/downloads.html">download the release</a> and <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.1/">check out the documentation</a>. Feedback through the Flink <a href="http://flink.apache.org/community.html#mailing-lists">mailing lists</a> is, as always, very welcome!</strong></p>

<p>Some highlights of the release are listed in the following sections.</p>

<h2 id="connectors">Connectors</h2>

<p>The <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.1/apis/streaming/connectors/index.html">streaming connectors</a> are a major part of Flink’s DataStream API. This release adds support for new external systems and further improves on the available connectors.</p>

<h3 id="continuous-file-system-sources">Continuous File System Sources</h3>

<p>A frequently requested feature for Flink 1.0 was to be able to monitor directories and process files continuously. Flink 1.1 now adds support for this via <code>FileProcessingMode</code>s:</p>

<div class="highlight"><pre><code class="language-java"><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">stream</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">readFile</span><span class="o">(</span>
  <span class="n">textInputFormat</span><span class="o">,</span>
  <span class="s">&quot;hdfs:///file-path&quot;</span><span class="o">,</span>
  <span class="n">FileProcessingMode</span><span class="o">.</span><span class="na">PROCESS_CONTINUOUSLY</span><span class="o">,</span>
  <span class="mi">5000</span><span class="o">,</span> <span class="c1">// monitoring interval (millis)</span>
  <span class="n">FilePathFilter</span><span class="o">.</span><span class="na">createDefaultFilter</span><span class="o">());</span> <span class="c1">// file path filter</span></code></pre></div>

<p>This will monitor <code>hdfs:///file-path</code> every <code>5000</code> milliseconds. Check out the <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.1/apis/streaming/index.html#data-sources">DataSource documentation for more details</a>.</p>

<h3 id="kinesis-source-and-sink">Kinesis Source and Sink</h3>

<p>Flink 1.1 adds a Kinesis connector for both consuming (<code>FlinkKinesisConsumer</code>) from and producing (<code>FlinkKinesisProduer</code>) to <a href="https://aws.amazon.com/kinesis/">Amazon Kinesis Streams</a>, which is a managed service purpose-built to make it easy to work with streaming data on AWS.</p>

<div class="highlight"><pre><code class="language-java"><span class="n">DataStream</span><span class="o">&lt;</span><span class="n">String</span><span class="o">&gt;</span> <span class="n">kinesis</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="na">addSource</span><span class="o">(</span>
  <span class="k">new</span> <span class="n">FlinkKinesisConsumer</span><span class="o">&lt;&gt;(</span><span class="s">&quot;stream-name&quot;</span><span class="o">,</span> <span class="n">schema</span><span class="o">,</span> <span class="n">config</span><span class="o">));</span></code></pre></div>

<p>Check out the <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.1/apis/streaming/connectors/kinesis.html">Kinesis connector documentation for more details</a>.</p>

<h3 id="cassandra-sink">Cassandra Sink</h3>

<p>The <a href="http://wiki.apache.org/cassandra/GettingStarted">Apache Cassandra</a> sink allows you to write from Flink to Cassandra. Flink can provide exactly-once guarantees if the query is idempotent, meaning it can be applied multiple times without changing the result.</p>

<div class="highlight"><pre><code class="language-java"><span class="n">CassandraSink</span><span class="o">.</span><span class="na">addSink</span><span class="o">(</span><span class="n">input</span><span class="o">)</span></code></pre></div>

<p>Check out the <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.1/apis/streaming/connectors/cassandra.html">Cassandra Sink documentation for more details</a>.</p>

<h2 id="table-api-and-sql">Table API and SQL</h2>

<p>The Table API is a SQL-like expression language for relational stream and batch processing that can be easily embedded in Flink’s DataSet and DataStream APIs (for both Java and Scala).</p>

<div class="highlight"><pre><code class="language-java"><span class="n">Table</span> <span class="n">custT</span> <span class="o">=</span> <span class="n">tableEnv</span>
  <span class="o">.</span><span class="na">toTable</span><span class="o">(</span><span class="n">custDs</span><span class="o">,</span> <span class="s">&quot;name, zipcode&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">where</span><span class="o">(</span><span class="s">&quot;zipcode = &#39;12345&#39;&quot;</span><span class="o">)</span>
  <span class="o">.</span><span class="na">select</span><span class="o">(</span><span class="s">&quot;name&quot;</span><span class="o">)</span></code></pre></div>

<p>An initial version of this API was already available in Flink 1.0. For Flink 1.1, the community put a lot of work into reworking the architecture of the Table API and integrating it with <a href="https://calcite.apache.org">Apache Calcite</a>.</p>

<p>In this first version, SQL (and Table API) queries on streams are limited to selection, filter, and union operators. Compared to Flink 1.0, the revised Table API supports many more scalar functions and is able to read tables from external sources and write them back to external sinks.</p>

<div class="highlight"><pre><code class="language-java"><span class="n">Table</span> <span class="n">result</span> <span class="o">=</span> <span class="n">tableEnv</span><span class="o">.</span><span class="na">sql</span><span class="o">(</span>
  <span class="s">&quot;SELECT STREAM product, amount FROM Orders WHERE product LIKE &#39;%Rubber%&#39;&quot;</span><span class="o">);</span></code></pre></div>
<p>A more detailed introduction can be found in the <a href="http://flink.apache.org/news/2016/05/24/stream-sql.html">Flink blog</a> and the <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.1/apis/table.html">Table API documentation</a>.</p>

<h2 id="datastream-api">DataStream API</h2>

<p>The DataStream API now exposes <strong>session windows</strong> and <strong>allowed lateness</strong> as first-class citizens.</p>

<h3 id="session-windows">Session Windows</h3>

<p>Session windows are ideal for cases where the window boundaries need to adjust to the incoming data. This enables you to have windows that start at individual points in time for each key and that end once there has been a <em>certain period of inactivity</em>. The configuration parameter is the session gap that specifies how long to wait for new data before considering a session as closed.</p>

<center>
<img src="/img/blog/session-windows.svg" style="height:400px" />
</center>

<div class="highlight"><pre><code class="language-java"><span class="n">input</span><span class="o">.</span><span class="na">keyBy</span><span class="o">(&lt;</span><span class="n">key</span> <span class="n">selector</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="na">window</span><span class="o">(</span><span class="n">EventTimeSessionWindows</span><span class="o">.</span><span class="na">withGap</span><span class="o">(</span><span class="n">Time</span><span class="o">.</span><span class="na">minutes</span><span class="o">(</span><span class="mi">10</span><span class="o">)))</span>
    <span class="o">.&lt;</span><span class="n">windowed</span> <span class="n">transformation</span><span class="o">&gt;(&lt;</span><span class="n">window</span> <span class="n">function</span><span class="o">&gt;);</span></code></pre></div>

<h3 id="support-for-late-elements">Support for Late Elements</h3>

<p>You can now specify how a windowed transformation should deal with late elements and how much lateness is allowed. The parameter for this is called <em>allowed lateness</em>. This specifies by how much time elements can be late.</p>

<div class="highlight"><pre><code class="language-java"><span class="n">input</span><span class="o">.</span><span class="na">keyBy</span><span class="o">(&lt;</span><span class="n">key</span> <span class="n">selector</span><span class="o">&gt;).</span><span class="na">window</span><span class="o">(&lt;</span><span class="n">window</span> <span class="n">assigner</span><span class="o">&gt;)</span>
    <span class="o">.</span><span class="na">allowedLateness</span><span class="o">(&lt;</span><span class="n">time</span><span class="o">&gt;)</span>
    <span class="o">.&lt;</span><span class="n">windowed</span> <span class="n">transformation</span><span class="o">&gt;(&lt;</span><span class="n">window</span> <span class="n">function</span><span class="o">&gt;);</span></code></pre></div>

<p>Elements that arrive within the allowed lateness are still put into windows and are considered when computing window results. If elements arrive after the allowed lateness they will be dropped. Flink will also make sure that any state held by the windowing operation is garbage collected once the watermark passes the end of a window plus the allowed lateness.</p>

<p>Check out the <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.1/apis/streaming/windows.html">Windows documentation for more details</a>.</p>

<h2 id="scala-api-for-complex-event-processing-cep">Scala API for Complex Event Processing (CEP)</h2>

<p>Flink 1.0 added the initial version of the CEP library. The core of the library is a Pattern API, which allows you to easily specify patterns to match against in your event stream. While in Flink 1.0 this API was only available for Java, Flink 1.1. now exposes the same API for Scala, allowing you to specify your event patterns in a more concise manner.</p>

<p>A more detailed introduction can be found in the <a href="http://flink.apache.org/news/2016/04/06/cep-monitoring.html">Flink blog</a> and the <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.1/apis/streaming/libs/cep.html">CEP documentation</a>.</p>

<h2 id="graph-generators-and-new-gelly-library-algorithms">Graph generators and new Gelly library algorithms</h2>

<p>This release includes many enhancements and new features for graph processing. Gelly now provides a collection of scalable graph generators for common graph types, such as complete, cycle, grid, hypercube, and RMat graphs. A variety of new graph algorithms have been added to the Gelly library, including Global and Local Clustering Coefficient, HITS, and similarity measures (Jaccard and Adamic-Adar).</p>

<p>For a full list of new graph processing features, check out the <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.1/apis/batch/libs/gelly.html">Gelly documentation</a>.</p>

<h2 id="metrics">Metrics</h2>

<p>Flink’s new metrics system allows you to easily gather and expose metrics from your user application to external systems. You can add counters, gauges, and histograms to your application via the runtime context:</p>

<div class="highlight"><pre><code class="language-java"><span class="n">Counter</span> <span class="n">counter</span> <span class="o">=</span> <span class="n">getRuntimeContext</span><span class="o">()</span>
  <span class="o">.</span><span class="na">getMetricGroup</span><span class="o">()</span>
  <span class="o">.</span><span class="na">counter</span><span class="o">(</span><span class="s">&quot;my-counter&quot;</span><span class="o">);</span></code></pre></div>

<p>All registered metrics will be exposed via reporters. Out of the box, Flinks comes with support for JMX, Ganglia, Graphite, and statsD. In addition to your custom metrics, Flink exposes many internal metrics like checkpoint sizes and JVM stats.</p>

<p>Check out the <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.1/apis/metrics.html">Metrics documentation for more details</a>.</p>

<h2 id="list-of-contributors">List of Contributors</h2>

<p>The following 95 people contributed to this release:</p>

<ul>
  <li>Abdullah Ozturk</li>
  <li>Ajay Bhat</li>
  <li>Alexey Savartsov</li>
  <li>Aljoscha Krettek</li>
  <li>Andrea Sella</li>
  <li>Andrew Palumbo</li>
  <li>Chenguang He</li>
  <li>Chiwan Park</li>
  <li>David Moravek</li>
  <li>Dominik Bruhn</li>
  <li>Dyana Rose</li>
  <li>Fabian Hueske</li>
  <li>Flavio Pompermaier</li>
  <li>Gabor Gevay</li>
  <li>Gabor Horvath</li>
  <li>Geoffrey Mon</li>
  <li>Gordon Tai</li>
  <li>Greg Hogan</li>
  <li>Gyula Fora</li>
  <li>Henry Saputra</li>
  <li>Ignacio N. Lucero Ascencio</li>
  <li>Igor Berman</li>
  <li>Ismaël Mejía</li>
  <li>Ivan Mushketyk</li>
  <li>Jark Wu</li>
  <li>Jiri Simsa</li>
  <li>Jonas Traub</li>
  <li>Josh</li>
  <li>Joshi</li>
  <li>Joshua Herman</li>
  <li>Ken Krugler</li>
  <li>Konstantin Knauf</li>
  <li>Lasse Dalegaard</li>
  <li>Li Fanxi</li>
  <li>MaBiao</li>
  <li>Mao Wei</li>
  <li>Mark Reddy</li>
  <li>Martin Junghanns</li>
  <li>Martin Liesenberg</li>
  <li>Maximilian Michels</li>
  <li>Michal Fijolek</li>
  <li>Márton Balassi</li>
  <li>Nathan Howell</li>
  <li>Niels Basjes</li>
  <li>Niels Zeilemaker</li>
  <li>Phetsarath, Sourigna</li>
  <li>Robert Metzger</li>
  <li>Scott Kidder</li>
  <li>Sebastian Klemke</li>
  <li>Shahin</li>
  <li>Shannon Carey</li>
  <li>Shannon Quinn</li>
  <li>Stefan Richter</li>
  <li>Stefano Baghino</li>
  <li>Stefano Bortoli</li>
  <li>Stephan Ewen</li>
  <li>Steve Cosenza</li>
  <li>Sumit Chawla</li>
  <li>Tatu Saloranta</li>
  <li>Tianji Li</li>
  <li>Till Rohrmann</li>
  <li>Todd Lisonbee</li>
  <li>Tony Baines</li>
  <li>Trevor Grant</li>
  <li>Ufuk Celebi</li>
  <li>Vasudevan</li>
  <li>Yijie Shen</li>
  <li>Zack Pierce</li>
  <li>Zhai Jia</li>
  <li>chengxiang li</li>
  <li>chobeat</li>
  <li>danielblazevski</li>
  <li>dawid</li>
  <li>dawidwys</li>
  <li>eastcirclek</li>
  <li>erli ding</li>
  <li>gallenvara</li>
  <li>kl0u</li>
  <li>mans2singh</li>
  <li>markreddy</li>
  <li>mjsax</li>
  <li>nikste</li>
  <li>omaralvarez</li>
  <li>philippgrulich</li>
  <li>ramkrishna</li>
  <li>sahitya-pavurala</li>
  <li>samaitra</li>
  <li>smarthi</li>
  <li>spkavuly</li>
  <li>subhankar</li>
  <li>twalthr</li>
  <li>vasia</li>
  <li>xueyan.li</li>
  <li>zentol</li>
  <li>卫乐</li>
</ul>
</p>

      <p><a href="/news/2016/08/08/release-1.1.0.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    
    <article>
      <h2 class="blog-title"><a href="/news/2016/05/24/stream-sql.html">Stream Processing for Everyone with SQL and Apache Flink</a></h2>

      <p>24 May 2016 by Fabian Hueske (<a href="https://twitter.com/">@fhueske</a>)
      </p>

      <p><p>About six months ago, the Apache Flink community started an effort to add a SQL interface for stream data analysis. SQL is <i>the</i> standard language to access and process data. Everybody who occasionally analyzes data is familiar with SQL. Consequently, a SQL interface for stream data processing will make this technology accessible to a much wider audience. Moreover, SQL support for streaming data will also enable new use cases such as interactive and ad-hoc stream analysis and significantly simplify many applications including stream ingestion and simple transformations.</p>
<p>In this blog post, we report on the current status, architectural design, and future plans of the Apache Flink community to implement support for SQL as a language for analyzing data streams.</p></p>

      <p><a href="/news/2016/05/24/stream-sql.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    
    <article>
      <h2 class="blog-title"><a href="/news/2016/05/11/release-1.0.3.html">Flink 1.0.3 Released</a></h2>

      <p>11 May 2016
      </p>

      <p><p>Today, the Flink community released Flink version <strong>1.0.3</strong>, the third bugfix release of the 1.0 series.</p>

<p>We <strong>recommend all users updating to this release</strong> by bumping the version of your Flink dependencies to <code>1.0.3</code> and updating the binaries on the server. You can find the binaries on the updated <a href="/downloads.html">Downloads page</a>.</p>

<h2 id="fixed-issues">Fixed Issues</h2>

<h3 id="bug">Bug</h3>

<ul>
  <li>[<a href="https://issues.apache.org/jira/browse/FLINK-3790">FLINK-3790</a>] [streaming] Use proper hadoop config in rolling sink</li>
  <li>[<a href="https://issues.apache.org/jira/browse/FLINK-3840">FLINK-3840</a>] Remove Testing Files in RocksDB Backend</li>
  <li>[<a href="https://issues.apache.org/jira/browse/FLINK-3835">FLINK-3835</a>] [optimizer] Add input id to JSON plan to resolve ambiguous input names</li>
  <li>[hotfix] OptionSerializer.duplicate to respect stateful element serializer</li>
  <li>[<a href="https://issues.apache.org/jira/browse/FLINK-3803">FLINK-3803</a>] [runtime] Pass CheckpointStatsTracker to ExecutionGraph</li>
  <li>[hotfix] [cep] Make cep window border treatment consistent</li>
</ul>

<h3 id="improvement">Improvement</h3>

<ul>
  <li>[<a href="https://issues.apache.org/jira/browse/FLINK-3678">FLINK-3678</a>] [dist, docs] Make Flink logs directory configurable</li>
</ul>

<h3 id="docs">Docs</h3>

<ul>
  <li>[docs] Add note about S3AFileSystem ‘buffer.dir’ property</li>
  <li>[docs] Update AWS S3 docs</li>
</ul>

<h3 id="tests">Tests</h3>

<ul>
  <li>[<a href="https://issues.apache.org/jira/browse/FLINK-3860">FLINK-3860</a>] [connector-wikiedits] Add retry loop to WikipediaEditsSourceTest</li>
  <li>[streaming-contrib] Fix port clash in DbStateBackend tests</li>
</ul>
</p>

      <p><a href="/news/2016/05/11/release-1.0.3.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    
    <article>
      <h2 class="blog-title"><a href="/news/2016/04/22/release-1.0.2.html">Flink 1.0.2 Released</a></h2>

      <p>22 Apr 2016
      </p>

      <p><p>Today, the Flink community released Flink version <strong>1.0.2</strong>, the second bugfix release of the 1.0 series.</p>

<p>We <strong>recommend all users updating to this release</strong> by bumping the version of your Flink dependencies to <code>1.0.2</code> and updating the binaries on the server. You can find the binaries on the updated <a href="/downloads.html">Downloads page</a>.</p>

<h2 id="fixed-issues">Fixed Issues</h2>

<h3 id="bug">Bug</h3>

<ul>
  <li>[<a href="https://issues.apache.org/jira/browse/FLINK-3657">FLINK-3657</a>] [dataSet] Change access of DataSetUtils.countElements() to ‘public’</li>
  <li>[<a href="https://issues.apache.org/jira/browse/FLINK-3762">FLINK-3762</a>] [core] Enable Kryo reference tracking</li>
  <li>[<a href="https://issues.apache.org/jira/browse/FLINK-3732">FLINK-3732</a>] [core] Fix potential null deference in ExecutionConfig#equals()</li>
  <li>[<a href="https://issues.apache.org/jira/browse/FLINK-3760">FLINK-3760</a>] Fix StateDescriptor.readObject</li>
  <li>[<a href="https://issues.apache.org/jira/browse/FLINK-3730">FLINK-3730</a>] Fix RocksDB Local Directory Initialization</li>
  <li>[<a href="https://issues.apache.org/jira/browse/FLINK-3712">FLINK-3712</a>] Make all dynamic properties available to the CLI frontend</li>
  <li>[<a href="https://issues.apache.org/jira/browse/FLINK-3688">FLINK-3688</a>] WindowOperator.trigger() does not emit Watermark anymore</li>
  <li>[<a href="https://issues.apache.org/jira/browse/FLINK-3697">FLINK-3697</a>] Properly access type information for nested POJO key selection</li>
</ul>

<h3 id="improvement">Improvement</h3>

<ul>
  <li>[<a href="https://issues.apache.org/jira/browse/FLINK-3654">FLINK-3654</a>] Disable Write-Ahead-Log in RocksDB State</li>
</ul>

<h3 id="docs">Docs</h3>
<ul>
  <li>[<a href="https://issues.apache.org/jira/browse/FLINK-2544">FLINK-2544</a>] [docs] Add Java 8 version for building PowerMock tests to docs</li>
  <li>[<a href="https://issues.apache.org/jira/browse/FLINK-3469">FLINK-3469</a>] [docs] Improve documentation for grouping keys</li>
  <li>[<a href="https://issues.apache.org/jira/browse/FLINK-3634">FLINK-3634</a>] [docs] Fix documentation for DataSetUtils.zipWithUniqueId()</li>
  <li>[<a href="https://issues.apache.org/jira/browse/FLINK-3711">FLINK-3711</a>][docs] Documentation of Scala fold()() uses correct syntax</li>
</ul>

<h3 id="tests">Tests</h3>

<ul>
  <li>[<a href="https://issues.apache.org/jira/browse/FLINK-3716">FLINK-3716</a>] [kafka consumer] Decreasing socket timeout so testFailOnNoBroker() will pass before JUnit timeout</li>
</ul>
</p>

      <p><a href="/news/2016/04/22/release-1.0.2.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    
    <article>
      <h2 class="blog-title"><a href="/news/2016/04/14/flink-forward-announce.html">Flink Forward 2016 Call for Submissions Is Now Open</a></h2>

      <p>14 Apr 2016 by Aljoscha Krettek (<a href="https://twitter.com/">@aljoscha</a>)
      </p>

      <p><p>We are happy to announce that the call for submissions for Flink Forward 2016 is now open! The conference will take place September 12-14, 2016 in Berlin, Germany, bringing together the open source stream processing community. Most Apache Flink committers will attend the conference, making it the ideal venue to learn more about the project and its roadmap and connect with the community.</p>

<p>The conference welcomes submissions on everything Flink-related, including experiences with using Flink, products based on Flink, technical talks on extending Flink, as well as connecting Flink with other open source or proprietary software.</p>

<p>Read more <a href="http://flink-forward.org/">here</a>.</p>
</p>

      <p><a href="/news/2016/04/14/flink-forward-announce.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    
    <article>
      <h2 class="blog-title"><a href="/news/2016/04/06/cep-monitoring.html">Introducing Complex Event Processing (CEP) with Apache Flink</a></h2>

      <p>06 Apr 2016 by Till Rohrmann (<a href="https://twitter.com/">@stsffap</a>)
      </p>

      <p>In this blog post, we introduce Flink's new <a href="https://ci.apache.org/projects/flink/flink-docs-master/apis/streaming/libs/cep.html">CEP library</a> that allows you to do pattern matching on event streams. Through the example of monitoring a data center and generating alerts, we showcase the library's ease of use and its intuitive Pattern API.</p>

      <p><a href="/news/2016/04/06/cep-monitoring.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    
    <article>
      <h2 class="blog-title"><a href="/news/2016/04/06/release-1.0.1.html">Flink 1.0.1 Released</a></h2>

      <p>06 Apr 2016
      </p>

      <p><p>Today, the Flink community released Flink version <strong>1.0.1</strong>, the first bugfix release of the 1.0 series.</p>

<p>We <strong>recommend all users updating to this release</strong> by bumping the version of your Flink dependencies to <code>1.0.1</code> and updating the binaries on the server. You can find the binaries on the updated <a href="/downloads.html">Downloads page</a>.</p>

<h2 id="fixed-issues">Fixed Issues</h2>

<h3>Bug</h3>
<ul>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3179">FLINK-3179</a>] -         Combiner is not injected if Reduce or GroupReduce input is explicitly partitioned
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3472">FLINK-3472</a>] -         JDBCInputFormat.nextRecord(..) has misleading message on NPE
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3491">FLINK-3491</a>] -         HDFSCopyUtilitiesTest fails on Windows
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3495">FLINK-3495</a>] -         RocksDB Tests can&#39;t run on Windows
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3533">FLINK-3533</a>] -         Update the Gelly docs wrt examples and cluster execution
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3563">FLINK-3563</a>] -         .returns() doesn&#39;t compile when using .map() with a custom MapFunction
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3566">FLINK-3566</a>] -         Input type validation often fails on custom TypeInfo implementations
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3578">FLINK-3578</a>] -         Scala DataStream API does not support Rich Window Functions
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3595">FLINK-3595</a>] -         Kafka09 consumer thread does not interrupt when stuck in record emission
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3602">FLINK-3602</a>] -         Recursive Types are not supported / crash TypeExtractor
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3621">FLINK-3621</a>] -         Misleading documentation of memory configuration parameters
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3629">FLINK-3629</a>] -         In wikiedits Quick Start example, &quot;The first call, .window()&quot; should be &quot;The first call, .timeWindow()&quot;
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3651">FLINK-3651</a>] -         Fix faulty RollingSink Restore
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3653">FLINK-3653</a>] -         recovery.zookeeper.storageDir is not documented on the configuration page
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3663">FLINK-3663</a>] -         FlinkKafkaConsumerBase.logPartitionInfo is missing a log marker
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3681">FLINK-3681</a>] -         CEP library does not support Java 8 lambdas as select function
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3682">FLINK-3682</a>] -         CEP operator does not set the processing timestamp correctly
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3684">FLINK-3684</a>] -         CEP operator does not forward watermarks properly
</li>
</ul>

<h3>Improvement</h3>
<ul>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3570">FLINK-3570</a>] -         Replace random NIC selection heuristic by InetAddress.getLocalHost
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3575">FLINK-3575</a>] -         Update Working With State Section in Doc
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3591">FLINK-3591</a>] -         Replace Quickstart K-Means Example by Streaming Example
</li>
</ul>

<h2>Test</h2>
<ul>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-2444">FLINK-2444</a>] -         Add tests for HadoopInputFormats
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-2445">FLINK-2445</a>] -         Add tests for HadoopOutputFormats
</li>
</ul>
</p>

      <p><a href="/news/2016/04/06/release-1.0.1.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    

    <!-- Pagination links -->
    
    <ul class="pager">
      <li>
      
        <a href="/blog/page11" class="previous">Previous</a>
      
      </li>
      <li>
        <span class="page_number ">Page: 12 of 15</span>
      </li>
      <li>
      
        <a href="/blog/page13" class="next">Next</a>
      
      </li>
    </ul>
    
  </div>

  <div class="col-sm-4" markdown="1">
    <!-- Blog posts by YEAR -->
    
      
      

      
    <h2>2021</h2>

    <ul id="markdown-toc">
      
      <li><a href="/2021/03/11/batch-execution-mode.html">A Rundown of Batch Execution Mode in the DataStream API</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2021/03/03/release-1.12.2.html">Apache Flink 1.12.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/2021/02/10/native-k8s-with-ha.html">How to natively deploy Flink on Kubernetes with High-Availability (HA)</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2021/01/29/release-1.10.3.html">Apache Flink 1.10.3 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2021/01/19/release-1.12.1.html">Apache Flink 1.12.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/2021/01/18/rocksdb.html">Using RocksDB State Backend in Apache Flink: When and How</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2021/01/11/batch-fine-grained-fault-tolerance.html">Exploring fine-grained recovery of bounded data sets on Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/2021/01/07/pulsar-flink-connector-270.html">What's New in the Pulsar Flink Connector 2.7.0</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2021/01/02/release-statefun-2.2.2.html">Stateful Functions 2.2.2 Release Announcement</a></li>

      
        
    </ul>
        <hr>
        <h2>2020</h2>
    <ul id="markdown-toc">
        
      
    
      
      

      
      <li><a href="/news/2020/12/18/release-1.11.3.html">Apache Flink 1.11.3 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/2020/12/15/pipelined-region-sheduling.html">Improvements in task scheduling for batch workloads in Apache Flink 1.12</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/12/10/release-1.12.0.html">Apache Flink 1.12.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/11/11/release-statefun-2.2.1.html">Stateful Functions 2.2.1 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/2020/10/15/from-aligned-to-unaligned-checkpoints-part-1.html">From Aligned to Unaligned Checkpoints - Part 1: Checkpoints, Alignment, and Backpressure</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/10/13/stateful-serverless-internals.html">Stateful Functions Internals: Behind the scenes of Stateful Serverless</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/09/28/release-statefun-2.2.0.html">Stateful Functions 2.2.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/09/17/release-1.11.2.html">Apache Flink 1.11.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/09/04/community-update.html">Flink Community Update - August'20</a></li>

      
        
      
    
      
      

      
      <li><a href="/2020/09/01/flink-1.11-memory-management-improvements.html">Memory Management improvements for Flink’s JobManager in Apache Flink 1.11</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/08/25/release-1.10.2.html">Apache Flink 1.10.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/08/20/flink-docker.html">The State of Flink on Docker</a></li>

      
        
      
    
      
      

      
      <li><a href="/2020/08/19/statefun.html">Monitoring and Controlling Networks of IoT Devices with Flink Stateful Functions</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/08/06/external-resource.html">Accelerating your workload with GPU and other external resources</a></li>

      
        
      
    
      
      

      
      <li><a href="/2020/08/04/pyflink-pandas-udf-support-flink.html">PyFlink: The integration of Pandas into PyFlink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/07/30/demo-fraud-detection-3.html">Advanced Flink Application Patterns Vol.3: Custom Window Processing</a></li>

      
        
      
    
      
      

      
      <li><a href="/2020/07/28/flink-sql-demo-building-e2e-streaming-application.html">Flink SQL Demo: Building an End-to-End Streaming Application</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/07/27/community-update.html">Flink Community Update - July'20</a></li>

      
        
      
    
      
      

      
      <li><a href="/2020/07/23/catalogs.html">Sharing is caring - Catalogs in Flink SQL</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/07/21/release-1.11.1.html">Apache Flink 1.11.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/07/14/application-mode.html">Application Deployment in Flink: Current State and the new Application Mode</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/07/06/release-1.11.0.html">Apache Flink 1.11.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/ecosystem/2020/06/23/flink-on-zeppelin-part2.html">Flink on Zeppelin Notebooks for Interactive Data Analysis - Part 2</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/06/15/flink-on-zeppelin-part1.html">Flink on Zeppelin Notebooks for Interactive Data Analysis - Part 1</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/06/11/community-update.html">Flink Community Update - June'20</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/06/09/release-statefun-2.1.0.html">Stateful Functions 2.1.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/05/12/release-1.10.1.html">Apache Flink 1.10.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/05/07/community-update.html">Flink Community Update - May'20</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/05/04/season-of-docs.html">Applying to Google Season of Docs 2020</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/04/24/release-1.9.3.html">Apache Flink 1.9.3 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/04/21/memory-management-improvements-flink-1.10.html">Memory Management Improvements with Apache Flink 1.10</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/04/15/flink-serialization-tuning-vol-1.html">Flink Serialization Tuning Vol. 1: Choosing your Serializer — if you can</a></li>

      
        
      
    
      
      

      
      <li><a href="/2020/04/09/pyflink-udf-support-flink.html">PyFlink: Introducing Python Support for UDFs in Flink's Table API</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/04/07/release-statefun-2.0.0.html">Stateful Functions 2.0 - An Event-driven Database on Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/04/01/community-update.html">Flink Community Update - April'20</a></li>

      
        
      
    
      
      

      
      <li><a href="/features/2020/03/27/flink-for-data-warehouse.html">Flink as Unified Engine for Modern Data Warehousing: Production-Ready Hive Integration</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/03/24/demo-fraud-detection-2.html">Advanced Flink Application Patterns Vol.2: Dynamic Updates of Application Logic</a></li>

      
        
      
    
      
      

      
      <li><a href="/ecosystem/2020/02/22/apache-beam-how-beam-runs-on-top-of-flink.html">Apache Beam: How Beam Runs on Top of Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/02/20/ddl.html">No Java Required: Configuring Sources and Sinks in SQL</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/02/11/release-1.10.0.html">Apache Flink 1.10.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/02/07/a-guide-for-unit-testing-in-apache-flink.html">A Guide for Unit Testing in Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/01/30/release-1.9.2.html">Apache Flink 1.9.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/01/29/state-unlocked-interacting-with-state-in-apache-flink.html">State Unlocked: Interacting with State in Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/01/15/demo-fraud-detection.html">Advanced Flink Application Patterns Vol.1: Case Study of a Fraud Detection System</a></li>

      
        
    </ul>
        <hr>
        <h2>2019</h2>
    <ul id="markdown-toc">
        
      
    
      
      

      
      <li><a href="/news/2019/12/11/release-1.8.3.html">Apache Flink 1.8.3 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/12/09/flink-kubernetes-kudo.html">Running Apache Flink on Kubernetes with KUDO</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/11/25/query-pulsar-streams-using-apache-flink.html">How to query Pulsar Streams using Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/10/18/release-1.9.1.html">Apache Flink 1.9.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/feature/2019/09/13/state-processor-api.html">The State Processor API: How to Read, write and modify the state of Flink applications</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/09/11/release-1.8.2.html">Apache Flink 1.8.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/09/10/community-update.html">Flink Community Update - September'19</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/08/22/release-1.9.0.html">Apache Flink 1.9.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/2019/07/23/flink-network-stack-2.html">Flink Network Stack Vol. 2: Monitoring, Metrics, and that Backpressure Thing</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/07/02/release-1.8.1.html">Apache Flink 1.8.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/2019/06/26/broadcast-state.html">A Practical Guide to Broadcast State in Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/2019/06/05/flink-network-stack.html">A Deep-Dive into Flink's Network Stack</a></li>

      
        
      
    
      
      

      
      <li><a href="/2019/05/19/state-ttl.html">State TTL in Flink 1.8.0: How to Automatically Cleanup Application State in Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/2019/05/14/temporal-tables.html">Flux capacitor, huh? Temporal Tables and Joins in Streaming SQL</a></li>

      
        
      
    
      
      

      
      <li><a href="/2019/05/03/pulsar-flink.html">When Flink & Pulsar Come Together</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/04/17/sod.html">Apache Flink's Application to Season of Docs</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/04/09/release-1.8.0.html">Apache Flink 1.8.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/features/2019/03/11/prometheus-monitoring.html">Flink and Prometheus: Cloud-native monitoring of streaming applications</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/03/06/ffsf-preview.html">What to expect from Flink Forward San Francisco 2019</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/02/25/monitoring-best-practices.html">Monitoring Apache Flink Applications 101</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/02/25/release-1.6.4.html">Apache Flink 1.6.4 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/02/15/release-1.7.2.html">Apache Flink 1.7.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/02/13/unified-batch-streaming-blink.html">Batch as a Special Case of Streaming and Alibaba's contribution of Blink</a></li>

      
        
    </ul>
        <hr>
        <h2>2018</h2>
    <ul id="markdown-toc">
        
      
    
      
      

      
      <li><a href="/news/2018/12/26/release-1.5.6.html">Apache Flink 1.5.6 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/12/22/release-1.6.3.html">Apache Flink 1.6.3 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/12/21/release-1.7.1.html">Apache Flink 1.7.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/11/30/release-1.7.0.html">Apache Flink 1.7.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/10/29/release-1.6.2.html">Apache Flink 1.6.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/10/29/release-1.5.5.html">Apache Flink 1.5.5 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/09/20/release-1.6.1.html">Apache Flink 1.6.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/09/20/release-1.5.4.html">Apache Flink 1.5.4 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/08/21/release-1.5.3.html">Apache Flink 1.5.3 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/08/09/release-1.6.0.html">Apache Flink 1.6.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/07/31/release-1.5.2.html">Apache Flink 1.5.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/07/12/release-1.5.1.html">Apache Flink 1.5.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/05/25/release-1.5.0.html">Apache Flink 1.5.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/03/15/release-1.3.3.html">Apache Flink 1.3.3 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/03/08/release-1.4.2.html">Apache Flink 1.4.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/features/2018/03/01/end-to-end-exactly-once-apache-flink.html">An Overview of End-to-End Exactly-Once Processing in Apache Flink (with Apache Kafka, too!)</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/02/15/release-1.4.1.html">Apache Flink 1.4.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/features/2018/01/30/incremental-checkpointing.html">Managing Large State in Apache Flink: An Intro to Incremental Checkpointing</a></li>

      
        
    </ul>
        <hr>
        <h2>2017</h2>
    <ul id="markdown-toc">
        
      
    
      
      

      
      <li><a href="/news/2017/12/21/2017-year-in-review.html">Apache Flink in 2017: Year in Review</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/12/12/release-1.4.0.html">Apache Flink 1.4.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/11/22/release-1.4-and-1.5-timeline.html">Looking Ahead to Apache Flink 1.4.0 and 1.5.0</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/08/05/release-1.3.2.html">Apache Flink 1.3.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/features/2017/07/04/flink-rescalable-state.html">A Deep Dive into Rescalable State in Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/06/23/release-1.3.1.html">Apache Flink 1.3.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/06/01/release-1.3.0.html">Apache Flink 1.3.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/05/16/official-docker-image.html">Introducing Docker Images for Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/04/26/release-1.2.1.html">Apache Flink 1.2.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/04/04/dynamic-tables.html">Continuous Queries on Dynamic Tables</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/03/29/table-sql-api-update.html">From Streams to Tables and Back Again: An Update on Flink's Table & SQL API</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/03/23/release-1.1.5.html">Apache Flink 1.1.5 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/02/06/release-1.2.0.html">Announcing Apache Flink 1.2.0</a></li>

      
        
    </ul>
        <hr>
        <h2>2016</h2>
    <ul id="markdown-toc">
        
      
    
      
      

      
      <li><a href="/news/2016/12/21/release-1.1.4.html">Apache Flink 1.1.4 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/12/19/2016-year-in-review.html">Apache Flink in 2016: Year in Review</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/10/12/release-1.1.3.html">Apache Flink 1.1.3 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/09/05/release-1.1.2.html">Apache Flink 1.1.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/08/24/ff16-keynotes-panels.html">Flink Forward 2016: Announcing Schedule, Keynotes, and Panel Discussion</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/08/11/release-1.1.1.html">Flink 1.1.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/08/08/release-1.1.0.html">Announcing Apache Flink 1.1.0</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/05/24/stream-sql.html">Stream Processing for Everyone with SQL and Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/05/11/release-1.0.3.html">Flink 1.0.3 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/04/22/release-1.0.2.html">Flink 1.0.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/04/14/flink-forward-announce.html">Flink Forward 2016 Call for Submissions Is Now Open</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/04/06/cep-monitoring.html">Introducing Complex Event Processing (CEP) with Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/04/06/release-1.0.1.html">Flink 1.0.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/03/08/release-1.0.0.html">Announcing Apache Flink 1.0.0</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/02/11/release-0.10.2.html">Flink 0.10.2 Released</a></li>

      
        
    </ul>
        <hr>
        <h2>2015</h2>
    <ul id="markdown-toc">
        
      
    
      
      

      
      <li><a href="/news/2015/12/18/a-year-in-review.html">Flink 2015: A year in review, and a lookout to 2016</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/12/11/storm-compatibility.html">Storm Compatibility in Apache Flink: How to run existing Storm topologies on Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/12/04/Introducing-windows.html">Introducing Stream Windows in Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/11/27/release-0.10.1.html">Flink 0.10.1 released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/11/16/release-0.10.0.html">Announcing Apache Flink 0.10.0</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/09/16/off-heap-memory.html">Off-heap Memory in Apache Flink and the curious JIT compiler</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/09/03/flink-forward.html">Announcing Flink Forward 2015</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/09/01/release-0.9.1.html">Apache Flink 0.9.1 available</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/08/24/introducing-flink-gelly.html">Introducing Gelly: Graph Processing with Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/06/24/announcing-apache-flink-0.9.0-release.html">Announcing Apache Flink 0.9.0</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/05/14/Community-update-April.html">April 2015 in the Flink community</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/05/11/Juggling-with-Bits-and-Bytes.html">Juggling with Bits and Bytes</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/04/13/release-0.9.0-milestone1.html">Announcing Flink 0.9.0-milestone1 preview release</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/04/07/march-in-flink.html">March 2015 in the Flink community</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/03/13/peeking-into-Apache-Flinks-Engine-Room.html">Peeking into Apache Flink's Engine Room</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/03/02/february-2015-in-flink.html">February 2015 in the Flink community</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/02/09/streaming-example.html">Introducing Flink Streaming</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/02/04/january-in-flink.html">January 2015 in the Flink community</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/01/21/release-0.8.html">Apache Flink 0.8.0 available</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/01/06/december-in-flink.html">December 2014 in the Flink community</a></li>

      
        
    </ul>
        <hr>
        <h2>2014</h2>
    <ul id="markdown-toc">
        
      
    
      
      

      
      <li><a href="/news/2014/11/18/hadoop-compatibility.html">Hadoop Compatibility in Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2014/11/04/release-0.7.0.html">Apache Flink 0.7.0 available</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2014/10/03/upcoming_events.html">Upcoming Events</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2014/09/26/release-0.6.1.html">Apache Flink 0.6.1 available</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2014/08/26/release-0.6.html">Apache Flink 0.6 available</a></li>

      
    </ul>
      
    
  </div>
</div>
      </div>
    </div>

    <hr />

    <div class="row">
      <div class="footer text-center col-sm-12">
        <p>Copyright © 2014-2019 <a href="http://apache.org">The Apache Software Foundation</a>. All Rights Reserved.</p>
        <p>Apache Flink, Flink®, Apache®, the squirrel logo, and the Apache feather logo are either registered trademarks or trademarks of The Apache Software Foundation.</p>
        <p><a href="/privacy-policy.html">Privacy Policy</a> &middot; <a href="/blog/feed.xml">RSS feed</a></p>
      </div>
    </div>
    </div><!-- /.container -->

    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="/js/jquery.matchHeight-min.js"></script>
    <script src="/js/bootstrap.min.js"></script>
    <script src="/js/codetabs.js"></script>
    <script src="/js/stickysidebar.js"></script>

    <!-- Google Analytics -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-52545728-1', 'auto');
      ga('send', 'pageview');
    </script>
  </body>
</html>

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Apache Flink: Blog</title>
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">

    <!-- Bootstrap -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">
    <link rel="stylesheet" href="/css/flink.css">
    <link rel="stylesheet" href="/css/syntax.css">

    <!-- Blog RSS feed -->
    <link href="/blog/feed.xml" rel="alternate" type="application/rss+xml" title="Apache Flink Blog: RSS feed" />

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <!-- We need to load Jquery in the header for custom google analytics event tracking-->
    <script src="/js/jquery.min.js"></script>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>  
    

    <!-- Main content. -->
    <div class="container">
    <div class="row">

      
     <div id="sidebar" class="col-sm-3">
        

<!-- Top navbar. -->
    <nav class="navbar navbar-default">
        <!-- The logo. -->
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <div class="navbar-logo">
            <a href="/">
              <img alt="Apache Flink" src="/img/flink-header-logo.svg" width="147px" height="73px">
            </a>
          </div>
        </div><!-- /.navbar-header -->

        <!-- The navigation links. -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
          <ul class="nav navbar-nav navbar-main">

            <!-- First menu section explains visitors what Flink is -->

            <!-- What is Stream Processing? -->
            <!--
            <li><a href="/streamprocessing1.html">What is Stream Processing?</a></li>
            -->

            <!-- What is Flink? -->
            <li><a href="/flink-architecture.html">What is Apache Flink?</a></li>

            

            <!-- What is Stateful Functions? -->

            <li><a href="/stateful-functions.html">What is Stateful Functions?</a></li>

            <!-- Use cases -->
            <li><a href="/usecases.html">Use Cases</a></li>

            <!-- Powered by -->
            <li><a href="/poweredby.html">Powered By</a></li>


            &nbsp;
            <!-- Second menu section aims to support Flink users -->

            <!-- Downloads -->
            <li><a href="/downloads.html">Downloads</a></li>

            <!-- Getting Started -->
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#">Getting Started<span class="caret"></span></a>
              <ul class="dropdown-menu">
                <li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/try-flink/index.html" target="_blank">With Flink <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2/getting-started/project-setup.html" target="_blank">With Flink Stateful Functions <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="/training.html">Training Course</a></li>
              </ul>
            </li>

            <!-- Documentation -->
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#">Documentation<span class="caret"></span></a>
              <ul class="dropdown-menu">
                <li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12" target="_blank">Flink 1.12 (Latest stable release) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://ci.apache.org/projects/flink/flink-docs-master" target="_blank">Flink Master (Latest Snapshot) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2" target="_blank">Flink Stateful Functions 2.2 (Latest stable release) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://ci.apache.org/projects/flink/flink-statefun-docs-master" target="_blank">Flink Stateful Functions Master (Latest Snapshot) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
              </ul>
            </li>

            <!-- getting help -->
            <li><a href="/gettinghelp.html">Getting Help</a></li>

            <!-- Blog -->
            <li class="active"><a href="/blog/"><b>Flink Blog</b></a></li>


            <!-- Flink-packages -->
            <li>
              <a href="https://flink-packages.org" target="_blank">flink-packages.org <small><span class="glyphicon glyphicon-new-window"></span></small></a>
            </li>
            &nbsp;

            <!-- Third menu section aim to support community and contributors -->

            <!-- Community -->
            <li><a href="/community.html">Community &amp; Project Info</a></li>

            <!-- Roadmap -->
            <li><a href="/roadmap.html">Roadmap</a></li>

            <!-- Contribute -->
            <li><a href="/contributing/how-to-contribute.html">How to Contribute</a></li>
            

            <!-- GitHub -->
            <li>
              <a href="https://github.com/apache/flink" target="_blank">Flink on GitHub <small><span class="glyphicon glyphicon-new-window"></span></small></a>
            </li>

            &nbsp;

            <!-- Language Switcher -->
            <li>
              
                
                  <!-- link to the Chinese home page when current is blog page -->
                  <a href="/zh">中文版</a>
                
              
            </li>

          </ul>

          <style>
            .smalllinks:link {
              display: inline-block !important; background: none; padding-top: 0px; padding-bottom: 0px; padding-right: 0px; min-width: 75px;
            }
          </style>

          <ul class="nav navbar-nav navbar-bottom">
          <hr />

            <!-- Twitter -->
            <li><a href="https://twitter.com/apacheflink" target="_blank">@ApacheFlink <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

            <!-- Visualizer -->
            <li class=" hidden-md hidden-sm"><a href="/visualizer/" target="_blank">Plan Visualizer <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

            <li >
                  <a href="/security.html">Flink Security</a>
            </li>

          <hr />

            <li><a href="https://apache.org" target="_blank">Apache Software Foundation <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

            <li>

              <a class="smalllinks" href="https://www.apache.org/licenses/" target="_blank">License</a> <small><span class="glyphicon glyphicon-new-window"></span></small>

              <a class="smalllinks" href="https://www.apache.org/security/" target="_blank">Security</a> <small><span class="glyphicon glyphicon-new-window"></span></small>

              <a class="smalllinks" href="https://www.apache.org/foundation/sponsorship.html" target="_blank">Donate</a> <small><span class="glyphicon glyphicon-new-window"></span></small>

              <a class="smalllinks" href="https://www.apache.org/foundation/thanks.html" target="_blank">Thanks</a> <small><span class="glyphicon glyphicon-new-window"></span></small>
            </li>

          </ul>
        </div><!-- /.navbar-collapse -->
    </nav>

      </div>
      <div class="col-sm-9">
      <h1>Blog</h1>
<hr />

<div class="row">
  <div class="col-sm-8">
    <!-- Blog posts -->
    
    <article>
      <h2 class="blog-title"><a href="/news/2018/03/08/release-1.4.2.html">Apache Flink 1.4.2 Released</a></h2>

      <p>08 Mar 2018
      </p>

      <p><p>The Apache Flink community released the second bugfix version of the Apache Flink 1.4 series.</p>

<p>This release includes more than 10 fixes and minor improvements for Flink 1.4.1. The list below includes a detailed list of all fixes.</p>

<p>We highly recommend all users to upgrade to Flink 1.4.2.</p>

<p>Updated Maven dependencies:</p>

<div class="highlight"><pre><code class="language-xml"><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-java<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.4.2<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-streaming-java_2.11<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.4.2<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-clients_2.11<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.4.2<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span></code></pre></div>

<p>You can find the binaries on the updated <a href="http://flink.apache.org/downloads.html">Downloads page</a>.</p>

<p>List of resolved issues:</p>

<h2>        Sub-task
</h2>
<ul>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6321">FLINK-6321</a>] -         RocksDB state backend Checkpointing is not working with KeyedCEP.
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7756">FLINK-7756</a>] -         RocksDB state backend Checkpointing (Async and Incremental)  is not working with CEP.
</li>
</ul>

<h2>        Bug
</h2>
<ul>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8423">FLINK-8423</a>] -         OperatorChain#pushToOperator catch block may fail with NPE
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8451">FLINK-8451</a>] -         CaseClassSerializer is not backwards compatible in 1.4
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8520">FLINK-8520</a>] -         CassandraConnectorITCase.testCassandraTableSink unstable on Travis
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8621">FLINK-8621</a>] -         PrometheusReporterTest.endpointIsUnavailableAfterReporterIsClosed unstable on Travis
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8692">FLINK-8692</a>] -         Mistake in MyMapFunction code snippet
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8735">FLINK-8735</a>] -         Add savepoint migration ITCase that covers operator state
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8741">FLINK-8741</a>] -         KafkaFetcher09/010/011 uses wrong user code classloader
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8772">FLINK-8772</a>] -         FlinkKafkaConsumerBase partitions discover missing a log parameter
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8791">FLINK-8791</a>] -         Fix documentation on how to link dependencies
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8798">FLINK-8798</a>] -         Make commons-logging a parent-first pattern
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8849">FLINK-8849</a>] -         Wrong link from concepts/runtime to doc on chaining
</li>
</ul>

<h2>        Improvement
</h2>
<ul>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8202">FLINK-8202</a>] -         Update queryable section on configuration page
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8574">FLINK-8574</a>] -         Add timestamps to travis logging messages
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8576">FLINK-8576</a>] -         Log message for QueryableState loading failure too verbose
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8652">FLINK-8652</a>] -         Reduce log level of QueryableStateClient.getKvState() to DEBUG
</li>
</ul>

<h2>        Task
</h2>
<ul>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8308">FLINK-8308</a>] -         Update yajl-ruby dependency to 1.3.1 or higher
</li>
</ul>
</p>

      <p><a href="/news/2018/03/08/release-1.4.2.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    
    <article>
      <h2 class="blog-title"><a href="/features/2018/03/01/end-to-end-exactly-once-apache-flink.html">An Overview of End-to-End Exactly-Once Processing in Apache Flink (with Apache Kafka, too!)</a></h2>

      <p>01 Mar 2018
       Piotr Nowojski (<a href="https://twitter.com/PiotrNowojski">@PiotrNowojski</a>) &amp; Mike Winters (<a href="https://twitter.com/wints">@wints</a>)</p>

      <p>Flink 1.4.0 introduced a new feature that makes it possible to build end-to-end exactly-once applications with Flink and data sources and sinks that support transactions.</p>

      <p><a href="/features/2018/03/01/end-to-end-exactly-once-apache-flink.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    
    <article>
      <h2 class="blog-title"><a href="/news/2018/02/15/release-1.4.1.html">Apache Flink 1.4.1 Released</a></h2>

      <p>15 Feb 2018
      </p>

      <p><p>The Apache Flink community released the first bugfix version of the Apache Flink 1.4 series.</p>

<p>This release includes more than 60 fixes and minor improvements for Flink 1.4.0. The list below includes a detailed list of all fixes.</p>

<p>We highly recommend all users to upgrade to Flink 1.4.1.</p>

<p>Updated Maven dependencies:</p>

<div class="highlight"><pre><code class="language-xml"><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-java<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.4.1<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-streaming-java_2.11<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.4.1<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-clients_2.11<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.4.1<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span></code></pre></div>

<p>You can find the binaries on the updated <a href="http://flink.apache.org/downloads.html">Downloads page</a>.</p>

<p>List of resolved issues:</p>

<h2>        Sub-task
</h2>
<ul>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6321">FLINK-6321</a>] -         RocksDB state backend Checkpointing is not working with KeyedCEP.
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7499">FLINK-7499</a>] -         double buffer release in SpillableSubpartitionView
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7756">FLINK-7756</a>] -         RocksDB state backend Checkpointing (Async and Incremental)  is not working with CEP.
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7760">FLINK-7760</a>] -         Restore failing from external checkpointing metadata.
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8323">FLINK-8323</a>] -         Fix Mod scala function bug
</li>
</ul>

<h2>        Bug
</h2>
<ul>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-5506">FLINK-5506</a>] -         Java 8 - CommunityDetection.java:158 - java.lang.NullPointerException
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6951">FLINK-6951</a>] -         Incompatible versions of httpcomponents jars for Flink kinesis connector
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7949">FLINK-7949</a>] -         AsyncWaitOperator is not restarting when queue is full
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8145">FLINK-8145</a>] -         IOManagerAsync not properly shut down in various tests
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8200">FLINK-8200</a>] -         RocksDBAsyncSnapshotTest should use temp fold instead of fold with fixed name
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8226">FLINK-8226</a>] -         Dangling reference generated after NFA clean up timed out SharedBufferEntry
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8230">FLINK-8230</a>] -         NPE in OrcRowInputFormat on nested structs
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8235">FLINK-8235</a>] -         Cannot run spotbugs for single module
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8242">FLINK-8242</a>] -         ClassCastException in OrcTableSource.toOrcPredicate
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8248">FLINK-8248</a>] -         RocksDB state backend Checkpointing is not working with KeyedCEP in 1.4
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8249">FLINK-8249</a>] -         Kinesis Producer didnt configure region
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8261">FLINK-8261</a>] -         Typos in the shading exclusion for jsr305 in the quickstarts
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8263">FLINK-8263</a>] -         Wrong packaging of flink-core in scala quickstarty
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8265">FLINK-8265</a>] -         Missing jackson dependency for flink-mesos
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8270">FLINK-8270</a>] -         TaskManagers do not use correct local path for shipped Keytab files in Yarn deployment modes
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8275">FLINK-8275</a>] -         Flink YARN deployment with Kerberos enabled not working 
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8278">FLINK-8278</a>] -         Scala examples in Metric documentation do not compile
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8283">FLINK-8283</a>] -         FlinkKafkaConsumerBase failing on Travis with no output in 10min
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8295">FLINK-8295</a>] -         Netty shading does not work properly
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8306">FLINK-8306</a>] -         FlinkKafkaConsumerBaseTest has invalid mocks on final methods
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8318">FLINK-8318</a>] -         Conflict jackson library with ElasticSearch connector
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8325">FLINK-8325</a>] -         Add COUNT AGG support constant parameter, i.e. COUNT(*), COUNT(1) 
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8352">FLINK-8352</a>] -         Flink UI Reports No Error on Job Submission Failures
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8355">FLINK-8355</a>] -         DataSet Should not union a NULL row for AGG without GROUP BY clause.
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8371">FLINK-8371</a>] -         Buffers are not recycled in a non-spilled SpillableSubpartition upon release
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8398">FLINK-8398</a>] -         Stabilize flaky KinesisDataFetcherTests
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8406">FLINK-8406</a>] -         BucketingSink does not detect hadoop file systems
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8409">FLINK-8409</a>] -         Race condition in KafkaConsumerThread leads to potential NPE
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8419">FLINK-8419</a>] -         Kafka consumer&#39;s offset metrics are not registered for dynamically discovered partitions
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8421">FLINK-8421</a>] -         HeapInternalTimerService should reconfigure compatible key / namespace serializers on restore
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8433">FLINK-8433</a>] -         Update code example for &quot;Managed Operator State&quot; documentation
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8461">FLINK-8461</a>] -         Wrong logger configurations for shaded Netty
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8466">FLINK-8466</a>] -         ErrorInfo needs to hold Exception as SerializedThrowable
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8484">FLINK-8484</a>] -         Kinesis consumer re-reads closed shards on job restart
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8485">FLINK-8485</a>] -         Running Flink inside Intellij no longer works after upgrading from 1.3.2 to 1.4.0
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8489">FLINK-8489</a>] -         Data is not emitted by second ElasticSearch connector
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8496">FLINK-8496</a>] -         WebUI does not display TM MemorySegment metrics
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8499">FLINK-8499</a>] -         Kryo must not be child-first loaded
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8522">FLINK-8522</a>] -         DefaultOperatorStateBackend writes data in checkpoint that is never read.
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8559">FLINK-8559</a>] -         Exceptions in RocksDBIncrementalSnapshotOperation#takeSnapshot cause job to get stuck
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8561">FLINK-8561</a>] -         SharedBuffer line 573 uses == to compare BufferEntries instead of .equals.
</li>
</ul>

<h2>        Improvement
</h2>
<ul>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8079">FLINK-8079</a>] -         Skip remaining E2E tests if one failed
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8202">FLINK-8202</a>] -         Update queryable section on configuration page
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8243">FLINK-8243</a>] -         OrcTableSource should recursively read all files in nested directories of the input path.
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8260">FLINK-8260</a>] -         Document API of Kafka 0.11 Producer
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8264">FLINK-8264</a>] -         Add Scala to the parent-first loading patterns
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8271">FLINK-8271</a>] -         upgrade from deprecated classes to AmazonKinesis
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8287">FLINK-8287</a>] -         Flink Kafka Producer docs should clearly state what partitioner is used by default
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8296">FLINK-8296</a>] -         Rework FlinkKafkaConsumerBestTest to not use Java reflection for dependency injection
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8346">FLINK-8346</a>] -         add S3 signature v4 workaround to docs
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8362">FLINK-8362</a>] -         Shade Elasticsearch dependencies away
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8455">FLINK-8455</a>] -         Add Hadoop to the parent-first loading patterns
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8473">FLINK-8473</a>] -         JarListHandler may fail with NPE if directory is deleted
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8571">FLINK-8571</a>] -         Provide an enhanced KeyedStream implementation to use ForwardPartitioner
</li>
</ul>

<h2>        Test
</h2>
<ul>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-8472">FLINK-8472</a>] -         Extend migration tests for Flink 1.4
</li>
</ul>
</p>

      <p><a href="/news/2018/02/15/release-1.4.1.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    
    <article>
      <h2 class="blog-title"><a href="/features/2018/01/30/incremental-checkpointing.html">Managing Large State in Apache Flink: An Intro to Incremental Checkpointing</a></h2>

      <p>30 Jan 2018
       Stefan Ricther (<a href="https://twitter.com/StefanRRicther">@StefanRRicther</a>) &amp; Chris Ward (<a href="https://twitter.com/chrischinch">@chrischinch</a>)</p>

      <p>Flink 1.3.0 introduced incremental checkpointing, making it possible for applications with large state to generate checkpoints more efficiently.</p>

      <p><a href="/features/2018/01/30/incremental-checkpointing.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    
    <article>
      <h2 class="blog-title"><a href="/news/2017/12/21/2017-year-in-review.html">Apache Flink in 2017: Year in Review</a></h2>

      <p>21 Dec 2017
       Chris Ward (<a href="https://twitter.com/chrischinch">@chrischinch</a>) &amp; Mike Winters (<a href="https://twitter.com/wints">@wints</a>)</p>

      <p>As 2017 comes to a close, let's take a moment to look back on the Flink community's great work during the past year.</p>

      <p><a href="/news/2017/12/21/2017-year-in-review.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    
    <article>
      <h2 class="blog-title"><a href="/news/2017/12/12/release-1.4.0.html">Apache Flink 1.4.0 Release Announcement</a></h2>

      <p>12 Dec 2017
       Aljoscha Krettek (<a href="https://twitter.com/aljoscha">@aljoscha</a>) &amp; Mike Winters (<a href="https://twitter.com/wints">@wints</a>)</p>

      <p><p>The Apache Flink community is pleased to announce the 1.4.0 release. Over the past 5 months, the
Flink community has been working hard to resolve more than 900 issues. See the <a href="https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12315522&amp;version=12340533">complete changelog</a>
for more detail.</p>

<p>This is the fifth major release in the 1.x.y series. It is API-compatible with the other 1.x.y
releases for APIs annotated with the @Public annotation.</p>

<p>We encourage everyone to download the release and check out the <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/">documentation</a>.</p>

<p>Feedback through the <a href="http://flink.apache.org/community.html#mailing-lists">Flink mailing lists</a> is, as always, gladly encouraged!</p>

<p>You can find the binaries on the updated <a href="http://flink.apache.org/downloads.html">Downloads</a> page on the Flink project site.</p>

<p>The release includes improvements to many different aspects of Flink, including:</p>

<ul>
  <li>The ability to build end-to-end exactly-once applications with Flink and popular data sources and sinks such as Apache Kafka.</li>
  <li>A more developer-friendly dependency structure as well as Hadoop-free Flink for Flink users who do not have Hadoop dependencies.</li>
  <li>Support for JOIN and for new sources and sinks in table API and SQL, expanding the range of logic that can be expressed with these APIs.</li>
</ul>

<p>A summary of some of the features in the release is available below.</p>

<p>For more background on the Flink 1.4.0 release and the work planned for the Flink 1.5.0 release, please refer to <a href="http://flink.apache.org/news/2017/11/22/release-1.4-and-1.5-timeline.html">this blog post</a> on the Apache Flink blog.</p>

<div class="page-toc">
<ul id="markdown-toc">
  <li><a href="#new-features-and-improvements" id="markdown-toc-new-features-and-improvements">New Features and Improvements</a>    <ul>
      <li><a href="#end-to-end-exactly-once-applications-with-apache-flink-and-apache-kafka-and-twophasecommitsinkfunction" id="markdown-toc-end-to-end-exactly-once-applications-with-apache-flink-and-apache-kafka-and-twophasecommitsinkfunction">End-to-end Exactly Once Applications with Apache Flink and Apache Kafka and TwoPhaseCommitSinkFunction</a></li>
      <li><a href="#table-api-and-streaming-sql-enhancements" id="markdown-toc-table-api-and-streaming-sql-enhancements">Table API and Streaming SQL Enhancements</a></li>
      <li><a href="#a-significantly-improved-dependency-structure-and-reversed-class-loading" id="markdown-toc-a-significantly-improved-dependency-structure-and-reversed-class-loading">A Significantly-Improved Dependency Structure and Reversed Class Loading</a></li>
      <li><a href="#hadoop-free-flink" id="markdown-toc-hadoop-free-flink">Hadoop-free Flink</a></li>
      <li><a href="#improvements-to-flink-internals" id="markdown-toc-improvements-to-flink-internals">Improvements to Flink Internals</a></li>
      <li><a href="#improvements-to-the-queryable-state-client" id="markdown-toc-improvements-to-the-queryable-state-client">Improvements to the Queryable State Client</a></li>
      <li><a href="#metrics-and-monitoring" id="markdown-toc-metrics-and-monitoring">Metrics and Monitoring</a></li>
      <li><a href="#connector-improvements-and-fixes" id="markdown-toc-connector-improvements-and-fixes">Connector improvements and fixes</a></li>
    </ul>
  </li>
  <li><a href="#release-notes---please-read" id="markdown-toc-release-notes---please-read">Release Notes - Please Read</a>    <ul>
      <li><a href="#changes-to-dynamic-class-loading-of-user-code" id="markdown-toc-changes-to-dynamic-class-loading-of-user-code">Changes to dynamic class loading of user code</a></li>
      <li><a href="#no-more-avro-dependency-included-by-default" id="markdown-toc-no-more-avro-dependency-included-by-default">No more Avro dependency included by default</a></li>
      <li><a href="#hadoop-free-flink-1" id="markdown-toc-hadoop-free-flink-1">Hadoop-free Flink</a></li>
      <li><a href="#bundled-s3-filesystems" id="markdown-toc-bundled-s3-filesystems">Bundled S3 FileSystems</a></li>
    </ul>
  </li>
  <li><a href="#list-of-contributors" id="markdown-toc-list-of-contributors">List of Contributors</a></li>
</ul>

</div>

<h2 id="new-features-and-improvements">New Features and Improvements</h2>

<h3 id="end-to-end-exactly-once-applications-with-apache-flink-and-apache-kafka-and-twophasecommitsinkfunction">End-to-end Exactly Once Applications with Apache Flink and Apache Kafka and TwoPhaseCommitSinkFunction</h3>

<p>Flink 1.4 includes a first version of an exactly-once producer for Apache Kafka 0.11. This producer
enables developers who build Flink applications with Kafka as a data source and sink to compute
exactly-once results not just within the Flink program, but truly “end-to-end” in the application.</p>

<p>The common pattern used for exactly-once applications in Kafka and in other sinks–the two-phase
commit algorithm–has been extracted in Flink 1.4.0 into a common class, the
TwoPhaseCommitSinkFunction (<a href="https://issues.apache.org/jira/browse/FLINK-7210">FLINK-7210</a>). This
will make it easier for users to create their own exactly-once data sinks in the future.</p>

<h3 id="table-api-and-streaming-sql-enhancements">Table API and Streaming SQL Enhancements</h3>

<p>Flink SQL now supports windowed joins based on processing time and event time
(<a href="https://issues.apache.org/jira/browse/FLINK-5725">FLINK-5725</a>). Users will be able to execute a
join between 2 streaming tables and compute windowed results according to these 2 different concepts
of time. The syntax and semantics in Flink are the same as standard SQL with JOIN and with Flink’s
streaming SQL more broadly.</p>

<p>Flink SQL also now supports “INSERT INTO SELECT” queries, which makes it possible to write results
from SQL directly into a data sink (an external system that receives data from a Flink application).
This improves operability and ease-of-use of Flink SQL.</p>

<p>The Table API now supports aggregations on streaming tables; previously, the only supported
operations on streaming tables were projection, selection, and union
(<a href="https://issues.apache.org/jira/browse/FLINK-4557">FLINK-4557</a>). This feature was initially discussed in Flink
Improvement Proposal 11: <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-11%3A+Table+API+Stream+Aggregations">FLIP-11</a>.</p>

<p>The release also adds support for new table API and SQL sources and sinks, including a Kafka 0.11
source and JDBC sink.</p>

<p>Lastly, Flink SQL now uses Apache Calcite 1.14, which was just released in October 2017
(<a href="https://issues.apache.org/jira/browse/FLINK-7051">FLINK-7051</a>).</p>

<h3 id="a-significantly-improved-dependency-structure-and-reversed-class-loading">A Significantly-Improved Dependency Structure and Reversed Class Loading</h3>

<p>Flink 1.4.0 shades a number of dependences and subtle runtime conflicts, including:</p>

<ul>
  <li>ASM</li>
  <li>Guava</li>
  <li>Jackson</li>
  <li>Netty</li>
  <li>Apache Zookeeper</li>
</ul>

<p>These changes improve Flink’s overall stability and removes friction when embedding Flink or calling
Flink “library style”.</p>

<p>The release also introduces default reversed (child-first) class loading for dynamically-loaded user
code, allowing for different dependencies than those included in the core framework.</p>

<p>For details on those changes please check out the relevant Jira issues:</p>

<ul>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-7442">FLINK-7442</a></li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-6529">FLINK-6529</a></li>
</ul>

<h3 id="hadoop-free-flink">Hadoop-free Flink</h3>

<p>Apache Flink users without any Apache Hadoop dependencies can now run Flink without Hadoop. Flink
programs that do not rely on Hadoop components can now be much smaller, a benefit particularly in a
container-based setup resulting in less network traffic and better performance.</p>

<p>This includes the addition of Flink’s own Amazon S3 filesystem implementations based on Hadoop’s S3a
and Presto’s S3 file system with properly shaded dependencies (<a href="https://issues.apache.org/jira/browse/FLINK-5706">FLINK-5706</a>).</p>

<p>The details of these changes regarding Hadoop-free Flink are available in the Jira issue:
<a href="https://issues.apache.org/jira/browse/FLINK-2268">FLINK-2268</a>.</p>

<h3 id="improvements-to-flink-internals">Improvements to Flink Internals</h3>

<p>Flink 1.4.0 introduces a new blob storage architecture that was first discussed in
<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-19%3A+Improved+BLOB+storage+architecture">Flink Improvement Proposal 19</a> (<a href="https://issues.apache.org/jira/browse/FLINK-6916">FLINK-6916</a>).</p>

<p>This will enable easier integration with both the work being done in <a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=65147077">Flink Improvement Proposal 6</a> in
the future and with other improvements in the 1.4.0 release, such as support for messages larger
than the maximum Akka Framesize (<a href="https://issues.apache.org/jira/browse/FLINK-6046">FLINK-6046</a>).</p>

<p>The improvement also enables Flink to leverage distributed file systems in high availability
settings for optimized distribution of deployment data to TaskManagers.</p>

<h3 id="improvements-to-the-queryable-state-client">Improvements to the Queryable State Client</h3>

<p>Flink’s <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/stream/state/queryable_state.html">queryable state</a> makes it possible for users to access application state directly in Flink
before the state has been sent to an external database or key-value store.</p>

<p>Flink 1.4.0 introduces a range of improvements to the queryable state client, including a more
container-friendly architecture, a more user-friendly API that hides configuration parameters, and
the groundwork to be able to expose window state (the state of an in-flight window) in the future.</p>

<p>For details about the changes to queryable state please refer to the umbrella Jira issue:
<a href="https://issues.apache.org/jira/browse/FLINK-5675">FLINK-5675</a>.</p>

<h3 id="metrics-and-monitoring">Metrics and Monitoring</h3>

<p>Flink’s metrics system now also includes support for Prometheus, an increasingly-popular metrics and
reporting system within the Flink community (<a href="https://issues.apache.org/jira/browse/FLINK-6221">FLINK-6221</a>).</p>

<p>And the Apache Kafka connector in Flink now exposes metrics for failed and successful offset commits
in the Kafka consumer callback (<a href="https://issues.apache.org/jira/browse/FLINK-6998">FLINK-6998</a>).</p>

<h3 id="connector-improvements-and-fixes">Connector improvements and fixes</h3>

<p>Flink 1.4.0 introduces an Apache Kafka 0.11 connector and, as described above, support for an
exactly-once producer for Kafka 0.11 (<a href="https://issues.apache.org/jira/browse/FLINK-6988">FLINK-6988</a>).</p>

<p>Additionally, the Flink-Kafka consumer now supports dynamic partition discovery &amp; topic discovery
based on regex. This means that the Flink-Kafka consumer can pick up new Kafka partitions without
needing to restart the job and while maintaining exactly-once guarantees
(<a href="https://issues.apache.org/jira/browse/FLINK-4022">FLINK-4022</a>).</p>

<p>Flink’s Apache Kinesis connector now uses an updated version of the Kinesis Consumer Library and
Kinesis Consumer Library. This introduces improved retry logic to the connector and should
significantly reduce the number of failures caused by Flink writing too quickly to Kinesis
(<a href="https://issues.apache.org/jira/browse/FLINK-7366">FLINK-7366</a>).</p>

<p>Flink’s Apache Cassandra connector now supports Scala tuples–previously, only streams of Java
tuples were supported (<a href="https://issues.apache.org/jira/browse/FLINK-4497">FLINK-4497</a>). Also, a bug was fixed in
the Cassandra connector that caused messages to be lost in certain instances
(<a href="https://issues.apache.org/jira/browse/FLINK-4500">FLINK-4500</a>).</p>

<h2 id="release-notes---please-read">Release Notes - Please Read</h2>

<p>Some of these changes will require updating the configuration or Maven dependencies for existing
programs. Please read below to see if you might be affected.</p>

<h3 id="changes-to-dynamic-class-loading-of-user-code">Changes to dynamic class loading of user code</h3>

<p>As mentioned above, we changed the way Flink loads user code from the previous default of
<em>parent-first class loading</em> (the default for Java) to <em>child-first classloading</em>, which is a common
practice in Java Application Servers, where this is also referred to as inverted or reversed class
loading.</p>

<p>This should not affect regular user code but will enable programs to use a different version of
dependencies that come with Flink – for example Akka, netty, or Jackson. If you want to change back
to the previous default, you can use the configuration setting <code>classloader.resolve-order: parent-first</code>,
the new default being <code>child-first</code>.</p>

<h3 id="no-more-avro-dependency-included-by-default">No more Avro dependency included by default</h3>

<p>Flink previously included Avro by default so user programs could simply use Avro and not worry about
adding any dependencies. This behavior was changed in Flink 1.4 because it can lead to dependency
clashes.</p>

<p>You now must manually include the Avro dependency (<code>flink-avro</code>) with your program jar (or add it to
the Flink lib folder) if you want to use Avro.</p>

<h3 id="hadoop-free-flink-1">Hadoop-free Flink</h3>

<p>Starting with version 1.4, Flink can run without any Hadoop dependencies present in the Classpath.
Along with simply running without Hadoop, this enables Flink to dynamically use whatever Hadoop
version is available in the classpath.</p>

<p>You could, for example, download the Hadoop-free release of Flink but use that to run on any
supported version of YARN, and Flink would dynamically use the Hadoop dependencies from YARN.</p>

<p>This also means that in cases where you used connectors to HDFS, such as the <code>BucketingSink</code> or
<code>RollingSink</code>, you now have to ensure that you either use a Flink distribution with bundled Hadoop
dependencies or make sure to include Hadoop dependencies when building a jar file for your
application.</p>

<h3 id="bundled-s3-filesystems">Bundled S3 FileSystems</h3>

<p>Flink 1.4 comes bundled with two different S3 FileSystems based on the Presto S3 FileSystem and
the Hadoop S3A FileSystem. They don’t have dependencies (because all dependencies are
shaded/relocated) and you can use them by dropping the respective file from the <code>opt</code> directory
into the <code>lib</code> directory of your Flink installation. For more information about this, please refer
to the <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/ops/filesystems.html#built-in-file-systems">documentation</a>.</p>

<h2 id="list-of-contributors">List of Contributors</h2>

<p>According to git shortlog, the following 106 people contributed to the 1.4.0 release. Thank you to
all contributors!</p>

<p>Ajay Tripathy, Alejandro Alcalde, Aljoscha Krettek, Bang, Phiradet, Bowen Li, Chris Ward, Cristian,
Dan Kelley, David Anderson, Dawid Wysakowicz, Dian Fu, Dmitrii Kniazev, DmytroShkvyra, Fabian
Hueske, FlorianFan, Fokko Driesprong, Gabor Gevay, Gary Yao, Greg Hogan, Haohui Mai, Hequn Cheng,
James Lafa, Jark Wu, Jie Shen, Jing Fan, JingsongLi, Joerg Schad, Juan Paulo Gutierrez, Ken Geis,
Kent Murra, Kurt Young, Lim Chee Hau, Maximilian Bode, Michael Fong, Mike Kobit, Mikhail Lipkovich,
Nico Kruber, Novotnik, Petr, Nycholas de Oliveira e Oliveira, Patrick Lucas, Piotr Nowojski, Robert
Metzger, Rodrigo Bonifacio, Rong Rong, Scott Kidder, Sebastian Klemke, Shuyi Chen, Stefan Richter,
Stephan Ewen, Svend Vanderveken, Till Rohrmann, Tony Wei, Tzu-Li (Gordon) Tai, Ufuk Celebi, Usman
Younas, Vetriselvan1187, Vishnu Viswanath, Wright, Eron, Xingcan Cui, Xpray, Yestin, Yonatan Most,
Zhenzhong Xu, Zhijiang, adebski, asdf2014, bbayani, biao.liub, cactuslrd.lird, dawidwys, desktop,
fengyelei, godfreyhe, gosubpl, gyao, hongyuhong, huafengw, kkloudas, kl0u, lincoln-lil,
lingjinjiang, mengji.fy, minwenjun, mtunique, p1tz, paul, rtudoran, shaoxuan-wang, sirko
bretschneider, sunjincheng121, tedyu, twalthr, uybhatti, wangmiao1981, yew1eb, z00376786, zentol,
zhangminglei, zhe li, zhouhai02, zjureel, 付典, 军长, 宝牛, 淘江, 金竹</p>
</p>

      <p><a href="/news/2017/12/12/release-1.4.0.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    
    <article>
      <h2 class="blog-title"><a href="/news/2017/11/22/release-1.4-and-1.5-timeline.html">Looking Ahead to Apache Flink 1.4.0 and 1.5.0</a></h2>

      <p>22 Nov 2017
       Stephan Ewen (<a href="https://twitter.com/StephanEwen">@StephanEwen</a>), Aljoscha Krettek (<a href="https://twitter.com/aljoscha">@aljoscha</a>), &amp; Mike Winters (<a href="https://twitter.com/wints">@wints</a>)</p>

      <p><p>The Apache Flink 1.4.0 release is on track to happen in the next couple of weeks, and for all of the
readers out there who haven’t been following the release discussion on <a href="http://flink.apache.org/community.html#mailing-lists">Flink’s developer mailing
list</a>, we’d like to provide some details on
what’s coming in Flink 1.4.0 as well as a preview of what the Flink community will save for 1.5.0.</p>

<p>Both releases include ambitious features that we believe will move Flink to an entirely new level in
terms of the types of problems it can solve and applications it can support. The community deserves
lots of credit for its hard work over the past few months, and we’re excited to see these features
in the hands of users.</p>

<p>This post will describe how the community plans to get there and the rationale behind the approach.</p>

<h2 id="coming-soon-major-changes-to-flinks-runtime">Coming soon: Major Changes to Flink’s Runtime</h2>

<p>There are 3 significant improvements to the Apache Flink engine that the community has nearly
completed and that will have a meaningful impact on Flink’s operability and performance.</p>

<ol>
  <li>Rework of the deployment model and distributed process</li>
  <li>Transition from configurable, fixed-interval network I/O to event-driven network I/O and application-level flow control for better backpressure handling</li>
  <li>Faster recovery from failure</li>
</ol>

<p>Next, we’ll go through each of these improvements in more detail.</p>

<h2 id="reworking-flinks-deployment-model-and-distributed-processing">Reworking Flink’s Deployment Model and Distributed Processing</h2>

<p><a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=65147077">FLIP-6</a> (FLIP is short for
FLink Improvement Proposal and FLIPs are proposals for bigger changes to Flink) is an initiative
that’s been in the works for more than a year and represents a major refactor of Flink’s deployment
model and distributed process. The underlying motivation for FLIP-6 was the fact that Flink is being
adopted by a wider range of developer communities–both developers coming from the big data and
analytics space as well as developers coming from the event-driven applications space.</p>

<p>Modern, stateful stream processing has served as a convergence for these two developer communities.
Despite a significant overlap of the core concepts in the applications being built, each group of
developers has its own set of common tools, deployment models, and expected behaviors when working
with a stream processing framework like Flink.</p>

<p>FLIP-6 will ensure that Flink fits naturally in both of these contexts, behaving as though it’s
native to each ecosystem and operating seamlessly within a broader technology stack. A few of the
specific changes in FLIP-6 that will have such an impact:</p>

<ul>
  <li>Leveraging cluster management frameworks to support full resource elasticity</li>
  <li>First-class support for containerized environments such as Kubernetes and Docker</li>
  <li>REST-based client-cluster communication to ease operations and 3rd party integrations</li>
</ul>

<p>FLIP-6, along with already-introduced features like
<a href="https://data-artisans.com/blog/apache-flink-at-mediamath-rescaling-stateful-applications">rescalable state</a>,
lays the groundwork for dynamic scaling in Flink, meaning that Flink programs will be able to scale up or down
automatically based on required resources–a huge step forward in terms of ease of operability and
the efficiency of Flink applications.</p>

<h2 id="lower-latency-via-improvements-to-the-apache-flink-network-stack">Lower Latency via Improvements to the Apache Flink Network Stack</h2>

<p>Speed will always be a key consideration for users who build stream processing applications, and
Flink 1.5 will include a rework of the network stack that will even further improve Flink’s latency.
At the heart of this work is a transition from configurable, fixed-interval network I/O to event-
driven network I/O and application-level flow control, ensuring that Flink will use all available
network capacity, as well as credit-based flow control which offers more fine-grained backpressuring
for improved checkpoint alignments.</p>

<p>In our testing (<a href="https://www.slideshare.net/FlinkForward/flink-forward-berlin-2017-nico-kruber-building-a-network-stack-for-optimal-throughput-lowlatency-tradeoffs#26">see slide 26 here</a>),
we’ve seen a substantial improvement in latency using event-driven network I/O, and the community
is also doing work to make sure we’re able to provide this increase in speed without a measurable
throughput tradeoff.</p>

<h2 id="faster-recovery-from-failures">Faster Recovery from Failures</h2>

<p>Flink 1.3.0 introduced incremental checkpoints, making it possible to take a checkpoint of state
updates since the last successfully-completed checkpoint only rather than the previous behavior of
only taking checkpoints of the entire state of the application. This has led to significant
performance improvements for users with large state.</p>

<p>Flink 1.5 will introduce task-local recovery, which means that Flink will store a second copy of the
most recent checkpoint on the local disk (or even in main memory) of a task manager. The primary
copy still goes to durable storage so that it’s resilient to machine failures.</p>

<p>In case of failover, the scheduler will try to reschedule tasks to their previous task manager (in
other words, to the same machine again) if this is possible. The task can then recover from the
locally-kept state. This makes it possible to avoid reading all state from the distributed file
system (which is remote over the network). Especially in applications with very large state, not
having to read many gigabytes over the network and instead from local disk will result in
significant performance gains in recovery.</p>

<h2 id="the-proposed-timeline-for-flink-14-and-flink-15">The Proposed Timeline for Flink 1.4 and Flink 1.5</h2>

<p>The good news is that all 3 of the features described above are well underway, and in fact, much of
the work is already covered by open pull requests.</p>

<p>But given these features’ importance and the complexity of the work involved, the community expected
that the QA and testing required would be extensive and would delay the release of the otherwise-
ready features also on the list for the next release.</p>

<p>And so the community decided to withhold the 3 features above (deployment model rework, improvements
to the network stack, and faster recovery) to be included a separate Flink 1.5 release that will
come shortly after the Flink 1.4 release. Flink 1.5 is estimated to come just a couple of months
after 1.4 rather than the typical 4-month cycle in between major releases.</p>

<p>The soon-to-be-released Flink 1.4 represents the current state of Flink without merging those 3
features. And Flink 1.4 is a substantial release in its own right, including, but not limited to,
the following:</p>

<ul>
  <li><strong>A significantly improved dependency structure</strong>, removing many of Flink’s dependencies and subtle runtime conflicts. This increases overall stability and removes friction when embedding Flink or calling Flink “library style”.</li>
  <li><strong>Reversed class loading for dynamically-loaded user code</strong>, allowing for different dependencies than those included in the core framework.</li>
  <li><strong>An Apache Kafka 0.11 exactly-once producer</strong>, making it possible to build end-to-end exactly once applications with Flink and Kafka.</li>
  <li><strong>Streaming SQL JOIN based on processing time and event time</strong>, which gives users the full advantage of Flink’s time handling while using a SQL JOIN.</li>
  <li><strong>Table API / Streaming SQL Source and Sink Additions</strong>, including a Kafka 0.11 source and JDBC sink.</li>
  <li><strong>Hadoop-free Flink</strong>, meaning that users who don’t rely on any Hadoop components (such as YARN or HDFS) in their Flink applications can use Flink without Hadoop for the first time.</li>
  <li><strong>Improvements to queryable state</strong>, including a more container-friendly architecture, a more user-friendly API that hides configuration parameters, and the groundwork to be able to expose window state (the state of an in-flight window) in the future.</li>
  <li><strong>Connector improvements and fixes</strong> for a range of connectors including Kafka, Apache Cassandra, Amazon Kinesis, and more.</li>
  <li><strong>Improved RPC performance</strong> for faster recovery from failure</li>
</ul>

<p>The community decided it was best to get these features into a stable version of Flink as soon as
possible, and the separation of what could have been a single (and very substantial) Flink 1.4
release into 1.4 and 1.5 serves that purpose.</p>

<p>We’re excited by what each of these represents for Apache Flink, and we’d like to extend our thanks
to the Flink community for all of their hard work.</p>

<p>If you’d like to follow along with release discussions, <a href="http://flink.apache.org/community.html#mailing-lists">please subscribe to the dev@ mailing
list</a>.</p>

</p>

      <p><a href="/news/2017/11/22/release-1.4-and-1.5-timeline.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    
    <article>
      <h2 class="blog-title"><a href="/news/2017/08/05/release-1.3.2.html">Apache Flink 1.3.2 Released</a></h2>

      <p>05 Aug 2017
      </p>

      <p><p>The Apache Flink community released the second bugfix version of the Apache Flink 1.3 series.</p>

<p>This release includes more than 60 fixes and minor improvements for Flink 1.3.1. The list below includes a detailed list of all fixes.</p>

<p>We highly recommend all users to upgrade to Flink 1.3.2.</p>

<div class="alert alert-warning">
  Important Notice:

  <p>A user reported a bug in the FlinkKafkaConsumer
  (<a href="https://issues.apache.org/jira/browse/FLINK-7143">FLINK-7143</a>) that is causing
  incorrect partition assignment in large Kafka deployments in the presence of inconsistent broker
  metadata.  In that case multiple parallel instances of the FlinkKafkaConsumer may read from the
  same topic partition, leading to data duplication. In Flink 1.3.2 this bug is fixed but incorrect
  assignments from Flink 1.3.0 and 1.3.1 cannot be automatically fixed by upgrading to Flink 1.3.2
  via a savepoint because the upgraded version would resume the wrong partition assignment from the
  savepoint. If you believe you are affected by this bug (seeing messages from some partitions
  duplicated) please refer to the JIRA issue for an upgrade path that works around that.</p>

  <p>Before attempting the more elaborate upgrade path, we would suggest to check if you are
  actually affected by this bug. We did not manage to reproduce it in various testing clusters and
  according to the reporting user, it only appeared in rare cases on their very large setup. This
  leads us to believe that most likely only a minority of setups would be affected by this bug.</p>
</div>

<p>Notable changes:</p>

<ul>
  <li>The default Kafka version for Flink Kafka Consumer 0.10 was bumped from 0.10.0.1 to 0.10.2.1.</li>
  <li>Some default values for configurations of AWS API call behaviors in the Flink Kinesis Consumer
 were adapted for better default consumption performance: 1) <code>SHARD_GETRECORDS_MAX</code> default changed
 to 10,000, and 2) <code>SHARD_GETRECORDS_INTERVAL_MILLIS</code> default changed to 200ms.</li>
</ul>

<p>Updated Maven dependencies:</p>

<div class="highlight"><pre><code class="language-xml"><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-java<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.3.2<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-streaming-java_2.10<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.3.2<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-clients_2.10<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.3.2<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span></code></pre></div>

<p>You can find the binaries on the updated <a href="http://flink.apache.org/downloads.html">Downloads page</a>.</p>

<p>List of resolved issues:</p>

<h2>        Sub-task
</h2>
<ul>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6665">FLINK-6665</a>] -         Pass a ScheduledExecutorService to the RestartStrategy
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6667">FLINK-6667</a>] -         Pass a callback type to the RestartStrategy, rather than the full ExecutionGraph
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6680">FLINK-6680</a>] -         App &amp; Flink migration guide: updates for the 1.3 release
</li>
</ul>

<h2>        Bug
</h2>
<ul>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-5488">FLINK-5488</a>] -         yarnClient should be closed in AbstractYarnClusterDescriptor for error conditions
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6376">FLINK-6376</a>] -         when deploy flink cluster on the yarn, it is lack of hdfs delegation token.
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6541">FLINK-6541</a>] -         Jar upload directory not created
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6654">FLINK-6654</a>] -         missing maven dependency on &quot;flink-shaded-hadoop2-uber&quot; in flink-dist
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6655">FLINK-6655</a>] -         Misleading error message when HistoryServer path is empty
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6742">FLINK-6742</a>] -         Improve error message when savepoint migration fails due to task removal
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6774">FLINK-6774</a>] -         build-helper-maven-plugin version not set
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6806">FLINK-6806</a>] -         rocksdb is not listed as state backend in doc
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6843">FLINK-6843</a>] -         ClientConnectionTest fails on travis
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6867">FLINK-6867</a>] -         Elasticsearch 1.x ITCase still instable due to embedded node instability
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6918">FLINK-6918</a>] -         Failing tests: ChainLengthDecreaseTest and ChainLengthIncreaseTest
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6945">FLINK-6945</a>] -         TaskCancelAsyncProducerConsumerITCase.testCancelAsyncProducerAndConsumer instable test case
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6964">FLINK-6964</a>] -         Fix recovery for incremental checkpoints in StandaloneCompletedCheckpointStore
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6965">FLINK-6965</a>] -         Avro is missing snappy dependency
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6987">FLINK-6987</a>] -         TextInputFormatTest fails when run in path containing spaces
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6996">FLINK-6996</a>] -         FlinkKafkaProducer010 doesn&#39;t guarantee at-least-once semantic
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7005">FLINK-7005</a>] -         Optimization steps are missing for nested registered tables
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7011">FLINK-7011</a>] -         Instable Kafka testStartFromKafkaCommitOffsets failures on Travis
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7025">FLINK-7025</a>] -         Using NullByteKeySelector for Unbounded ProcTime NonPartitioned Over
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7034">FLINK-7034</a>] -         GraphiteReporter cannot recover from lost connection
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7038">FLINK-7038</a>] -         Several misused &quot;KeyedDataStream&quot; term in docs and Javadocs
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7041">FLINK-7041</a>] -         Deserialize StateBackend from JobCheckpointingSettings with user classloader
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7132">FLINK-7132</a>] -         Fix BulkIteration parallelism
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7133">FLINK-7133</a>] -         Fix Elasticsearch version interference
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7137">FLINK-7137</a>] -         Flink table API defaults top level fields as nullable and all nested fields within CompositeType as non-nullable
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7143">FLINK-7143</a>] -         Partition assignment for Kafka consumer is not stable
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7154">FLINK-7154</a>] -         Missing call to build CsvTableSource example
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7158">FLINK-7158</a>] -         Wrong test jar dependency in flink-clients
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7177">FLINK-7177</a>] -         DataSetAggregateWithNullValuesRule fails creating null literal for non-nullable type
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7178">FLINK-7178</a>] -         Datadog Metric Reporter Jar is Lacking Dependencies
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7180">FLINK-7180</a>] -         CoGroupStream perform checkpoint failed
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7195">FLINK-7195</a>] -         FlinkKafkaConsumer should not respect fetched partitions to filter restored partition states
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7216">FLINK-7216</a>] -         ExecutionGraph can perform concurrent global restarts to scheduling
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7225">FLINK-7225</a>] -         Cutoff exception message in StateDescriptor
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7226">FLINK-7226</a>] -         REST responses contain invalid content-encoding header
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7231">FLINK-7231</a>] -         SlotSharingGroups are not always released in time for new restarts
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7234">FLINK-7234</a>] -         Fix CombineHint documentation
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7241">FLINK-7241</a>] -         Fix YARN high availability documentation
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7255">FLINK-7255</a>] -         ListStateDescriptor example uses wrong constructor
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7258">FLINK-7258</a>] -         IllegalArgumentException in Netty bootstrap with large memory state segment size
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7266">FLINK-7266</a>] -         Don&#39;t attempt to delete parent directory on S3
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7268">FLINK-7268</a>] -         Zookeeper Checkpoint Store interacting with Incremental State Handles can lead to loss of handles
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7281">FLINK-7281</a>] -         Fix various issues in (Maven) release infrastructure
</li>
</ul>

<h2>        Improvement
</h2>
<ul>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6365">FLINK-6365</a>] -         Adapt default values of the Kinesis connector
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6575">FLINK-6575</a>] -         Disable all tests on Windows that use HDFS
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6682">FLINK-6682</a>] -         Improve error message in case parallelism exceeds maxParallelism
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6789">FLINK-6789</a>] -         Remove duplicated test utility reducer in optimizer
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6874">FLINK-6874</a>] -         Static and transient fields ignored for POJOs
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6898">FLINK-6898</a>] -         Limit size of operator component in metric name
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6937">FLINK-6937</a>] -         Fix link markdown in Production Readiness Checklist doc
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6940">FLINK-6940</a>] -         Clarify the effect of configuring per-job state backend
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6998">FLINK-6998</a>] -         Kafka connector needs to expose metrics for failed/successful offset commits in the Kafka Consumer callback
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7004">FLINK-7004</a>] -         Switch to Travis Trusty image
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7032">FLINK-7032</a>] -         Intellij is constantly changing language level of sub projects back to 1.6
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7069">FLINK-7069</a>] -         Catch exceptions for each reporter separately
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7149">FLINK-7149</a>] -         Add checkpoint ID to &#39;sendValues()&#39; in GenericWriteAheadSink
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7164">FLINK-7164</a>] -         Extend integration tests for (externalised) checkpoints, checkpoint store
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7174">FLINK-7174</a>] -         Bump dependency of Kafka 0.10.x to the latest one
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7211">FLINK-7211</a>] -         Exclude Gelly javadoc jar from release
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7224">FLINK-7224</a>] -         Incorrect Javadoc description in all Kafka consumer versions
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7228">FLINK-7228</a>] -         Harden HistoryServerStaticFileHandlerTest
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7233">FLINK-7233</a>] -         TaskManagerHeapSizeCalculationJavaBashTest failed on Travis
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7287">FLINK-7287</a>] -         test instability in Kafka010ITCase.testCommitOffsetsToKafka
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-7290">FLINK-7290</a>] -         Make release scripts modular
</li>
</ul>
</p>

      <p><a href="/news/2017/08/05/release-1.3.2.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    
    <article>
      <h2 class="blog-title"><a href="/features/2017/07/04/flink-rescalable-state.html">A Deep Dive into Rescalable State in Apache Flink</a></h2>

      <p>04 Jul 2017 by Stefan Richter (<a href="https://twitter.com/">@StefanRRichter</a>)
      </p>

      <p><p>A primer on stateful stream processing and an in-depth walkthrough of rescalable state in Apache Flink.</p></p>

      <p><a href="/features/2017/07/04/flink-rescalable-state.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    
    <article>
      <h2 class="blog-title"><a href="/news/2017/06/23/release-1.3.1.html">Apache Flink 1.3.1 Released</a></h2>

      <p>23 Jun 2017
      </p>

      <p><p>The Apache Flink community released the first bugfix version of the Apache Flink 1.3 series.</p>

<p>This release includes 50 fixes and minor improvements for Flink 1.3.0. The list below includes a detailed list of all fixes.</p>

<p>We highly recommend all users to upgrade to Flink 1.3.1.</p>

<div class="highlight"><pre><code class="language-xml"><span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-java<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.3.1<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-streaming-java_2.10<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.3.1<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span>
<span class="nt">&lt;dependency&gt;</span>
  <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
  <span class="nt">&lt;artifactId&gt;</span>flink-clients_2.10<span class="nt">&lt;/artifactId&gt;</span>
  <span class="nt">&lt;version&gt;</span>1.3.1<span class="nt">&lt;/version&gt;</span>
<span class="nt">&lt;/dependency&gt;</span></code></pre></div>

<p>You can find the binaries on the updated <a href="http://flink.apache.org/downloads.html">Downloads page</a>.</p>

<h3>        Bug
</h3>
<ul>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6492">FLINK-6492</a>] -         Unclosed DataOutputViewStream in GenericArraySerializerConfigSnapshot#write()
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6602">FLINK-6602</a>] -         Table source with defined time attributes allows empty string
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6652">FLINK-6652</a>] -         Problem with DelimitedInputFormat
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6659">FLINK-6659</a>] -         RocksDBMergeIteratorTest, SavepointITCase leave temporary directories behind
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6669">FLINK-6669</a>] -         [Build] Scala style check errror on Windows
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6685">FLINK-6685</a>] -         SafetyNetCloseableRegistry is closed prematurely in Task::triggerCheckpointBarrier
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6772">FLINK-6772</a>] -         Incorrect ordering of matched state events in Flink CEP
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6775">FLINK-6775</a>] -         StateDescriptor cannot be shared by multiple subtasks
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6780">FLINK-6780</a>] -         ExternalTableSource should add time attributes in the row type
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6783">FLINK-6783</a>] -         Wrongly extracted TypeInformations for WindowedStream::aggregate
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6797">FLINK-6797</a>] -         building docs fails with bundler 1.15
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6801">FLINK-6801</a>] -         PojoSerializerConfigSnapshot cannot deal with missing Pojo fields
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6804">FLINK-6804</a>] -         Inconsistent state migration behaviour between different state backends
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6807">FLINK-6807</a>] -         Elasticsearch 5 connector artifact not published to maven 
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6808">FLINK-6808</a>] -         Stream join fails when checkpointing is enabled
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6809">FLINK-6809</a>] -         side outputs documentation: wrong variable name in java example code
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6812">FLINK-6812</a>] -         Elasticsearch 5 release artifacts not published to Maven central
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6815">FLINK-6815</a>] -         Javadocs don&#39;t work anymore in Flink 1.4-SNAPSHOT
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6816">FLINK-6816</a>] -         Fix wrong usage of Scala string interpolation in Table API
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6833">FLINK-6833</a>] -         Race condition: Asynchronous checkpointing task can fail completed StreamTask
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6844">FLINK-6844</a>] -         TraversableSerializer should implement compatibility methods
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6848">FLINK-6848</a>] -         Extend the managed state docs with a Scala example
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6853">FLINK-6853</a>] -         Migrating from Flink 1.1 fails for FlinkCEP
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6869">FLINK-6869</a>] -         Scala serializers do not have the serialVersionUID specified
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6875">FLINK-6875</a>] -         Remote DataSet API job submission timing out
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6881">FLINK-6881</a>] -         Creating a table from a POJO and defining a time attribute fails
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6883">FLINK-6883</a>] -         Serializer for collection of Scala case classes are generated with different anonymous class names in 1.3
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6886">FLINK-6886</a>] -         Fix Timestamp field can not be selected in event time case when  toDataStream[T], `T` not a `Row` Type.
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6896">FLINK-6896</a>] -         Creating a table from a POJO and use table sink to output fail
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6899">FLINK-6899</a>] -         Wrong state array size in NestedMapsStateTable
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6914">FLINK-6914</a>] -         TrySerializer#ensureCompatibility causes StackOverflowException
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6915">FLINK-6915</a>] -         EnumValueSerializer broken
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6921">FLINK-6921</a>] -         EnumValueSerializer cannot properly handle appended enum values
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6922">FLINK-6922</a>] -         Enum(Value)SerializerConfigSnapshot uses Java serialization to store enum values
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6930">FLINK-6930</a>] -         Selecting window start / end on row-based Tumble/Slide window causes NPE
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6932">FLINK-6932</a>] -         Update the inaccessible Dataflow Model paper link
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6941">FLINK-6941</a>] -         Selecting window start / end on over window causes field not resolve exception
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6948">FLINK-6948</a>] -         EnumValueSerializer cannot handle removed enum values
</li>
</ul>

<h3>        Improvement
</h3>
<ul>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-5354">FLINK-5354</a>] -         Split up Table API documentation into multiple pages 
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6038">FLINK-6038</a>] -         Add deep links to Apache Bahir Flink streaming connector documentations
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6796">FLINK-6796</a>] -         Allow setting the user code class loader for AbstractStreamOperatorTestHarness
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6803">FLINK-6803</a>] -         Add test for PojoSerializer when Pojo changes
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6859">FLINK-6859</a>] -         StateCleaningCountTrigger should not delete timer
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6929">FLINK-6929</a>] -         Add documentation for Table API OVER windows
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6952">FLINK-6952</a>] -         Add link to Javadocs
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6748">FLINK-6748</a>] -         Table API / SQL Docs: Table API Page
</li>
</ul>

<h3>        Test
</h3>
<ul>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6830">FLINK-6830</a>] -         Add ITTests for savepoint migration from 1.3
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6320">FLINK-6320</a>] -         Flakey JobManagerHAJobGraphRecoveryITCase
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6744">FLINK-6744</a>] -         Flaky ExecutionGraphSchedulingTest
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-6913">FLINK-6913</a>] -         Instable StatefulJobSavepointMigrationITCase.testRestoreSavepoint
</li>
</ul>

</p>

      <p><a href="/news/2017/06/23/release-1.3.1.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    

    <!-- Pagination links -->
    
    <ul class="pager">
      <li>
      
        <a href="/blog/page9" class="previous">Previous</a>
      
      </li>
      <li>
        <span class="page_number ">Page: 10 of 15</span>
      </li>
      <li>
      
        <a href="/blog/page11" class="next">Next</a>
      
      </li>
    </ul>
    
  </div>

  <div class="col-sm-4" markdown="1">
    <!-- Blog posts by YEAR -->
    
      
      

      
    <h2>2021</h2>

    <ul id="markdown-toc">
      
      <li><a href="/2021/03/11/batch-execution-mode.html">A Rundown of Batch Execution Mode in the DataStream API</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2021/03/03/release-1.12.2.html">Apache Flink 1.12.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/2021/02/10/native-k8s-with-ha.html">How to natively deploy Flink on Kubernetes with High-Availability (HA)</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2021/01/29/release-1.10.3.html">Apache Flink 1.10.3 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2021/01/19/release-1.12.1.html">Apache Flink 1.12.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/2021/01/18/rocksdb.html">Using RocksDB State Backend in Apache Flink: When and How</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2021/01/11/batch-fine-grained-fault-tolerance.html">Exploring fine-grained recovery of bounded data sets on Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/2021/01/07/pulsar-flink-connector-270.html">What's New in the Pulsar Flink Connector 2.7.0</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2021/01/02/release-statefun-2.2.2.html">Stateful Functions 2.2.2 Release Announcement</a></li>

      
        
    </ul>
        <hr>
        <h2>2020</h2>
    <ul id="markdown-toc">
        
      
    
      
      

      
      <li><a href="/news/2020/12/18/release-1.11.3.html">Apache Flink 1.11.3 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/2020/12/15/pipelined-region-sheduling.html">Improvements in task scheduling for batch workloads in Apache Flink 1.12</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/12/10/release-1.12.0.html">Apache Flink 1.12.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/11/11/release-statefun-2.2.1.html">Stateful Functions 2.2.1 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/2020/10/15/from-aligned-to-unaligned-checkpoints-part-1.html">From Aligned to Unaligned Checkpoints - Part 1: Checkpoints, Alignment, and Backpressure</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/10/13/stateful-serverless-internals.html">Stateful Functions Internals: Behind the scenes of Stateful Serverless</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/09/28/release-statefun-2.2.0.html">Stateful Functions 2.2.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/09/17/release-1.11.2.html">Apache Flink 1.11.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/09/04/community-update.html">Flink Community Update - August'20</a></li>

      
        
      
    
      
      

      
      <li><a href="/2020/09/01/flink-1.11-memory-management-improvements.html">Memory Management improvements for Flink’s JobManager in Apache Flink 1.11</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/08/25/release-1.10.2.html">Apache Flink 1.10.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/08/20/flink-docker.html">The State of Flink on Docker</a></li>

      
        
      
    
      
      

      
      <li><a href="/2020/08/19/statefun.html">Monitoring and Controlling Networks of IoT Devices with Flink Stateful Functions</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/08/06/external-resource.html">Accelerating your workload with GPU and other external resources</a></li>

      
        
      
    
      
      

      
      <li><a href="/2020/08/04/pyflink-pandas-udf-support-flink.html">PyFlink: The integration of Pandas into PyFlink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/07/30/demo-fraud-detection-3.html">Advanced Flink Application Patterns Vol.3: Custom Window Processing</a></li>

      
        
      
    
      
      

      
      <li><a href="/2020/07/28/flink-sql-demo-building-e2e-streaming-application.html">Flink SQL Demo: Building an End-to-End Streaming Application</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/07/27/community-update.html">Flink Community Update - July'20</a></li>

      
        
      
    
      
      

      
      <li><a href="/2020/07/23/catalogs.html">Sharing is caring - Catalogs in Flink SQL</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/07/21/release-1.11.1.html">Apache Flink 1.11.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/07/14/application-mode.html">Application Deployment in Flink: Current State and the new Application Mode</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/07/06/release-1.11.0.html">Apache Flink 1.11.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/ecosystem/2020/06/23/flink-on-zeppelin-part2.html">Flink on Zeppelin Notebooks for Interactive Data Analysis - Part 2</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/06/15/flink-on-zeppelin-part1.html">Flink on Zeppelin Notebooks for Interactive Data Analysis - Part 1</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/06/11/community-update.html">Flink Community Update - June'20</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/06/09/release-statefun-2.1.0.html">Stateful Functions 2.1.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/05/12/release-1.10.1.html">Apache Flink 1.10.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/05/07/community-update.html">Flink Community Update - May'20</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/05/04/season-of-docs.html">Applying to Google Season of Docs 2020</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/04/24/release-1.9.3.html">Apache Flink 1.9.3 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/04/21/memory-management-improvements-flink-1.10.html">Memory Management Improvements with Apache Flink 1.10</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/04/15/flink-serialization-tuning-vol-1.html">Flink Serialization Tuning Vol. 1: Choosing your Serializer — if you can</a></li>

      
        
      
    
      
      

      
      <li><a href="/2020/04/09/pyflink-udf-support-flink.html">PyFlink: Introducing Python Support for UDFs in Flink's Table API</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/04/07/release-statefun-2.0.0.html">Stateful Functions 2.0 - An Event-driven Database on Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/04/01/community-update.html">Flink Community Update - April'20</a></li>

      
        
      
    
      
      

      
      <li><a href="/features/2020/03/27/flink-for-data-warehouse.html">Flink as Unified Engine for Modern Data Warehousing: Production-Ready Hive Integration</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/03/24/demo-fraud-detection-2.html">Advanced Flink Application Patterns Vol.2: Dynamic Updates of Application Logic</a></li>

      
        
      
    
      
      

      
      <li><a href="/ecosystem/2020/02/22/apache-beam-how-beam-runs-on-top-of-flink.html">Apache Beam: How Beam Runs on Top of Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/02/20/ddl.html">No Java Required: Configuring Sources and Sinks in SQL</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/02/11/release-1.10.0.html">Apache Flink 1.10.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/02/07/a-guide-for-unit-testing-in-apache-flink.html">A Guide for Unit Testing in Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/01/30/release-1.9.2.html">Apache Flink 1.9.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/01/29/state-unlocked-interacting-with-state-in-apache-flink.html">State Unlocked: Interacting with State in Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/01/15/demo-fraud-detection.html">Advanced Flink Application Patterns Vol.1: Case Study of a Fraud Detection System</a></li>

      
        
    </ul>
        <hr>
        <h2>2019</h2>
    <ul id="markdown-toc">
        
      
    
      
      

      
      <li><a href="/news/2019/12/11/release-1.8.3.html">Apache Flink 1.8.3 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/12/09/flink-kubernetes-kudo.html">Running Apache Flink on Kubernetes with KUDO</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/11/25/query-pulsar-streams-using-apache-flink.html">How to query Pulsar Streams using Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/10/18/release-1.9.1.html">Apache Flink 1.9.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/feature/2019/09/13/state-processor-api.html">The State Processor API: How to Read, write and modify the state of Flink applications</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/09/11/release-1.8.2.html">Apache Flink 1.8.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/09/10/community-update.html">Flink Community Update - September'19</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/08/22/release-1.9.0.html">Apache Flink 1.9.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/2019/07/23/flink-network-stack-2.html">Flink Network Stack Vol. 2: Monitoring, Metrics, and that Backpressure Thing</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/07/02/release-1.8.1.html">Apache Flink 1.8.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/2019/06/26/broadcast-state.html">A Practical Guide to Broadcast State in Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/2019/06/05/flink-network-stack.html">A Deep-Dive into Flink's Network Stack</a></li>

      
        
      
    
      
      

      
      <li><a href="/2019/05/19/state-ttl.html">State TTL in Flink 1.8.0: How to Automatically Cleanup Application State in Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/2019/05/14/temporal-tables.html">Flux capacitor, huh? Temporal Tables and Joins in Streaming SQL</a></li>

      
        
      
    
      
      

      
      <li><a href="/2019/05/03/pulsar-flink.html">When Flink & Pulsar Come Together</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/04/17/sod.html">Apache Flink's Application to Season of Docs</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/04/09/release-1.8.0.html">Apache Flink 1.8.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/features/2019/03/11/prometheus-monitoring.html">Flink and Prometheus: Cloud-native monitoring of streaming applications</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/03/06/ffsf-preview.html">What to expect from Flink Forward San Francisco 2019</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/02/25/monitoring-best-practices.html">Monitoring Apache Flink Applications 101</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/02/25/release-1.6.4.html">Apache Flink 1.6.4 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/02/15/release-1.7.2.html">Apache Flink 1.7.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/02/13/unified-batch-streaming-blink.html">Batch as a Special Case of Streaming and Alibaba's contribution of Blink</a></li>

      
        
    </ul>
        <hr>
        <h2>2018</h2>
    <ul id="markdown-toc">
        
      
    
      
      

      
      <li><a href="/news/2018/12/26/release-1.5.6.html">Apache Flink 1.5.6 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/12/22/release-1.6.3.html">Apache Flink 1.6.3 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/12/21/release-1.7.1.html">Apache Flink 1.7.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/11/30/release-1.7.0.html">Apache Flink 1.7.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/10/29/release-1.6.2.html">Apache Flink 1.6.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/10/29/release-1.5.5.html">Apache Flink 1.5.5 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/09/20/release-1.6.1.html">Apache Flink 1.6.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/09/20/release-1.5.4.html">Apache Flink 1.5.4 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/08/21/release-1.5.3.html">Apache Flink 1.5.3 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/08/09/release-1.6.0.html">Apache Flink 1.6.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/07/31/release-1.5.2.html">Apache Flink 1.5.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/07/12/release-1.5.1.html">Apache Flink 1.5.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/05/25/release-1.5.0.html">Apache Flink 1.5.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/03/15/release-1.3.3.html">Apache Flink 1.3.3 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/03/08/release-1.4.2.html">Apache Flink 1.4.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/features/2018/03/01/end-to-end-exactly-once-apache-flink.html">An Overview of End-to-End Exactly-Once Processing in Apache Flink (with Apache Kafka, too!)</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/02/15/release-1.4.1.html">Apache Flink 1.4.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/features/2018/01/30/incremental-checkpointing.html">Managing Large State in Apache Flink: An Intro to Incremental Checkpointing</a></li>

      
        
    </ul>
        <hr>
        <h2>2017</h2>
    <ul id="markdown-toc">
        
      
    
      
      

      
      <li><a href="/news/2017/12/21/2017-year-in-review.html">Apache Flink in 2017: Year in Review</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/12/12/release-1.4.0.html">Apache Flink 1.4.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/11/22/release-1.4-and-1.5-timeline.html">Looking Ahead to Apache Flink 1.4.0 and 1.5.0</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/08/05/release-1.3.2.html">Apache Flink 1.3.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/features/2017/07/04/flink-rescalable-state.html">A Deep Dive into Rescalable State in Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/06/23/release-1.3.1.html">Apache Flink 1.3.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/06/01/release-1.3.0.html">Apache Flink 1.3.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/05/16/official-docker-image.html">Introducing Docker Images for Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/04/26/release-1.2.1.html">Apache Flink 1.2.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/04/04/dynamic-tables.html">Continuous Queries on Dynamic Tables</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/03/29/table-sql-api-update.html">From Streams to Tables and Back Again: An Update on Flink's Table & SQL API</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/03/23/release-1.1.5.html">Apache Flink 1.1.5 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/02/06/release-1.2.0.html">Announcing Apache Flink 1.2.0</a></li>

      
        
    </ul>
        <hr>
        <h2>2016</h2>
    <ul id="markdown-toc">
        
      
    
      
      

      
      <li><a href="/news/2016/12/21/release-1.1.4.html">Apache Flink 1.1.4 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/12/19/2016-year-in-review.html">Apache Flink in 2016: Year in Review</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/10/12/release-1.1.3.html">Apache Flink 1.1.3 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/09/05/release-1.1.2.html">Apache Flink 1.1.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/08/24/ff16-keynotes-panels.html">Flink Forward 2016: Announcing Schedule, Keynotes, and Panel Discussion</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/08/11/release-1.1.1.html">Flink 1.1.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/08/08/release-1.1.0.html">Announcing Apache Flink 1.1.0</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/05/24/stream-sql.html">Stream Processing for Everyone with SQL and Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/05/11/release-1.0.3.html">Flink 1.0.3 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/04/22/release-1.0.2.html">Flink 1.0.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/04/14/flink-forward-announce.html">Flink Forward 2016 Call for Submissions Is Now Open</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/04/06/cep-monitoring.html">Introducing Complex Event Processing (CEP) with Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/04/06/release-1.0.1.html">Flink 1.0.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/03/08/release-1.0.0.html">Announcing Apache Flink 1.0.0</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/02/11/release-0.10.2.html">Flink 0.10.2 Released</a></li>

      
        
    </ul>
        <hr>
        <h2>2015</h2>
    <ul id="markdown-toc">
        
      
    
      
      

      
      <li><a href="/news/2015/12/18/a-year-in-review.html">Flink 2015: A year in review, and a lookout to 2016</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/12/11/storm-compatibility.html">Storm Compatibility in Apache Flink: How to run existing Storm topologies on Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/12/04/Introducing-windows.html">Introducing Stream Windows in Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/11/27/release-0.10.1.html">Flink 0.10.1 released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/11/16/release-0.10.0.html">Announcing Apache Flink 0.10.0</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/09/16/off-heap-memory.html">Off-heap Memory in Apache Flink and the curious JIT compiler</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/09/03/flink-forward.html">Announcing Flink Forward 2015</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/09/01/release-0.9.1.html">Apache Flink 0.9.1 available</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/08/24/introducing-flink-gelly.html">Introducing Gelly: Graph Processing with Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/06/24/announcing-apache-flink-0.9.0-release.html">Announcing Apache Flink 0.9.0</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/05/14/Community-update-April.html">April 2015 in the Flink community</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/05/11/Juggling-with-Bits-and-Bytes.html">Juggling with Bits and Bytes</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/04/13/release-0.9.0-milestone1.html">Announcing Flink 0.9.0-milestone1 preview release</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/04/07/march-in-flink.html">March 2015 in the Flink community</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/03/13/peeking-into-Apache-Flinks-Engine-Room.html">Peeking into Apache Flink's Engine Room</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/03/02/february-2015-in-flink.html">February 2015 in the Flink community</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/02/09/streaming-example.html">Introducing Flink Streaming</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/02/04/january-in-flink.html">January 2015 in the Flink community</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/01/21/release-0.8.html">Apache Flink 0.8.0 available</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/01/06/december-in-flink.html">December 2014 in the Flink community</a></li>

      
        
    </ul>
        <hr>
        <h2>2014</h2>
    <ul id="markdown-toc">
        
      
    
      
      

      
      <li><a href="/news/2014/11/18/hadoop-compatibility.html">Hadoop Compatibility in Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2014/11/04/release-0.7.0.html">Apache Flink 0.7.0 available</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2014/10/03/upcoming_events.html">Upcoming Events</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2014/09/26/release-0.6.1.html">Apache Flink 0.6.1 available</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2014/08/26/release-0.6.html">Apache Flink 0.6 available</a></li>

      
    </ul>
      
    
  </div>
</div>
      </div>
    </div>

    <hr />

    <div class="row">
      <div class="footer text-center col-sm-12">
        <p>Copyright © 2014-2021 <a href="http://apache.org">The Apache Software Foundation</a>. All Rights Reserved.</p>
        <p>Apache Flink, Flink®, Apache®, the squirrel logo, and the Apache feather logo are either registered trademarks or trademarks of The Apache Software Foundation.</p>
        <p><a href="/privacy-policy.html">Privacy Policy</a> &middot; <a href="/blog/feed.xml">RSS feed</a></p>
      </div>
    </div>
    </div><!-- /.container -->

    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="/js/jquery.matchHeight-min.js"></script>
    <script src="/js/bootstrap.min.js"></script>
    <script src="/js/codetabs.js"></script>
    <script src="/js/stickysidebar.js"></script>

    <!-- Google Analytics -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-52545728-1', 'auto');
      ga('send', 'pageview');
    </script>
  </body>
</html>

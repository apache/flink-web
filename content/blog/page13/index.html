<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Apache Flink: Blog</title>
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">

    <!-- Bootstrap -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">
    <link rel="stylesheet" href="/css/flink.css">
    <link rel="stylesheet" href="/css/syntax.css">

    <!-- Blog RSS feed -->
    <link href="/blog/feed.xml" rel="alternate" type="application/rss+xml" title="Apache Flink Blog: RSS feed" />

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <!-- We need to load Jquery in the header for custom google analytics event tracking-->
    <script src="/js/jquery.min.js"></script>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>  
    

    <!-- Main content. -->
    <div class="container">
    <div class="row">

      
     <div id="sidebar" class="col-sm-3">
        

<!-- Top navbar. -->
    <nav class="navbar navbar-default">
        <!-- The logo. -->
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <div class="navbar-logo">
            <a href="/">
              <img alt="Apache Flink" src="/img/flink-header-logo.svg" width="147px" height="73px">
            </a>
          </div>
        </div><!-- /.navbar-header -->

        <!-- The navigation links. -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
          <ul class="nav navbar-nav navbar-main">

            <!-- First menu section explains visitors what Flink is -->

            <!-- What is Stream Processing? -->
            <!--
            <li><a href="/streamprocessing1.html">What is Stream Processing?</a></li>
            -->

            <!-- What is Flink? -->
            <li><a href="/flink-architecture.html">What is Apache Flink?</a></li>

            

            <!-- What is Stateful Functions? -->

            <li><a href="/stateful-functions.html">What is Stateful Functions?</a></li>

            <!-- Use cases -->
            <li><a href="/usecases.html">Use Cases</a></li>

            <!-- Powered by -->
            <li><a href="/poweredby.html">Powered By</a></li>


            &nbsp;
            <!-- Second menu section aims to support Flink users -->

            <!-- Downloads -->
            <li><a href="/downloads.html">Downloads</a></li>

            <!-- Getting Started -->
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#">Getting Started<span class="caret"></span></a>
              <ul class="dropdown-menu">
                <li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/try-flink/index.html" target="_blank">With Flink <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2/getting-started/project-setup.html" target="_blank">With Flink Stateful Functions <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="/training.html">Training Course</a></li>
              </ul>
            </li>

            <!-- Documentation -->
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#">Documentation<span class="caret"></span></a>
              <ul class="dropdown-menu">
                <li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12" target="_blank">Flink 1.12 (Latest stable release) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://ci.apache.org/projects/flink/flink-docs-master" target="_blank">Flink Master (Latest Snapshot) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2" target="_blank">Flink Stateful Functions 2.2 (Latest stable release) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://ci.apache.org/projects/flink/flink-statefun-docs-master" target="_blank">Flink Stateful Functions Master (Latest Snapshot) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
              </ul>
            </li>

            <!-- getting help -->
            <li><a href="/gettinghelp.html">Getting Help</a></li>

            <!-- Blog -->
            <li class="active"><a href="/blog/"><b>Flink Blog</b></a></li>


            <!-- Flink-packages -->
            <li>
              <a href="https://flink-packages.org" target="_blank">flink-packages.org <small><span class="glyphicon glyphicon-new-window"></span></small></a>
            </li>
            &nbsp;

            <!-- Third menu section aim to support community and contributors -->

            <!-- Community -->
            <li><a href="/community.html">Community &amp; Project Info</a></li>

            <!-- Roadmap -->
            <li><a href="/roadmap.html">Roadmap</a></li>

            <!-- Contribute -->
            <li><a href="/contributing/how-to-contribute.html">How to Contribute</a></li>
            

            <!-- GitHub -->
            <li>
              <a href="https://github.com/apache/flink" target="_blank">Flink on GitHub <small><span class="glyphicon glyphicon-new-window"></span></small></a>
            </li>

            &nbsp;

            <!-- Language Switcher -->
            <li>
              
                
                  <!-- link to the Chinese home page when current is blog page -->
                  <a href="/zh">中文版</a>
                
              
            </li>

          </ul>

          <style>
            .smalllinks:link {
              display: inline-block !important; background: none; padding-top: 0px; padding-bottom: 0px; padding-right: 0px; min-width: 75px;
            }
          </style>

          <ul class="nav navbar-nav navbar-bottom">
          <hr />

            <!-- Twitter -->
            <li><a href="https://twitter.com/apacheflink" target="_blank">@ApacheFlink <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

            <!-- Visualizer -->
            <li class=" hidden-md hidden-sm"><a href="/visualizer/" target="_blank">Plan Visualizer <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

            <li >
                  <a href="/security.html">Flink Security</a>
            </li>

          <hr />

            <li><a href="https://apache.org" target="_blank">Apache Software Foundation <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

            <li>

              <a class="smalllinks" href="https://www.apache.org/licenses/" target="_blank">License</a> <small><span class="glyphicon glyphicon-new-window"></span></small>

              <a class="smalllinks" href="https://www.apache.org/security/" target="_blank">Security</a> <small><span class="glyphicon glyphicon-new-window"></span></small>

              <a class="smalllinks" href="https://www.apache.org/foundation/sponsorship.html" target="_blank">Donate</a> <small><span class="glyphicon glyphicon-new-window"></span></small>

              <a class="smalllinks" href="https://www.apache.org/foundation/thanks.html" target="_blank">Thanks</a> <small><span class="glyphicon glyphicon-new-window"></span></small>
            </li>

          </ul>
        </div><!-- /.navbar-collapse -->
    </nav>

      </div>
      <div class="col-sm-9">
      <h1>Blog</h1>
<hr />

<div class="row">
  <div class="col-sm-8">
    <!-- Blog posts -->
    
    <article>
      <h2 class="blog-title"><a href="/news/2016/03/08/release-1.0.0.html">Announcing Apache Flink 1.0.0</a></h2>

      <p>08 Mar 2016
      </p>

      <p><p>The Apache Flink community is pleased to announce the availability of the 1.0.0 release. The community put significant effort into improving and extending Apache Flink since the last release, focusing on improving the experience of writing and executing data stream processing pipelines in production.</p>

<center>
<img src="/img/blog/flink-1.0.png" style="height:200px;margin:15px" />
</center>

<p>Flink version 1.0.0 marks the beginning of the 1.X.X series of releases, which will maintain backwards compatibility with 1.0.0. This means that applications written against stable APIs of Flink 1.0.0 will compile and run with all Flink versions in the 1. series. This is the first time we are formally guaranteeing compatibility in Flink’s history, and we therefore see this release as a major milestone of the project, perhaps the most important since graduation as a top-level project.</p>

<p>Apart from backwards compatibility, Flink 1.0.0 brings a variety of new user-facing features, as well as tons of bug fixes. About 64 contributors provided bug fixes, improvements, and new features such that in total more than 450 JIRA issues could be resolved.</p>

<p>We encourage everyone to <a href="http://flink.apache.org/downloads.html">download the release</a> and <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.0/">check out the documentation</a>. Feedback through the Flink <a href="http://flink.apache.org/community.html#mailing-lists">mailing lists</a> is, as always, very welcome!</p>

<h2 id="interface-stability-annotations">Interface stability annotations</h2>

<p>Flink 1.0.0 introduces interface stability annotations for API classes and methods. Interfaces defined as <code>@Public</code> are guaranteed to remain stable across all releases of the 1.x series. The <code>@PublicEvolving</code> annotation marks API features that may be subject to change in future versions.</p>

<p>Flink’s stability annotations will help users to implement applications that compile and execute unchanged against future versions of Flink 1.x. This greatly reduces the complexity for users when upgrading to a newer Flink release.</p>

<h2 id="out-of-core-state-support">Out-of-core state support</h2>

<p>Flink 1.0.0 adds a new state backend that uses RocksDB to store state (both windows and user-defined key-value state). <a href="http://rocksdb.org/">RocksDB</a> is an embedded key/value store database, originally developed by Facebook.
When using this backend, active state in streaming programs can grow well beyond memory. The RocksDB files are stored in a distributed file system such as HDFS or S3 for backups.</p>

<h2 id="savepoints-and-version-upgrades">Savepoints and version upgrades</h2>

<p>Savepoints are checkpoints of the state of a running streaming job that can be manually triggered by the user while the job is running. Savepoints solve several production headaches, including code upgrades (both application and framework), cluster maintenance and migration, A/B testing and what-if scenarios, as well as testing and debugging. Read more about savepoints at the <a href="http://data-artisans.com/how-apache-flink-enables-new-streaming-applications/">data Artisans blog</a>.</p>

<h2 id="library-for-complex-event-processing-cep">Library for Complex Event Processing (CEP)</h2>

<p>Complex Event Processing has been one of the oldest and more important use cases from stream processing. The new CEP functionality in Flink allows you to use a distributed general-purpose stream processor instead of a specialized CEP system to detect complex patterns in event streams. Get started with <a href="https://ci.apache.org/projects/flink/flink-docs-master/apis/streaming/libs/cep.html">CEP on Flink</a>.</p>

<h2 id="enhanced-monitoring-interface-job-submission-checkpoint-statistics-and-backpressure-monitoring">Enhanced monitoring interface: job submission, checkpoint statistics and backpressure monitoring</h2>

<p>The web interface now allows users to submit jobs. Previous Flink releases had a separate service for submitting jobs. The new interface is part of the JobManager frontend. It also works on YARN now.</p>

<p>Backpressure monitoring allows users to trigger a sampling mechanism which analyzes the time operators are waiting for new network buffers. When senders are spending most of their time for new network buffers, they are experiencing backpressure from their downstream operators. Many users requested this feature for understanding bottlenecks in both batch and streaming applications.</p>

<h2 id="improved-checkpointing-control-and-monitoring">Improved checkpointing control and monitoring</h2>

<p>The checkpointing has been extended by a more fine-grained control mechanism: In previous versions, new checkpoints were triggered independent of the speed at which old checkpoints completed. This can lead to situations where new checkpoints are piling up, because they are triggered too frequently.</p>

<p>The checkpoint coordinator now exposes statistics through our REST monitoring API and the web interface. Users can review the checkpoint size and duration on a per-operator basis and see the last completed checkpoints. This is helpful for identifying performance issues, such as processing slowdown by the checkpoints.</p>

<h2 id="improved-kafka-connector-and-support-for-kafka-09">Improved Kafka connector and support for Kafka 0.9</h2>

<p>Flink 1.0 supports both Kafka 0.8 and 0.9. With the new release, Flink exposes Kafka metrics for the producers and the 0.9 consumer through Flink’s accumulator system. We also enhanced the existing connector for Kafka 0.8, allowing users to subscribe to multiple topics in one source.</p>

<h2 id="changelog-and-known-issues">Changelog and known issues</h2>

<p>This release resolves more than 450 issues, including bug fixes, improvements, and new features. See the <a href="/blog/release_1.0.0-changelog_known_issues.html#changelog">complete changelog</a> and <a href="/blog/release_1.0.0-changelog_known_issues.html#known-issues">known issues</a>.</p>

<h2 id="list-of-contributors">List of contributors</h2>

<ul>
  <li>Abhishek Agarwal</li>
  <li>Ajay Bhat</li>
  <li>Aljoscha Krettek</li>
  <li>Andra Lungu</li>
  <li>Andrea Sella</li>
  <li>Chesnay Schepler</li>
  <li>Chiwan Park</li>
  <li>Daniel Pape</li>
  <li>Fabian Hueske</li>
  <li>Filipe Correia</li>
  <li>Frederick F. Kautz IV</li>
  <li>Gabor Gevay</li>
  <li>Gabor Horvath</li>
  <li>Georgios Andrianakis</li>
  <li>Greg Hogan</li>
  <li>Gyula Fora</li>
  <li>Henry Saputra</li>
  <li>Hilmi Yildirim</li>
  <li>Hubert Czerpak</li>
  <li>Jark Wu</li>
  <li>Johannes</li>
  <li>Jun Aoki</li>
  <li>Jun Aoki</li>
  <li>Kostas Kloudas</li>
  <li>Li Chengxiang</li>
  <li>Lun Gao</li>
  <li>Martin Junghanns</li>
  <li>Martin Liesenberg</li>
  <li>Matthias J. Sax</li>
  <li>Maximilian Michels</li>
  <li>Márton Balassi</li>
  <li>Nick Dimiduk</li>
  <li>Niels Basjes</li>
  <li>Omer Katz</li>
  <li>Paris Carbone</li>
  <li>Patrice Freydiere</li>
  <li>Peter Vandenabeele</li>
  <li>Piotr Godek</li>
  <li>Prez Cannady</li>
  <li>Robert Metzger</li>
  <li>Romeo Kienzler</li>
  <li>Sachin Goel</li>
  <li>Saumitra Shahapure</li>
  <li>Sebastian Klemke</li>
  <li>Stefano Baghino</li>
  <li>Stephan Ewen</li>
  <li>Stephen Samuel</li>
  <li>Subhobrata Dey</li>
  <li>Suneel Marthi</li>
  <li>Ted Yu</li>
  <li>Theodore Vasiloudis</li>
  <li>Till Rohrmann</li>
  <li>Timo Walther</li>
  <li>Trevor Grant</li>
  <li>Ufuk Celebi</li>
  <li>Ulf Karlsson</li>
  <li>Vasia Kalavri</li>
  <li>fversaci</li>
  <li>madhukar</li>
  <li>qingmeng.wyh</li>
  <li>ramkrishna</li>
  <li>rtudoran</li>
  <li>sahitya-pavurala</li>
  <li>zhangminglei</li>
</ul>
</p>

      <p><a href="/news/2016/03/08/release-1.0.0.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    
    <article>
      <h2 class="blog-title"><a href="/news/2016/02/11/release-0.10.2.html">Flink 0.10.2 Released</a></h2>

      <p>11 Feb 2016
      </p>

      <p><p>Today, the Flink community released Flink version <strong>0.10.2</strong>, the second bugfix release of the 0.10 series.</p>

<p>We <strong>recommend all users updating to this release</strong> by bumping the version of your Flink dependencies to <code>0.10.2</code> and updating the binaries on the server.</p>

<h2 id="issues-fixed">Issues fixed</h2>

<ul>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-3242">FLINK-3242</a>: Adjust StateBackendITCase for 0.10 signatures of state backends</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-3236">FLINK-3236</a>: Flink user code classloader as parent classloader from Flink core classes</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2962">FLINK-2962</a>: Cluster startup script refers to unused variable</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-3151">FLINK-3151</a>: Downgrade to Netty version 4.0.27.Final</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-3224">FLINK-3224</a>: Call setInputType() on output formats that implement InputTypeConfigurable</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-3218">FLINK-3218</a>: Fix overriding of user parameters when merging Hadoop configurations</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-3189">FLINK-3189</a>: Fix argument parsing of CLI client INFO action</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-3176">FLINK-3176</a>: Improve documentation for window apply</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-3185">FLINK-3185</a>: Log error on failure during recovery</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-3185">FLINK-3185</a>: Don’t swallow test failure Exception</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-3147">FLINK-3147</a>: Expose HadoopOutputFormatBase fields as protected</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-3145">FLINK-3145</a>: Pin Kryo version of transitive dependencies</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-3143">FLINK-3143</a>: Update Closure Cleaner’s ASM references to ASM5</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-3136">FLINK-3136</a>: Fix shaded imports in ClosureCleaner.scala</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-3108">FLINK-3108</a>: JoinOperator’s with() calls the wrong TypeExtractor method</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-3125">FLINK-3125</a>: Web server starts also when JobManager log files cannot be accessed.</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-3080">FLINK-3080</a>: Relax restrictions of DataStream.union()</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-3081">FLINK-3081</a>: Properly stop periodic Kafka committer</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-3082">FLINK-3082</a>: Fixed confusing error about an interface that no longer exists</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-3067">FLINK-3067</a>: Enforce zkclient 0.7 for Kafka</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-3020">FLINK-3020</a>: Set number of task slots to maximum parallelism in local execution</li>
</ul>
</p>

      <p><a href="/news/2016/02/11/release-0.10.2.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    
    <article>
      <h2 class="blog-title"><a href="/news/2015/12/18/a-year-in-review.html">Flink 2015: A year in review, and a lookout to 2016</a></h2>

      <p>18 Dec 2015 by Robert Metzger (<a href="https://twitter.com/">@rmetzger_</a>)
      </p>

      <p><p>With 2015 ending, we thought that this would be good time to reflect on the amazing work done by the Flink community over this past year, and how much this community has grown.</p></p>

      <p><a href="/news/2015/12/18/a-year-in-review.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    
    <article>
      <h2 class="blog-title"><a href="/news/2015/12/11/storm-compatibility.html">Storm Compatibility in Apache Flink: How to run existing Storm topologies on Flink</a></h2>

      <p>11 Dec 2015 by Matthias J. Sax (<a href="https://twitter.com/">@MatthiasJSax</a>)
      </p>

      <p>In this blog post, we describe Flink's compatibility package for <a href="https://storm.apache.org">Apache Storm</a> that allows to embed Spouts (sources) and Bolts (operators) in a regular Flink streaming job. Furthermore, the compatibility package provides a Storm compatible API in order to execute whole Storm topologies with (almost) no code adaption.</p>

      <p><a href="/news/2015/12/11/storm-compatibility.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    
    <article>
      <h2 class="blog-title"><a href="/news/2015/12/04/Introducing-windows.html">Introducing Stream Windows in Apache Flink</a></h2>

      <p>04 Dec 2015 by Fabian Hueske (<a href="https://twitter.com/">@fhueske</a>)
      </p>

      <p><p>The data analysis space is witnessing an evolution from batch to stream processing for many use cases. Although batch can be handled as a special case of stream processing, analyzing never-ending streaming data often requires a shift in the mindset and comes with its own terminology (for example, “windowing” and “at-least-once”/”exactly-once” processing). This shift and the new terminology can be quite confusing for people being new to the space of stream processing. Apache Flink is a production-ready stream processor with an easy-to-use yet very expressive API to define advanced stream analysis programs. Flink's API features very flexible window definitions on data streams which let it stand out among other open source stream processors.</p>
<p>In this blog post, we discuss the concept of windows for stream processing, present Flink's built-in windows, and explain its support for custom windowing semantics.</p></p>

      <p><a href="/news/2015/12/04/Introducing-windows.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    
    <article>
      <h2 class="blog-title"><a href="/news/2015/11/27/release-0.10.1.html">Flink 0.10.1 released</a></h2>

      <p>27 Nov 2015
      </p>

      <p><p>Today, the Flink community released the first bugfix release of the 0.10 series of Flink.</p>

<p>We recommend all users updating to this release, by bumping the version of your Flink dependencies and updating the binaries on the server.</p>

<h2 id="issues-fixed">Issues fixed</h2>

<ul class="list-unstyled">
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-2879">FLINK-2879</a>] -         Links in documentation are broken
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-2938">FLINK-2938</a>] -         Streaming docs not in sync with latest state changes
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-2942">FLINK-2942</a>] -         Dangling operators in web UI&#39;s program visualization (non-deterministic)
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-2967">FLINK-2967</a>] -         TM address detection might not always detect the right interface on slow networks / overloaded JMs
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-2977">FLINK-2977</a>] -         Cannot access HBase in a Kerberos secured Yarn cluster
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-2987">FLINK-2987</a>] -         Flink 0.10 fails to start on YARN 2.6.0
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-2989">FLINK-2989</a>] -         Job Cancel button doesn&#39;t work on Yarn
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3005">FLINK-3005</a>] -         Commons-collections object deserialization remote command execution vulnerability
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3011">FLINK-3011</a>] -         Cannot cancel failing/restarting streaming job from the command line
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3019">FLINK-3019</a>] -         CLI does not list running/restarting jobs
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3020">FLINK-3020</a>] -         Local streaming execution: set number of task manager slots to the maximum parallelism
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3024">FLINK-3024</a>] -         TimestampExtractor Does not Work When returning Long.MIN_VALUE
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3032">FLINK-3032</a>] -         Flink does not start on Hadoop 2.7.1 (HDP), due to class conflict
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3043">FLINK-3043</a>] -         Kafka Connector description in Streaming API guide is wrong/outdated
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3047">FLINK-3047</a>] -         Local batch execution: set number of task manager slots to the maximum parallelism
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3052">FLINK-3052</a>] -         Optimizer does not push properties out of bulk iterations
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-2966">FLINK-2966</a>] -         Improve the way job duration is reported on web frontend.
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-2974">FLINK-2974</a>] -         Add periodic offset commit to Kafka Consumer if checkpointing is disabled
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3028">FLINK-3028</a>] -         Cannot cancel restarting job via web frontend
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3040">FLINK-3040</a>] -         Add docs describing how to configure State Backends
</li>
<li>[<a href="https://issues.apache.org/jira/browse/FLINK-3041">FLINK-3041</a>] -         Twitter Streaming Description section of Streaming Programming guide refers to an incorrect example &#39;TwitterLocal&#39;
</li>
</ul>

</p>

      <p><a href="/news/2015/11/27/release-0.10.1.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    
    <article>
      <h2 class="blog-title"><a href="/news/2015/11/16/release-0.10.0.html">Announcing Apache Flink 0.10.0</a></h2>

      <p>16 Nov 2015
      </p>

      <p><p>The Apache Flink community is pleased to announce the availability of the 0.10.0 release. The community put significant effort into improving and extending Apache Flink since the last release, focusing on data stream processing and operational features. About 80 contributors provided bug fixes, improvements, and new features such that in total more than 400 JIRA issues could be resolved.</p>

<p>For Flink 0.10.0, the focus of the community was to graduate the DataStream API from beta and to evolve Apache Flink into a production-ready stream data processor with a competitive feature set. These efforts resulted in support for event-time and out-of-order streams, exactly-once guarantees in the case of failures, a very flexible windowing mechanism, sophisticated operator state management, and a highly-available cluster operation mode. Flink 0.10.0 also brings a new monitoring dashboard with real-time system and job monitoring capabilities. Both batch and streaming modes of Flink benefit from the new high availability and improved monitoring features. Needless to say that Flink 0.10.0 includes many more features, improvements, and bug fixes.</p>

<p>We encourage everyone to <a href="/downloads.html">download the release</a> and <a href="https://ci.apache.org/projects/flink/flink-docs-release-0.10/">check out the documentation</a>. Feedback through the Flink <a href="/community.html#mailing-lists">mailing lists</a> is, as always, very welcome!</p>

<h2 id="new-features">New Features</h2>

<h3 id="event-time-stream-processing">Event-time Stream Processing</h3>

<p>Many stream processing applications consume data from sources that produce events with associated timestamps such as sensor or user-interaction events. Very often, events have to be collected from several sources such that it is usually not guaranteed that events arrive in the exact order of their timestamps at the stream processor. Consequently, stream processors must take out-of-order elements into account in order to produce results which are correct and consistent with respect to the timestamps of the events. With release 0.10.0, Apache Flink supports event-time processing as well as ingestion-time and processing-time processing. See <a href="https://issues.apache.org/jira/browse/FLINK-2674">FLINK-2674</a> for details.</p>

<h3 id="stateful-stream-processing">Stateful Stream Processing</h3>

<p>Operators that maintain and update state are a common pattern in many stream processing applications. Since streaming applications tend to run for a very long time, operator state can become very valuable and impossible to recompute. In order to enable fault-tolerance, operator state must be backed up to persistent storage in regular intervals. Flink 0.10.0 offers flexible interfaces to define, update, and query operator state and hooks to connect various state backends.</p>

<h3 id="highly-available-cluster-operations">Highly-available Cluster Operations</h3>

<p>Stream processing applications may be live for months. Therefore, a production-ready stream processor must be highly-available and continue to process data even in the face of failures. With release 0.10.0, Flink supports high availability modes for standalone cluster and <a href="https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html">YARN</a> setups, eliminating any single point of failure. In this mode, Flink relies on <a href="https://zookeeper.apache.org">Apache Zookeeper</a> for leader election and persisting small sized meta-data of running jobs. You can <a href="https://ci.apache.org/projects/flink/flink-docs-release-0.10/setup/jobmanager_high_availability.html">check out the documentation</a> to see how to enable high availability. See <a href="https://issues.apache.org/jira/browse/FLINK-2287">FLINK-2287</a> for details.</p>

<h3 id="graduated-datastream-api">Graduated DataStream API</h3>

<p>The DataStream API was revised based on user feedback and with foresight for upcoming features and graduated from beta status to fully supported. The most obvious changes are related to the methods for stream partitioning and window operations. The new windowing system is based on the concepts of window assigners, triggers, and evictors, inspired by the <a href="http://www.vldb.org/pvldb/vol8/p1792-Akidau.pdf">Dataflow Model</a>. The new API is fully described in the <a href="https://ci.apache.org/projects/flink/flink-docs-release-0.10/apis/streaming_guide.html">DataStream API documentation</a>. This <a href="https://cwiki.apache.org/confluence/display/FLINK/Migration+Guide%3A+0.9.x+to+0.10.x">migration guide</a> will help to port your Flink 0.9 DataStream programs to the revised API of Flink 0.10.0. See <a href="https://issues.apache.org/jira/browse/FLINK-2674">FLINK-2674</a> and <a href="https://issues.apache.org/jira/browse/FLINK-2877">FLINK-2877</a> for details.</p>

<h3 id="new-connectors-for-data-streams">New Connectors for Data Streams</h3>

<p>Apache Flink 0.10.0 features DataStream sources and sinks for many common data producers and stores. This includes an exactly-once rolling file sink which supports any file system, including HDFS, local FS, and S3. We also updated the <a href="https://kafka.apache.org">Apache Kafka</a> producer to use the new producer API, and added a connectors for <a href="https://github.com/elastic/elasticsearch">ElasticSearch</a> and <a href="https://nifi.apache.org">Apache Nifi</a>. More connectors for DataStream programs will be added by the community in the future. See the following JIRA issues for details <a href="https://issues.apache.org/jira/browse/FLINK-2583">FLINK-2583</a>, <a href="https://issues.apache.org/jira/browse/FLINK-2386">FLINK-2386</a>, <a href="https://issues.apache.org/jira/browse/FLINK-2372">FLINK-2372</a>, <a href="https://issues.apache.org/jira/browse/FLINK-2740">FLINK-2740</a>, and <a href="https://issues.apache.org/jira/browse/FLINK-2558">FLINK-2558</a>.</p>

<h3 id="new-web-dashboard--real-time-monitoring">New Web Dashboard &amp; Real-time Monitoring</h3>

<p>The 0.10.0 release features a newly designed and significantly improved monitoring dashboard for Apache Flink. The new dashboard visualizes the progress of running jobs and shows real-time statistics of processed data volumes and record counts. Moreover, it gives access to resource usage and JVM statistics of TaskManagers including JVM heap usage and garbage collection details. The following screenshot shows the job view of the new dashboard.</p>

<center>
<img src="/img/blog/new-dashboard-screenshot.png" style="width:90%;margin:15px" />
</center>

<p>The web server that provides all monitoring statistics has been designed with a REST interface allowing other systems to also access the internal system metrics. See <a href="https://issues.apache.org/jira/browse/FLINK-2357">FLINK-2357</a> for details.</p>

<h3 id="off-heap-managed-memory">Off-heap Managed Memory</h3>

<p>Flink’s internal operators (such as its sort algorithm and hash tables) write data to and read data from managed memory to achieve memory-safe operations and reduce garbage collection overhead. Until version 0.10.0, managed memory was allocated only from JVM heap memory. With this release, managed memory can also be allocated from off-heap memory. This will facilitate shorter TaskManager start-up times as well as reduce garbage collection pressure. See <a href="https://ci.apache.org/projects/flink/flink-docs-release-0.10/setup/config.html#managed-memory">the documentation</a> to learn how to configure managed memory on off-heap memory. JIRA issue <a href="https://issues.apache.org/jira/browse/FLINK-1320">FLINK-1320</a> contains further details.</p>

<h3 id="outer-joins">Outer Joins</h3>

<p>Outer joins have been one of the most frequently requested features for Flink’s <a href="https://ci.apache.org/projects/flink/flink-docs-release-0.10/apis/programming_guide.html">DataSet API</a>. Although there was a workaround to implement outer joins as CoGroup function, it had significant drawbacks including added code complexity and not being fully memory-safe. With release 0.10.0, Flink adds native support for <a href="https://ci.apache.org/projects/flink/flink-docs-release-0.10/apis/dataset_transformations.html#outerjoin">left, right, and full outer joins</a> to the DataSet API. All outer joins are backed by a memory-safe operator implementation that leverages Flink’s managed memory. See <a href="https://issues.apache.org/jira/browse/FLINK-687">FLINK-687</a> and <a href="https://issues.apache.org/jira/browse/FLINK-2107">FLINK-2107</a> for details.</p>

<h3 id="gelly-major-improvements-and-scala-api">Gelly: Major Improvements and Scala API</h3>

<p><a href="https://ci.apache.org/projects/flink/flink-docs-release-0.10/libs/gelly_guide.html">Gelly</a> is Flink’s API and library for processing and analyzing large-scale graphs. Gelly was introduced with release 0.9.0 and has been very well received by users and contributors. Based on user feedback, Gelly has been improved since then. In addition, Flink 0.10.0 introduces a Scala API for Gelly. See <a href="https://issues.apache.org/jira/browse/FLINK-2857">FLINK-2857</a> and <a href="https://issues.apache.org/jira/browse/FLINK-1962">FLINK-1962</a> for details.</p>

<h2 id="more-improvements-and-fixes">More Improvements and Fixes</h2>

<p>The Flink community resolved more than 400 issues. The following list is a selection of new features and fixed bugs.</p>

<ul>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-1851">FLINK-1851</a> Java Table API does not support Casting</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2152">FLINK-2152</a> Provide zipWithIndex utility in flink-contrib</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2158">FLINK-2158</a> NullPointerException in DateSerializer.</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2240">FLINK-2240</a> Use BloomFilter to minimize probe side records which are spilled to disk in Hybrid-Hash-Join</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2533">FLINK-2533</a> Gap based random sample optimization</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2555">FLINK-2555</a> Hadoop Input/Output Formats are unable to access secured HDFS clusters</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2565">FLINK-2565</a> Support primitive arrays as keys</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2582">FLINK-2582</a> Document how to build Flink with other Scala versions</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2584">FLINK-2584</a> ASM dependency is not shaded away</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2689">FLINK-2689</a> Reusing null object for joins with SolutionSet</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2703">FLINK-2703</a> Remove log4j classes from fat jar / document how to use Flink with logback</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2763">FLINK-2763</a> Bug in Hybrid Hash Join: Request to spill a partition with less than two buffers.</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2767">FLINK-2767</a> Add support Scala 2.11 to Scala shell</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2774">FLINK-2774</a> Import Java API classes automatically in Flink’s Scala shell</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2782">FLINK-2782</a> Remove deprecated features for 0.10</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2800">FLINK-2800</a> kryo serialization problem</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2834">FLINK-2834</a> Global round-robin for temporary directories</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2842">FLINK-2842</a> S3FileSystem is broken</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2874">FLINK-2874</a> Certain Avro generated getters/setters not recognized</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2895">FLINK-2895</a> Duplicate immutable object creation</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2964">FLINK-2964</a> MutableHashTable fails when spilling partitions without overflow segments</li>
</ul>

<h2 id="notice">Notice</h2>

<p>As previously announced, Flink 0.10.0 no longer supports Java 6. If you are still using Java 6, please consider upgrading to Java 8 (Java 7 ended its free support in April 2015).
Also note that some methods in the DataStream API had to be renamed as part of the API rework. For example the <code>groupBy</code> method has been renamed to <code>keyBy</code> and the windowing API changed. This <a href="https://cwiki.apache.org/confluence/display/FLINK/Migration+Guide%3A+0.9.x+to+0.10.x">migration guide</a> will help to port your Flink 0.9 DataStream programs to the revised API of Flink 0.10.0.</p>

<h2 id="contributors">Contributors</h2>

<ul>
  <li>Alexander Alexandrov</li>
  <li>Marton Balassi</li>
  <li>Enrique Bautista</li>
  <li>Faye Beligianni</li>
  <li>Bryan Bende</li>
  <li>Ajay Bhat</li>
  <li>Chris Brinkman</li>
  <li>Dmitry Buzdin</li>
  <li>Kun Cao</li>
  <li>Paris Carbone</li>
  <li>Ufuk Celebi</li>
  <li>Shivani Chandna</li>
  <li>Liang Chen</li>
  <li>Felix Cheung</li>
  <li>Hubert Czerpak</li>
  <li>Vimal Das</li>
  <li>Behrouz Derakhshan</li>
  <li>Suminda Dharmasena</li>
  <li>Stephan Ewen</li>
  <li>Fengbin Fang</li>
  <li>Gyula Fora</li>
  <li>Lun Gao</li>
  <li>Gabor Gevay</li>
  <li>Piotr Godek</li>
  <li>Sachin Goel</li>
  <li>Anton Haglund</li>
  <li>Gábor Hermann</li>
  <li>Greg Hogan</li>
  <li>Fabian Hueske</li>
  <li>Martin Junghanns</li>
  <li>Vasia Kalavri</li>
  <li>Ulf Karlsson</li>
  <li>Frederick F. Kautz</li>
  <li>Samia Khalid</li>
  <li>Johannes Kirschnick</li>
  <li>Kostas Kloudas</li>
  <li>Alexander Kolb</li>
  <li>Johann Kovacs</li>
  <li>Aljoscha Krettek</li>
  <li>Sebastian Kruse</li>
  <li>Andreas Kunft</li>
  <li>Chengxiang Li</li>
  <li>Chen Liang</li>
  <li>Andra Lungu</li>
  <li>Suneel Marthi</li>
  <li>Tamara Mendt</li>
  <li>Robert Metzger</li>
  <li>Maximilian Michels</li>
  <li>Chiwan Park</li>
  <li>Sahitya Pavurala</li>
  <li>Pietro Pinoli</li>
  <li>Ricky Pogalz</li>
  <li>Niraj Rai</li>
  <li>Lokesh Rajaram</li>
  <li>Johannes Reifferscheid</li>
  <li>Till Rohrmann</li>
  <li>Henry Saputra</li>
  <li>Matthias Sax</li>
  <li>Shiti Saxena</li>
  <li>Chesnay Schepler</li>
  <li>Peter Schrott</li>
  <li>Saumitra Shahapure</li>
  <li>Nikolaas Steenbergen</li>
  <li>Thomas Sun</li>
  <li>Peter Szabo</li>
  <li>Viktor Taranenko</li>
  <li>Kostas Tzoumas</li>
  <li>Pieter-Jan Van Aeken</li>
  <li>Theodore Vasiloudis</li>
  <li>Timo Walther</li>
  <li>Chengxuan Wang</li>
  <li>Huang Wei</li>
  <li>Dawid Wysakowicz</li>
  <li>Rerngvit Yanggratoke</li>
  <li>Nezih Yigitbasi</li>
  <li>Ted Yu</li>
  <li>Rucong Zhang</li>
  <li>Vyacheslav Zholudev</li>
  <li>Zoltán Zvara</li>
</ul>

</p>

      <p><a href="/news/2015/11/16/release-0.10.0.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    
    <article>
      <h2 class="blog-title"><a href="/news/2015/09/16/off-heap-memory.html">Off-heap Memory in Apache Flink and the curious JIT compiler</a></h2>

      <p>16 Sep 2015 by Stephan Ewen (<a href="https://twitter.com/">@stephanewen</a>)
      </p>

      <p><p>Running data-intensive code in the JVM and making it well-behaved is tricky. Systems that put billions of data objects naively onto the JVM heap face unpredictable OutOfMemoryErrors and Garbage Collection stalls. Of course, you still want to to keep your data in memory as much as possible, for speed and responsiveness of the processing applications. In that context, &quot;off-heap&quot; has become almost something like a magic word to solve these problems.</p>
<p>In this blog post, we will look at how Flink exploits off-heap memory. The feature is part of the upcoming release, but you can try it out with the latest nightly builds. We will also give a few interesting insights into the behavior for Java's JIT compiler for highly optimized methods and loops.</p></p>

      <p><a href="/news/2015/09/16/off-heap-memory.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    
    <article>
      <h2 class="blog-title"><a href="/news/2015/09/03/flink-forward.html">Announcing Flink Forward 2015</a></h2>

      <p>03 Sep 2015
      </p>

      <p><p><a href="http://2015.flink-forward.org/">Flink Forward 2015</a> is the first
conference with Flink at its center that aims to bring together the
Apache Flink community in a single place. The organizers are starting
this conference in October 12 and 13 from Berlin, the place where
Apache Flink started.</p>

<center>
<img src="/img/blog/flink-forward-banner.png" style="width:80%;margin:15px" />
</center>

<p>The <a href="http://2015.flink-forward.org/?post_type=day">conference program</a> has
been announced by the organizers and a program committee consisting of
Flink PMC members. The agenda contains talks from industry and
academia as well as a dedicated session on hands-on Flink training.</p>

<p>Some highlights of the talks include</p>

<ul>
  <li>
    <p>A keynote by <a href="http://2015.flink-forward.org/?speaker=william-vambenepe">William
Vambenepe</a>,
lead of the product management team responsible for Big Data
services on Google Cloud Platform (BigQuery, Dataflow, etc…) on
data streaming, Google Cloud Dataflow, and Apache Flink.</p>
  </li>
  <li>
    <p>Talks by several practitioners on how they are putting Flink to work
in their projects, including ResearchGate, Bouygues Telecom,
Amadeus, Telefonica, Capital One, Ericsson, and Otto Group.</p>
  </li>
  <li>
    <p>Talks on how open source projects, including Apache Mahout, Apache
SAMOA (incubating), Apache Zeppelin (incubating), Apache BigTop, and
Apache Storm integrate with Apache Flink.</p>
  </li>
  <li>
    <p>Talks by Flink committers on several aspects of the system, such as
fault tolerance, the internal runtime architecture, and others.</p>
  </li>
</ul>

<p>Check out the <a href="http://2015.flink-forward.org/?post_type=day">schedule</a> and
register for the conference.</p>

</p>

      <p><a href="/news/2015/09/03/flink-forward.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    
    <article>
      <h2 class="blog-title"><a href="/news/2015/09/01/release-0.9.1.html">Apache Flink 0.9.1 available</a></h2>

      <p>01 Sep 2015
      </p>

      <p><p>The Flink community is happy to announce that Flink 0.9.1 is now available.</p>

<p>0.9.1 is a maintenance release, which includes a lot of minor fixes across
several parts of the system. We suggest all users of Flink to work with this
latest stable version.</p>

<p><a href="/downloads.html">Download the release</a> and <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12">check out the
documentation</a>. Feedback through the Flink mailing lists
is, as always, very welcome!</p>

<p>The following <a href="https://issues.apache.org/jira/issues/?jql=project%20%3D%20FLINK%20AND%20status%20in%20(Resolved%2C%20Closed)%20AND%20fixVersion%20%3D%200.9.1">issues were fixed</a>
for this release:</p>

<ul>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-1916">FLINK-1916</a> EOFException when running delta-iteration job</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2089">FLINK-2089</a> “Buffer recycled” IllegalStateException during cancelling</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2189">FLINK-2189</a> NullPointerException in MutableHashTable</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2205">FLINK-2205</a> Confusing entries in JM Webfrontend Job Configuration section</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2229">FLINK-2229</a> Data sets involving non-primitive arrays cannot be unioned</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2238">FLINK-2238</a> Scala ExecutionEnvironment.fromCollection does not work with Sets</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2248">FLINK-2248</a> Allow disabling of sdtout logging output</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2257">FLINK-2257</a> Open and close of RichWindowFunctions is not called</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2262">FLINK-2262</a> ParameterTool API misnamed function</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2280">FLINK-2280</a> GenericTypeComparator.compare() does not respect ascending flag</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2285">FLINK-2285</a> Active policy emits elements of the last window twice</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2286">FLINK-2286</a> Window ParallelMerge sometimes swallows elements of the last window</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2293">FLINK-2293</a> Division by Zero Exception</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2298">FLINK-2298</a> Allow setting custom YARN application names through the CLI</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2347">FLINK-2347</a> Rendering problem with Documentation website</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2353">FLINK-2353</a> Hadoop mapred IOFormat wrappers do not respect JobConfigurable interface</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2356">FLINK-2356</a> Resource leak in checkpoint coordinator</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2361">FLINK-2361</a> CompactingHashTable loses entries</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2362">FLINK-2362</a> distinct is missing in DataSet API documentation</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2381">FLINK-2381</a> Possible class not found Exception on failed partition producer</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2384">FLINK-2384</a> Deadlock during partition spilling</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2386">FLINK-2386</a> Implement Kafka connector using the new Kafka Consumer API</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2394">FLINK-2394</a> HadoopOutFormat OutputCommitter is default to FileOutputCommiter</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2412">FLINK-2412</a> Race leading to IndexOutOfBoundsException when querying for buffer while releasing SpillablePartition</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2422">FLINK-2422</a> Web client is showing a blank page if “Meta refresh” is disabled in browser</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2424">FLINK-2424</a> InstantiationUtil.serializeObject(Object) does not close output stream</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2437">FLINK-2437</a> TypeExtractor.analyzePojo has some problems around the default constructor detection</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2442">FLINK-2442</a> PojoType fields not supported by field position keys</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2447">FLINK-2447</a> TypeExtractor returns wrong type info when a Tuple has two fields of the same POJO type</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2450">FLINK-2450</a> IndexOutOfBoundsException in KryoSerializer</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2460">FLINK-2460</a> ReduceOnNeighborsWithExceptionITCase failure</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2527">FLINK-2527</a> If a VertexUpdateFunction calls setNewVertexValue more than once, the MessagingFunction will only see the first value set</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2540">FLINK-2540</a> LocalBufferPool.requestBuffer gets into infinite loop</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2542">FLINK-2542</a> It should be documented that it is required from a join key to override hashCode(), when it is not a POJO</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2555">FLINK-2555</a> Hadoop Input/Output Formats are unable to access secured HDFS clusters</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2560">FLINK-2560</a> Flink-Avro Plugin cannot be handled by Eclipse</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2572">FLINK-2572</a> Resolve base path of symlinked executable</li>
  <li><a href="https://issues.apache.org/jira/browse/FLINK-2584">FLINK-2584</a> ASM dependency is not shaded away</li>
</ul>
</p>

      <p><a href="/news/2015/09/01/release-0.9.1.html">Continue reading &raquo;</a></p>
    </article>

    <hr>
    

    <!-- Pagination links -->
    
    <ul class="pager">
      <li>
      
        <a href="/blog/page12" class="previous">Previous</a>
      
      </li>
      <li>
        <span class="page_number ">Page: 13 of 15</span>
      </li>
      <li>
      
        <a href="/blog/page14" class="next">Next</a>
      
      </li>
    </ul>
    
  </div>

  <div class="col-sm-4" markdown="1">
    <!-- Blog posts by YEAR -->
    
      
      

      
    <h2>2021</h2>

    <ul id="markdown-toc">
      
      <li><a href="/2021/03/11/batch-execution-mode.html">A Rundown of Batch Execution Mode in the DataStream API</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2021/03/03/release-1.12.2.html">Apache Flink 1.12.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/2021/02/10/native-k8s-with-ha.html">How to natively deploy Flink on Kubernetes with High-Availability (HA)</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2021/01/29/release-1.10.3.html">Apache Flink 1.10.3 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2021/01/19/release-1.12.1.html">Apache Flink 1.12.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/2021/01/18/rocksdb.html">Using RocksDB State Backend in Apache Flink: When and How</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2021/01/11/batch-fine-grained-fault-tolerance.html">Exploring fine-grained recovery of bounded data sets on Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/2021/01/07/pulsar-flink-connector-270.html">What's New in the Pulsar Flink Connector 2.7.0</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2021/01/02/release-statefun-2.2.2.html">Stateful Functions 2.2.2 Release Announcement</a></li>

      
        
    </ul>
        <hr>
        <h2>2020</h2>
    <ul id="markdown-toc">
        
      
    
      
      

      
      <li><a href="/news/2020/12/18/release-1.11.3.html">Apache Flink 1.11.3 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/2020/12/15/pipelined-region-sheduling.html">Improvements in task scheduling for batch workloads in Apache Flink 1.12</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/12/10/release-1.12.0.html">Apache Flink 1.12.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/11/11/release-statefun-2.2.1.html">Stateful Functions 2.2.1 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/2020/10/15/from-aligned-to-unaligned-checkpoints-part-1.html">From Aligned to Unaligned Checkpoints - Part 1: Checkpoints, Alignment, and Backpressure</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/10/13/stateful-serverless-internals.html">Stateful Functions Internals: Behind the scenes of Stateful Serverless</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/09/28/release-statefun-2.2.0.html">Stateful Functions 2.2.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/09/17/release-1.11.2.html">Apache Flink 1.11.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/09/04/community-update.html">Flink Community Update - August'20</a></li>

      
        
      
    
      
      

      
      <li><a href="/2020/09/01/flink-1.11-memory-management-improvements.html">Memory Management improvements for Flink’s JobManager in Apache Flink 1.11</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/08/25/release-1.10.2.html">Apache Flink 1.10.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/08/20/flink-docker.html">The State of Flink on Docker</a></li>

      
        
      
    
      
      

      
      <li><a href="/2020/08/19/statefun.html">Monitoring and Controlling Networks of IoT Devices with Flink Stateful Functions</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/08/06/external-resource.html">Accelerating your workload with GPU and other external resources</a></li>

      
        
      
    
      
      

      
      <li><a href="/2020/08/04/pyflink-pandas-udf-support-flink.html">PyFlink: The integration of Pandas into PyFlink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/07/30/demo-fraud-detection-3.html">Advanced Flink Application Patterns Vol.3: Custom Window Processing</a></li>

      
        
      
    
      
      

      
      <li><a href="/2020/07/28/flink-sql-demo-building-e2e-streaming-application.html">Flink SQL Demo: Building an End-to-End Streaming Application</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/07/27/community-update.html">Flink Community Update - July'20</a></li>

      
        
      
    
      
      

      
      <li><a href="/2020/07/23/catalogs.html">Sharing is caring - Catalogs in Flink SQL</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/07/21/release-1.11.1.html">Apache Flink 1.11.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/07/14/application-mode.html">Application Deployment in Flink: Current State and the new Application Mode</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/07/06/release-1.11.0.html">Apache Flink 1.11.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/ecosystem/2020/06/23/flink-on-zeppelin-part2.html">Flink on Zeppelin Notebooks for Interactive Data Analysis - Part 2</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/06/15/flink-on-zeppelin-part1.html">Flink on Zeppelin Notebooks for Interactive Data Analysis - Part 1</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/06/11/community-update.html">Flink Community Update - June'20</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/06/09/release-statefun-2.1.0.html">Stateful Functions 2.1.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/05/12/release-1.10.1.html">Apache Flink 1.10.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/05/07/community-update.html">Flink Community Update - May'20</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/05/04/season-of-docs.html">Applying to Google Season of Docs 2020</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/04/24/release-1.9.3.html">Apache Flink 1.9.3 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/04/21/memory-management-improvements-flink-1.10.html">Memory Management Improvements with Apache Flink 1.10</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/04/15/flink-serialization-tuning-vol-1.html">Flink Serialization Tuning Vol. 1: Choosing your Serializer — if you can</a></li>

      
        
      
    
      
      

      
      <li><a href="/2020/04/09/pyflink-udf-support-flink.html">PyFlink: Introducing Python Support for UDFs in Flink's Table API</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/04/07/release-statefun-2.0.0.html">Stateful Functions 2.0 - An Event-driven Database on Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/04/01/community-update.html">Flink Community Update - April'20</a></li>

      
        
      
    
      
      

      
      <li><a href="/features/2020/03/27/flink-for-data-warehouse.html">Flink as Unified Engine for Modern Data Warehousing: Production-Ready Hive Integration</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/03/24/demo-fraud-detection-2.html">Advanced Flink Application Patterns Vol.2: Dynamic Updates of Application Logic</a></li>

      
        
      
    
      
      

      
      <li><a href="/ecosystem/2020/02/22/apache-beam-how-beam-runs-on-top-of-flink.html">Apache Beam: How Beam Runs on Top of Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/02/20/ddl.html">No Java Required: Configuring Sources and Sinks in SQL</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/02/11/release-1.10.0.html">Apache Flink 1.10.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/02/07/a-guide-for-unit-testing-in-apache-flink.html">A Guide for Unit Testing in Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/01/30/release-1.9.2.html">Apache Flink 1.9.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/01/29/state-unlocked-interacting-with-state-in-apache-flink.html">State Unlocked: Interacting with State in Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2020/01/15/demo-fraud-detection.html">Advanced Flink Application Patterns Vol.1: Case Study of a Fraud Detection System</a></li>

      
        
    </ul>
        <hr>
        <h2>2019</h2>
    <ul id="markdown-toc">
        
      
    
      
      

      
      <li><a href="/news/2019/12/11/release-1.8.3.html">Apache Flink 1.8.3 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/12/09/flink-kubernetes-kudo.html">Running Apache Flink on Kubernetes with KUDO</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/11/25/query-pulsar-streams-using-apache-flink.html">How to query Pulsar Streams using Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/10/18/release-1.9.1.html">Apache Flink 1.9.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/feature/2019/09/13/state-processor-api.html">The State Processor API: How to Read, write and modify the state of Flink applications</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/09/11/release-1.8.2.html">Apache Flink 1.8.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/09/10/community-update.html">Flink Community Update - September'19</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/08/22/release-1.9.0.html">Apache Flink 1.9.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/2019/07/23/flink-network-stack-2.html">Flink Network Stack Vol. 2: Monitoring, Metrics, and that Backpressure Thing</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/07/02/release-1.8.1.html">Apache Flink 1.8.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/2019/06/26/broadcast-state.html">A Practical Guide to Broadcast State in Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/2019/06/05/flink-network-stack.html">A Deep-Dive into Flink's Network Stack</a></li>

      
        
      
    
      
      

      
      <li><a href="/2019/05/19/state-ttl.html">State TTL in Flink 1.8.0: How to Automatically Cleanup Application State in Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/2019/05/14/temporal-tables.html">Flux capacitor, huh? Temporal Tables and Joins in Streaming SQL</a></li>

      
        
      
    
      
      

      
      <li><a href="/2019/05/03/pulsar-flink.html">When Flink & Pulsar Come Together</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/04/17/sod.html">Apache Flink's Application to Season of Docs</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/04/09/release-1.8.0.html">Apache Flink 1.8.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/features/2019/03/11/prometheus-monitoring.html">Flink and Prometheus: Cloud-native monitoring of streaming applications</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/03/06/ffsf-preview.html">What to expect from Flink Forward San Francisco 2019</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/02/25/monitoring-best-practices.html">Monitoring Apache Flink Applications 101</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/02/25/release-1.6.4.html">Apache Flink 1.6.4 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/02/15/release-1.7.2.html">Apache Flink 1.7.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2019/02/13/unified-batch-streaming-blink.html">Batch as a Special Case of Streaming and Alibaba's contribution of Blink</a></li>

      
        
    </ul>
        <hr>
        <h2>2018</h2>
    <ul id="markdown-toc">
        
      
    
      
      

      
      <li><a href="/news/2018/12/26/release-1.5.6.html">Apache Flink 1.5.6 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/12/22/release-1.6.3.html">Apache Flink 1.6.3 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/12/21/release-1.7.1.html">Apache Flink 1.7.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/11/30/release-1.7.0.html">Apache Flink 1.7.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/10/29/release-1.6.2.html">Apache Flink 1.6.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/10/29/release-1.5.5.html">Apache Flink 1.5.5 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/09/20/release-1.6.1.html">Apache Flink 1.6.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/09/20/release-1.5.4.html">Apache Flink 1.5.4 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/08/21/release-1.5.3.html">Apache Flink 1.5.3 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/08/09/release-1.6.0.html">Apache Flink 1.6.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/07/31/release-1.5.2.html">Apache Flink 1.5.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/07/12/release-1.5.1.html">Apache Flink 1.5.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/05/25/release-1.5.0.html">Apache Flink 1.5.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/03/15/release-1.3.3.html">Apache Flink 1.3.3 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/03/08/release-1.4.2.html">Apache Flink 1.4.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/features/2018/03/01/end-to-end-exactly-once-apache-flink.html">An Overview of End-to-End Exactly-Once Processing in Apache Flink (with Apache Kafka, too!)</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2018/02/15/release-1.4.1.html">Apache Flink 1.4.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/features/2018/01/30/incremental-checkpointing.html">Managing Large State in Apache Flink: An Intro to Incremental Checkpointing</a></li>

      
        
    </ul>
        <hr>
        <h2>2017</h2>
    <ul id="markdown-toc">
        
      
    
      
      

      
      <li><a href="/news/2017/12/21/2017-year-in-review.html">Apache Flink in 2017: Year in Review</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/12/12/release-1.4.0.html">Apache Flink 1.4.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/11/22/release-1.4-and-1.5-timeline.html">Looking Ahead to Apache Flink 1.4.0 and 1.5.0</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/08/05/release-1.3.2.html">Apache Flink 1.3.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/features/2017/07/04/flink-rescalable-state.html">A Deep Dive into Rescalable State in Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/06/23/release-1.3.1.html">Apache Flink 1.3.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/06/01/release-1.3.0.html">Apache Flink 1.3.0 Release Announcement</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/05/16/official-docker-image.html">Introducing Docker Images for Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/04/26/release-1.2.1.html">Apache Flink 1.2.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/04/04/dynamic-tables.html">Continuous Queries on Dynamic Tables</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/03/29/table-sql-api-update.html">From Streams to Tables and Back Again: An Update on Flink's Table & SQL API</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/03/23/release-1.1.5.html">Apache Flink 1.1.5 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2017/02/06/release-1.2.0.html">Announcing Apache Flink 1.2.0</a></li>

      
        
    </ul>
        <hr>
        <h2>2016</h2>
    <ul id="markdown-toc">
        
      
    
      
      

      
      <li><a href="/news/2016/12/21/release-1.1.4.html">Apache Flink 1.1.4 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/12/19/2016-year-in-review.html">Apache Flink in 2016: Year in Review</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/10/12/release-1.1.3.html">Apache Flink 1.1.3 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/09/05/release-1.1.2.html">Apache Flink 1.1.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/08/24/ff16-keynotes-panels.html">Flink Forward 2016: Announcing Schedule, Keynotes, and Panel Discussion</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/08/11/release-1.1.1.html">Flink 1.1.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/08/08/release-1.1.0.html">Announcing Apache Flink 1.1.0</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/05/24/stream-sql.html">Stream Processing for Everyone with SQL and Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/05/11/release-1.0.3.html">Flink 1.0.3 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/04/22/release-1.0.2.html">Flink 1.0.2 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/04/14/flink-forward-announce.html">Flink Forward 2016 Call for Submissions Is Now Open</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/04/06/cep-monitoring.html">Introducing Complex Event Processing (CEP) with Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/04/06/release-1.0.1.html">Flink 1.0.1 Released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/03/08/release-1.0.0.html">Announcing Apache Flink 1.0.0</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2016/02/11/release-0.10.2.html">Flink 0.10.2 Released</a></li>

      
        
    </ul>
        <hr>
        <h2>2015</h2>
    <ul id="markdown-toc">
        
      
    
      
      

      
      <li><a href="/news/2015/12/18/a-year-in-review.html">Flink 2015: A year in review, and a lookout to 2016</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/12/11/storm-compatibility.html">Storm Compatibility in Apache Flink: How to run existing Storm topologies on Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/12/04/Introducing-windows.html">Introducing Stream Windows in Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/11/27/release-0.10.1.html">Flink 0.10.1 released</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/11/16/release-0.10.0.html">Announcing Apache Flink 0.10.0</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/09/16/off-heap-memory.html">Off-heap Memory in Apache Flink and the curious JIT compiler</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/09/03/flink-forward.html">Announcing Flink Forward 2015</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/09/01/release-0.9.1.html">Apache Flink 0.9.1 available</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/08/24/introducing-flink-gelly.html">Introducing Gelly: Graph Processing with Apache Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/06/24/announcing-apache-flink-0.9.0-release.html">Announcing Apache Flink 0.9.0</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/05/14/Community-update-April.html">April 2015 in the Flink community</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/05/11/Juggling-with-Bits-and-Bytes.html">Juggling with Bits and Bytes</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/04/13/release-0.9.0-milestone1.html">Announcing Flink 0.9.0-milestone1 preview release</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/04/07/march-in-flink.html">March 2015 in the Flink community</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/03/13/peeking-into-Apache-Flinks-Engine-Room.html">Peeking into Apache Flink's Engine Room</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/03/02/february-2015-in-flink.html">February 2015 in the Flink community</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/02/09/streaming-example.html">Introducing Flink Streaming</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/02/04/january-in-flink.html">January 2015 in the Flink community</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/01/21/release-0.8.html">Apache Flink 0.8.0 available</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2015/01/06/december-in-flink.html">December 2014 in the Flink community</a></li>

      
        
    </ul>
        <hr>
        <h2>2014</h2>
    <ul id="markdown-toc">
        
      
    
      
      

      
      <li><a href="/news/2014/11/18/hadoop-compatibility.html">Hadoop Compatibility in Flink</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2014/11/04/release-0.7.0.html">Apache Flink 0.7.0 available</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2014/10/03/upcoming_events.html">Upcoming Events</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2014/09/26/release-0.6.1.html">Apache Flink 0.6.1 available</a></li>

      
        
      
    
      
      

      
      <li><a href="/news/2014/08/26/release-0.6.html">Apache Flink 0.6 available</a></li>

      
    </ul>
      
    
  </div>
</div>
      </div>
    </div>

    <hr />

    <div class="row">
      <div class="footer text-center col-sm-12">
        <p>Copyright © 2014-2019 <a href="http://apache.org">The Apache Software Foundation</a>. All Rights Reserved.</p>
        <p>Apache Flink, Flink®, Apache®, the squirrel logo, and the Apache feather logo are either registered trademarks or trademarks of The Apache Software Foundation.</p>
        <p><a href="/privacy-policy.html">Privacy Policy</a> &middot; <a href="/blog/feed.xml">RSS feed</a></p>
      </div>
    </div>
    </div><!-- /.container -->

    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="/js/jquery.matchHeight-min.js"></script>
    <script src="/js/bootstrap.min.js"></script>
    <script src="/js/codetabs.js"></script>
    <script src="/js/stickysidebar.js"></script>

    <!-- Google Analytics -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-52545728-1', 'auto');
      ga('send', 'pageview');
    </script>
  </body>
</html>

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Apache Flink: Managing Large State in Apache Flink: An Intro to Incremental Checkpointing</title>
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">

    <!-- Bootstrap -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
    <link rel="stylesheet" href="/css/flink.css">
    <link rel="stylesheet" href="/css/syntax.css">

    <!-- Blog RSS feed -->
    <link href="/blog/feed.xml" rel="alternate" type="application/rss+xml" title="Apache Flink Blog: RSS feed" />

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <!-- We need to load Jquery in the header for custom google analytics event tracking-->
    <script src="/js/jquery.min.js"></script>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>  
    

    <!-- Main content. -->
    <div class="container">
    <div class="row">

      
     <div id="sidebar" class="col-sm-3">
        

<!-- Top navbar. -->
    <nav class="navbar navbar-default">
        <!-- The logo. -->
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <div class="navbar-logo">
            <a href="/">
              <img alt="Apache Flink" src="/img/flink-header-logo.svg" width="147px" height="73px">
            </a>
          </div>
        </div><!-- /.navbar-header -->

        <!-- The navigation links. -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
          <ul class="nav navbar-nav navbar-main">

            <!-- First menu section explains visitors what Flink is -->

            <!-- What is Stream Processing? -->
            <!--
            <li><a href="/streamprocessing1.html">What is Stream Processing?</a></li>
            -->

            <!-- What is Flink? -->
            <li><a href="/flink-architecture.html">What is Apache Flink?</a></li>

            

            <!-- Use cases -->
            <li><a href="/usecases.html">Use Cases</a></li>

            <!-- Powered by -->
            <li><a href="/poweredby.html">Powered By</a></li>

            <!-- FAQ -->
            <li><a href="/faq.html">FAQ</a></li>

            &nbsp;
            <!-- Second menu section aims to support Flink users -->

            <!-- Downloads -->
            <li><a href="/downloads.html">Downloads</a></li>

            <!-- Quickstart -->
            <li>
              <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.9/quickstart/setup_quickstart.html" target="_blank">Tutorials <small><span class="glyphicon glyphicon-new-window"></span></small></a>
            </li>

            <!-- Documentation -->
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#">Documentation<span class="caret"></span></a>
              <ul class="dropdown-menu">
                <li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.9" target="_blank">1.9 (Latest stable release) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://ci.apache.org/projects/flink/flink-docs-master" target="_blank">Master (Latest Snapshot) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
              </ul>
            </li>

            <!-- getting help -->
            <li><a href="/gettinghelp.html">Getting Help</a></li>

            <!-- Blog -->
            <li class="active"><a href="/blog/"><b>Flink Blog</b></a></li>

            &nbsp;

            <!-- Third menu section aim to support community and contributors -->

            <!-- Community -->
            <li><a href="/community.html">Community &amp; Project Info</a></li>

            <!-- Roadmap -->
            <li><a href="/roadmap.html">Roadmap</a></li>

            <!-- Contribute -->
            <li><a href="/contributing/how-to-contribute.html">How to Contribute</a></li>
            

            <!-- GitHub -->
            <li>
              <a href="https://github.com/apache/flink" target="_blank">Flink on GitHub <small><span class="glyphicon glyphicon-new-window"></span></small></a>
            </li>

            &nbsp;

            <!-- Language Switcher -->
            <li>
              
                
                  <!-- link to the Chinese home page when current is blog page -->
                  <a href="/zh">中文版</a>
                
              
            </li>

          </ul>

          <ul class="nav navbar-nav navbar-bottom">
          <hr />

            <!-- Twitter -->
            <li><a href="https://twitter.com/apacheflink" target="_blank">@ApacheFlink <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

            <!-- Visualizer -->
            <li class=" hidden-md hidden-sm"><a href="/visualizer/" target="_blank">Plan Visualizer <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

          </ul>
        </div><!-- /.navbar-collapse -->
    </nav>

      </div>
      <div class="col-sm-9">
      <div class="row-fluid">
  <div class="col-sm-12">
    <div class="row">
      <h1>Managing Large State in Apache Flink: An Intro to Incremental Checkpointing</h1>

      <article>
        <p>30 Jan 2018 Stefan Ricther (<a href="https://twitter.com/StefanRRicther">@StefanRRicther</a>) &amp; Chris Ward (<a href="https://twitter.com/chrischinch">@chrischinch</a>)</p>

<p>Apache Flink was purpose-built for <em>stateful</em> stream processing. However, what is state in a stream processing application? I defined state and stateful stream processing in a <a href="http://flink.apache.org/features/2017/07/04/flink-rescalable-state.html">previous blog post</a>, and in case you need a refresher, <em>state is defined as memory in an application’s operators that stores information about previously-seen events that you can use to influence the processing of future events</em>.</p>

<p>State is a fundamental, enabling concept in stream processing required for a majority of complex use cases. Some examples highlighted in the <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/dev/stream/state.html">Flink documentation</a>:</p>

<ul>
  <li>When an application searches for certain event patterns, the state stores the sequence of events encountered so far.</li>
  <li>When aggregating events per minute, the state holds the pending aggregates.</li>
  <li>When training a machine learning model over a stream of data points, the state holds the current version of the model parameters.</li>
</ul>

<p>However, stateful stream processing is only useful in production environments if the state is fault tolerant. “Fault tolerance” means that even if there’s a software or machine failure, the computed end-result is accurate, with no data loss or double-counting of events.</p>

<p>Flink’s fault tolerance has always been a powerful and popular feature, minimizing the impact of software or machine failure on your business and making it possible to guarantee exactly-once results from a Flink application.</p>

<p>Core to this is <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/dev/stream/checkpointing.html">checkpointing</a>, which is the mechanism Flink uses to make application state fault tolerant. A checkpoint in Flink is a global, asynchronous snapshot of application state that’s taken on a regular interval and sent to durable storage (usually, a distributed file system). In the event of a failure, Flink restarts an application using the most recently completed checkpoint as a starting point. Some Apache Flink users run applications with gigabytes or even terabytes of application state. These users reported that with such large state, creating a checkpoint was often a slow and resource intensive operation, which is why in Flink 1.3 we introduced ‘incremental checkpointing.’</p>

<p>Before incremental checkpointing, every single Flink checkpoint consisted of the full state of an application. We created the incremental checkpointing feature after we noticed that writing the full state for every checkpoint was often unnecessary, as the state changes from one checkpoint to the next were rarely that large. Incremental checkpointing instead maintains the differences (or ‘delta’) between each checkpoint and stores only the differences between the last checkpoint and the current state.</p>

<p>Incremental checkpoints can provide a significant performance improvement for jobs with a very large state. Early testing of the feature by a production user with terabytes of state shows a drop in checkpoint time from more than 3 minutes down to 30 seconds after implementing incremental checkpoints. This is because the checkpoint doesn’t need to transfer the full state to durable storage on each checkpoint.</p>

<h3 id="how-to-start">How to Start</h3>

<p>Currently, you can only use incremental checkpointing with a RocksDB state back-end, and Flink uses RocksDB’s internal backup mechanism to consolidate checkpoint data over time. As a result, the incremental checkpoint history in Flink does not grow indefinitely, and Flink eventually consumes and prunes old checkpoints automatically.</p>

<p>To enable incremental checkpointing in your application, I recommend you read the <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/ops/state/large_state_tuning.html#tuning-rocksdb">the Apache Flink documentation on checkpointing</a> for full details, but in summary, you enable checkpointing as normal, but enable incremental checkpointing in the constructor by setting the second parameter to <code>true</code>.</p>

<h4 id="java-example">Java Example</h4>

<div class="highlight"><pre><code class="language-java"><span class="n">StreamExecutionEnvironment</span> <span class="n">env</span> <span class="o">=</span> <span class="n">StreamExecutionEnvironment</span><span class="o">.</span><span class="na">getExecutionEnvironment</span><span class="o">();</span>
<span class="n">env</span><span class="o">.</span><span class="na">setStateBackend</span><span class="o">(</span><span class="k">new</span> <span class="nf">RocksDBStateBackend</span><span class="o">(</span><span class="n">filebackend</span><span class="o">,</span> <span class="kc">true</span><span class="o">));</span></code></pre></div>

<h4 id="scala-example">Scala Example</h4>

<div class="highlight"><pre><code class="language-scala"><span class="k">val</span> <span class="n">env</span> <span class="k">=</span> <span class="nc">StreamExecutionEnvironment</span><span class="o">.</span><span class="n">getExecutionEnvironment</span><span class="o">()</span>
<span class="n">env</span><span class="o">.</span><span class="n">setStateBackend</span><span class="o">(</span><span class="k">new</span> <span class="nc">RocksDBStateBackend</span><span class="o">(</span><span class="n">filebackend</span><span class="o">,</span> <span class="kc">true</span><span class="o">))</span></code></pre></div>

<p>By default, Flink retains 1 completed checkpoint, so if you need a higher number, <a href="https://ci.apache.org/projects/flink/flink-docs-master/dev/stream/state/checkpointing.html#related-config-options">you can configure it with the following flag</a>:</p>

<div class="highlight"><pre><code class="language-java"><span class="n">state</span><span class="o">.</span><span class="na">checkpoints</span><span class="o">.</span><span class="na">num</span><span class="o">-</span><span class="n">retained</span></code></pre></div>

<h3 id="how-it-works">How it Works</h3>

<p>Flink’s incremental checkpointing uses <a href="https://github.com/facebook/rocksdb/wiki/Checkpoints">RocksDB checkpoints</a> as a foundation. RocksDB is a key-value store based on ‘<a href="https://en.wikipedia.org/wiki/Log-structured_merge-tree">log-structured-merge</a>’ (LSM) trees that collects all changes in a mutable (changeable) in-memory buffer called a ‘memtable’. Any updates to the same key in the memtable replace previous values, and once the memtable is full, RocksDB writes it to disk with all entries sorted by their key and with light compression applied. Once RocksDB writes the memtable to disk it is immutable (unchangeable) and is now called a ‘sorted-string-table’ (sstable).</p>

<p>A ‘compaction’ background task merges sstables to consolidate potential duplicates for each key, and over time RocksDB deletes the original sstables, with the merged sstable containing all information from across all the other sstables.</p>

<p>On top of this, Flink tracks which sstable files RocksDB has created and deleted since the previous checkpoint, and as the sstables are immutable, Flink uses this to figure out the state changes. To do this, Flink triggers a flush in RocksDB, forcing all memtables into sstables on disk, and hard-linked in a local temporary directory. This process is synchronous to the processing pipeline, and Flink performs all further steps asynchronously and does not block processing.</p>

<p>Then Flink copies all new sstables to stable storage (e.g., HDFS, S3) to reference in the new checkpoint. Flink doesn’t copy all sstables that already existed in the previous checkpoint to stable storage but re-reference them. Any new checkpoints will no longer reference deleted files as deleted sstables in RocksDB are always the result of compaction, and it eventually replaces old tables with an sstable that is the result of a merge. This how in Flink’s incremental checkpoints can prune the checkpoint history.</p>

<p>For tracking changes between checkpoints, the uploading of consolidated tables is redundant work. Flink performs the process incrementally, and typically adds only a small overhead, so we consider this worthwhile because it allows Flink to keep a shorter history of checkpoints to consider in a recovery.</p>

<h4 id="an-example">An Example</h4>

<p><img src="/img/blog/incremental_cp_impl_example.svg" alt="Example setup" />
<em>Example setup</em></p>

<p>Take an example with a subtask of one operator that has a keyed state, and the number of retained checkpoints set at <strong>2</strong>. The columns in the figure above show the state of the local RocksDB instance for each checkpoint, the files it references, and the counts in the shared state registry after the checkpoint completes.</p>

<p>For checkpoint ‘CP 1’, the local RocksDB directory contains two sstable files, it considers these new and uploads them to stable storage using directory names that match the checkpoint name. When the checkpoint completes, Flink creates the two entries in the shared state registry and sets their counts to ‘1’. The key in the shared state registry is a composite of an operator, subtask, and the original sstable file name. The registry also keeps a mapping from the key to the file path in stable storage.</p>

<p>For checkpoint ‘CP 2’, RocksDB has created two new sstable files, and the two older ones still exist. For checkpoint ‘CP 2’, Flink adds the two new files to stable storage and can reference the previous two files. When the checkpoint completes, Flink increases the counts for all referenced files by 1.</p>

<p>For checkpoint ‘CP 3’, RocksDB’s compaction has merged <code>sstable-(1)</code>, <code>sstable-(2)</code>, and <code>sstable-(3)</code> into <code>sstable-(1,2,3)</code> and deleted the original files. This merged file contains the same information as the source files, with all duplicate entries eliminated. In addition to this merged file, <code>sstable-(4)</code> still exists and there is now a new <code>sstable-(5)</code> file. Flink adds the new <code>sstable-(1,2,3)</code> and <code>sstable-(5)</code> files to stable storage, <code>sstable-(4)</code> is re-referenced from checkpoint ‘CP 2’ and increases the counts for referenced files by 1. The older ‘CP 1’ checkpoint is now deleted as the number of retained checkpoints (2) has been reached. As part of this deletion, Flink decreases the counts for all files referenced ‘CP 1’, (<code>sstable-(1)</code> and <code>sstable-(2)</code>), by 1.</p>

<p>For checkpoint ‘CP-4’, RocksDB has merged <code>sstable-(4)</code>, <code>sstable-(5)</code>, and a new <code>sstable-(6)</code> into <code>sstable-(4,5,6)</code>. Flink adds this new table to stable storage and references it together with <code>sstable-(1,2,3)</code>, it increases the counts for <code>sstable-(1,2,3)</code> and <code>sstable-(4,5,6)</code> by 1 and then deletes ‘CP-2’ as the number of retained checkpoints has been reached. As the counts for <code>sstable-(1)</code>, <code>sstable-(2)</code>, and <code>sstable-(3)</code> have now dropped to 0, and Flink deletes them from stable storage.</p>

<h3 id="race-conditions-and-concurrent-checkpoints">Race Conditions and Concurrent Checkpoints</h3>

<p>As Flink can execute multiple checkpoints in parallel, sometimes new checkpoints start before confirming previous checkpoints as completed. Because of this, you should consider which the previous checkpoint to use as a basis for a new incremental checkpoint. Flink only references state from a checkpoint confirmed by the checkpoint coordinator so that it doesn’t unintentionally reference a deleted shared file.</p>

<h3 id="restoring-checkpoints-and-performance-considerations">Restoring Checkpoints and Performance Considerations</h3>

<p>If you enable incremental checkpointing, there are no further configuration steps needed to recover your state in case of failure. If a failure occurs, Flink’s <code>JobManager</code> tells all tasks to restore from the last completed checkpoint, be it a full or incremental checkpoint. Each <code>TaskManager</code> then downloads their share of the state from the checkpoint on the distributed file system.</p>

<p>Though the feature can lead to a substantial improvement in checkpoint time for users with a large state, there are trade-offs to consider with incremental checkpointing. Overall, the process reduces the checkpointing time during normal operations but can lead to a longer recovery time depending on the size of your state. If the cluster failure is particularly severe and the Flink <code>TaskManager</code>s have to read from multiple checkpoints, recovery can be a slower operation than when using non-incremental checkpointing. You can also no longer delete old checkpoints as newer checkpoints need them, and the history of differences between checkpoints can grow indefinitely over time. You need to plan for larger distributed storage to maintain the checkpoints and the network overhead to read from it.</p>

<p>There are some strategies for improving the convenience/performance trade-off, and I recommend you read <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/ops/state/checkpoints.html#basics-of-incremental-checkpoints">the Flink documentation</a> for more details.</p>

<p><em>This post <a href="https://data-artisans.com/blog/managing-large-state-apache-flink-incremental-checkpointing-overview" target="_blank"> originally appeared on the data Artisans blog </a>and was contributed to the Flink blog by Stefan Richter and Chris Ward.</em></p>
<link rel="canonical" href="https://data-artisans.com/blog/managing-large-state-apache-flink-incremental-checkpointing-overview" />


      </article>
    </div>

    <div class="row">
      <div id="disqus_thread"></div>
      <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'stratosphere-eu'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
             (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
      </script>
    </div>
  </div>
</div>
      </div>
    </div>

    <hr />

    <div class="row">
      <div class="footer text-center col-sm-12">
        <p>Copyright © 2014-2019 <a href="http://apache.org">The Apache Software Foundation</a>. All Rights Reserved.</p>
        <p>Apache Flink, Flink®, Apache®, the squirrel logo, and the Apache feather logo are either registered trademarks or trademarks of The Apache Software Foundation.</p>
        <p><a href="/privacy-policy.html">Privacy Policy</a> &middot; <a href="/blog/feed.xml">RSS feed</a></p>
      </div>
    </div>
    </div><!-- /.container -->

    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.matchHeight/0.7.0/jquery.matchHeight-min.js"></script>
    <script src="/js/codetabs.js"></script>
    <script src="/js/stickysidebar.js"></script>

    <!-- Google Analytics -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-52545728-1', 'auto');
      ga('send', 'pageview');
    </script>
  </body>
</html>

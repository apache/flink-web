<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Apache Flink: An Overview of End-to-End Exactly-Once Processing in Apache Flink (with Apache Kafka, too!)</title>
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">

    <!-- Bootstrap -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
    <link rel="stylesheet" href="/css/flink.css">
    <link rel="stylesheet" href="/css/syntax.css">

    <!-- Blog RSS feed -->
    <link href="/blog/feed.xml" rel="alternate" type="application/rss+xml" title="Apache Flink Blog: RSS feed" />

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <!-- We need to load Jquery in the header for custom google analytics event tracking-->
    <script src="/js/jquery.min.js"></script>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>  
    

    <!-- Main content. -->
    <div class="container">
    <div class="row">

      
     <div id="sidebar" class="col-sm-3">
        

<!-- Top navbar. -->
    <nav class="navbar navbar-default">
        <!-- The logo. -->
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <div class="navbar-logo">
            <a href="/">
              <img alt="Apache Flink" src="/img/flink-header-logo.svg" width="147px" height="73px">
            </a>
          </div>
        </div><!-- /.navbar-header -->

        <!-- The navigation links. -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
          <ul class="nav navbar-nav navbar-main">

            <!-- First menu section explains visitors what Flink is -->

            <!-- What is Stream Processing? -->
            <!--
            <li><a href="/streamprocessing1.html">What is Stream Processing?</a></li>
            -->

            <!-- What is Flink? -->
            <li><a href="/flink-architecture.html">What is Apache Flink?</a></li>

            

            <!-- What is Stateful Functions? -->

            <li><a href="/stateful-functions.html">What is Stateful Functions?</a></li>

            <!-- Use cases -->
            <li><a href="/usecases.html">Use Cases</a></li>

            <!-- Powered by -->
            <li><a href="/poweredby.html">Powered By</a></li>


            &nbsp;
            <!-- Second menu section aims to support Flink users -->

            <!-- Downloads -->
            <li><a href="/downloads.html">Downloads</a></li>

            <!-- Getting Started -->
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#">Getting Started<span class="caret"></span></a>
              <ul class="dropdown-menu">
                <li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/try-flink/index.html" target="_blank">With Flink <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2/getting-started/project-setup.html" target="_blank">With Flink Stateful Functions <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="/training.html">Training Course</a></li>
              </ul>
            </li>

            <!-- Documentation -->
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#">Documentation<span class="caret"></span></a>
              <ul class="dropdown-menu">
                <li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12" target="_blank">Flink 1.12 (Latest stable release) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://ci.apache.org/projects/flink/flink-docs-master" target="_blank">Flink Master (Latest Snapshot) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2" target="_blank">Flink Stateful Functions 2.2 (Latest stable release) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://ci.apache.org/projects/flink/flink-statefun-docs-master" target="_blank">Flink Stateful Functions Master (Latest Snapshot) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
              </ul>
            </li>

            <!-- getting help -->
            <li><a href="/gettinghelp.html">Getting Help</a></li>

            <!-- Blog -->
            <li class="active"><a href="/blog/"><b>Flink Blog</b></a></li>


            <!-- Flink-packages -->
            <li>
              <a href="https://flink-packages.org" target="_blank">flink-packages.org <small><span class="glyphicon glyphicon-new-window"></span></small></a>
            </li>
            &nbsp;

            <!-- Third menu section aim to support community and contributors -->

            <!-- Community -->
            <li><a href="/community.html">Community &amp; Project Info</a></li>

            <!-- Roadmap -->
            <li><a href="/roadmap.html">Roadmap</a></li>

            <!-- Contribute -->
            <li><a href="/contributing/how-to-contribute.html">How to Contribute</a></li>
            

            <!-- GitHub -->
            <li>
              <a href="https://github.com/apache/flink" target="_blank">Flink on GitHub <small><span class="glyphicon glyphicon-new-window"></span></small></a>
            </li>

            &nbsp;

            <!-- Language Switcher -->
            <li>
              
                
                  <!-- link to the Chinese home page when current is blog page -->
                  <a href="/zh">中文版</a>
                
              
            </li>

          </ul>

          <ul class="nav navbar-nav navbar-bottom">
          <hr />

            <!-- Twitter -->
            <li><a href="https://twitter.com/apacheflink" target="_blank">@ApacheFlink <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

            <!-- Visualizer -->
            <li class=" hidden-md hidden-sm"><a href="/visualizer/" target="_blank">Plan Visualizer <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

          <hr />

            <li><a href="https://apache.org" target="_blank">Apache Software Foundation <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

            <li>
              <style>
                .smalllinks:link {
                  display: inline-block !important; background: none; padding-top: 0px; padding-bottom: 0px; padding-right: 0px; min-width: 75px;
                }
              </style>

              <a class="smalllinks" href="https://www.apache.org/licenses/" target="_blank">License</a> <small><span class="glyphicon glyphicon-new-window"></span></small>

              <a class="smalllinks" href="https://www.apache.org/security/" target="_blank">Security</a> <small><span class="glyphicon glyphicon-new-window"></span></small>

              <a class="smalllinks" href="https://www.apache.org/foundation/sponsorship.html" target="_blank">Donate</a> <small><span class="glyphicon glyphicon-new-window"></span></small>

              <a class="smalllinks" href="https://www.apache.org/foundation/thanks.html" target="_blank">Thanks</a> <small><span class="glyphicon glyphicon-new-window"></span></small>
            </li>

          </ul>
        </div><!-- /.navbar-collapse -->
    </nav>

      </div>
      <div class="col-sm-9">
      <div class="row-fluid">
  <div class="col-sm-12">
    <div class="row">
      <h1>An Overview of End-to-End Exactly-Once Processing in Apache Flink (with Apache Kafka, too!)</h1>
      <p><i></i></p>

      <article>
        <p>01 Mar 2018 Piotr Nowojski (<a href="https://twitter.com/PiotrNowojski">@PiotrNowojski</a>) &amp; Mike Winters (<a href="https://twitter.com/wints">@wints</a>)</p>

<p><em>This post is an adaptation of <a href="https://berlin.flink-forward.org/kb_sessions/hit-me-baby-just-one-time-building-end-to-end-exactly-once-applications-with-flink/">Piotr Nowojski’s presentation from Flink Forward Berlin 2017</a>. You can find the slides and a recording of the presentation on the Flink Forward Berlin website.</em></p>

<p>Apache Flink 1.4.0, released in December 2017, introduced a significant milestone for stream processing with Flink: a new feature called <code>TwoPhaseCommitSinkFunction</code> (<a href="https://issues.apache.org/jira/browse/FLINK-7210">relevant Jira here</a>) that extracts the common logic of the two-phase commit protocol and makes it possible to build end-to-end exactly-once applications with Flink and a selection of data sources and sinks, including Apache Kafka versions 0.11 and beyond. It provides a layer of abstraction and requires a user to implement only a handful of methods to achieve end-to-end exactly-once semantics.</p>

<p>If that’s all you need to hear, let us point you <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/api/java/org/apache/flink/streaming/api/functions/sink/TwoPhaseCommitSinkFunction.html">to the relevant place in the Flink documentation</a>, where you can read about how to put <code>TwoPhaseCommitSinkFunction</code> to use.</p>

<p>But if you’d like to learn more, in this post, we’ll share an in-depth overview of the new feature and what is happening behind the scenes in Flink.</p>

<p>Throughout the rest of this post, we’ll:</p>

<ul>
  <li>Describe the role of Flink’s checkpoints for guaranteeing exactly-once results within a Flink application.</li>
  <li>Show how Flink interacts with data sources and data sinks via the two-phase commit protocol to deliver <em>end-to-end</em> exactly-once guarantees.</li>
  <li>Walk through a simple example on how to use <code>TwoPhaseCommitSinkFunction</code> to implement an exactly-once file sink.</li>
</ul>

<h2 id="exactly-once-semantics-within-an-apache-flink-application">Exactly-once Semantics Within an Apache Flink Application</h2>

<p>When we say “exactly-once semantics”, what we mean is that each incoming event affects the final results exactly once. Even in case of a machine or software failure, there’s no duplicate data and no data that goes unprocessed.</p>

<p>Flink has long provided exactly-once semantics <em>within</em> a Flink application. Over the past few years, we’ve <a href="https://data-artisans.com/blog/high-throughput-low-latency-and-exactly-once-stream-processing-with-apache-flink">written in depth about Flink’s checkpointing</a>, which is at the core of Flink’s ability to provide exactly-once semantics. The Flink documentation also <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/ops/state/checkpoints.html">provides a thorough overview of the feature</a>.</p>

<p>Before we continue, here’s a quick summary of the checkpointing algorithm because understanding checkpoints is necessary for understanding this broader topic.</p>

<p>A checkpoint in Flink is a consistent snapshot of:</p>

<ol>
  <li>The current state of an application</li>
  <li>The position in an input stream</li>
</ol>

<p>Flink generates checkpoints on a regular, configurable interval and then writes the checkpoint to a persistent storage system, such as S3 or HDFS. Writing the checkpoint data to the persistent storage happens asynchronously, which means that a Flink application continues to process data during the checkpointing process.</p>

<p>In the event of a machine or software failure and upon restart, a Flink application resumes processing from the most recent successfully-completed checkpoint; Flink restores application state and rolls back to the correct position in the input stream from a checkpoint before processing starts again. This means that Flink computes results as though the failure never occurred.</p>

<p>Before Flink 1.4.0, exactly-once semantics were limited to the scope of <em>a Flink application only</em> and did not extend to most of the external systems to which Flink sends data after processing.</p>

<p>But Flink applications operate in conjunction with a wide range of data sinks, and developers should be able to maintain exactly-once semantics beyond the context of one component.</p>

<p>To provide <em>end-to-end exactly-once</em> semantics–that is, semantics that also apply to the external systems that Flink writes to in addition to the state of the Flink application–these external systems must provide a means to commit or roll back writes that coordinate with Flink’s checkpoints.</p>

<p>One common approach for coordinating commits and rollbacks in a distributed system is the <a href="https://en.wikipedia.org/wiki/Two-phase_commit_protocol">two-phase commit protocol</a>. In the next section, we’ll go behind the scenes and discuss how Flink’s <code>TwoPhaseCommitSinkFunction </code>utilizes the two-phase commit protocol to provide end-to-end exactly-once semantics.</p>

<h2 id="end-to-end-exactly-once-applications-with-apache-flink">End-to-end Exactly Once Applications with Apache Flink</h2>

<p>We’ll walk through the two-phase commit protocol and how it enables end-to-end exactly-once semantics in a sample Flink application that reads from and writes to Kafka. Kafka is a popular messaging system to use along with Flink, and Kafka recently added support for transactions with its 0.11 release. <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/connectors/kafka.html#kafka-011">This means that Flink now has the necessary mechanism to provide end-to-end exactly-once semantics</a> in applications when receiving data from and writing data to Kafka.</p>

<p>Flink’s support for end-to-end exactly-once semantics is not limited to Kafka and you can use it with any source / sink that provides the necessary coordination mechanism. For example, <a href="http://pravega.io/">Pravega</a>, an open-source streaming storage system from Dell/EMC, also supports end-to-end exactly-once semantics with Flink via the <code>TwoPhaseCommitSinkFunction</code>.</p>

<center>
<img src="/img/blog/eo-post-graphic-1.png" width="600px" alt="A sample Flink application" />
</center>

<p>In the sample Flink application that we’ll discuss today, we have:</p>

<ul>
  <li>A data source that reads from Kafka (in Flink, a <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/connectors/kafka.html#kafka-consumer">KafkaConsumer</a>)</li>
  <li>A windowed aggregation</li>
  <li>A data sink that writes data back to Kafka (in Flink, a <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/connectors/kafka.html#kafka-producer">KafkaProducer</a>)</li>
</ul>

<p>For the data sink to provide exactly-once guarantees, it must write all data to Kafka within the scope of a transaction. A commit bundles all writes between two checkpoints.</p>

<p>This ensures that writes are rolled back in case of a failure.</p>

<p>However, in a distributed system with multiple, concurrently-running sink tasks, a simple commit or rollback is not sufficient, because all of the components must “agree” together on committing or rolling back to ensure a consistent result. Flink uses the two-phase commit protocol and its pre-commit phase to address this challenge.</p>

<p>The starting of a checkpoint represents the “pre-commit” phase of our two-phase commit protocol. When a checkpoint starts, the Flink JobManager injects a checkpoint barrier (which separates the records in the data stream into the set that goes into the current checkpoint vs. the set that goes into the next checkpoint) into the data stream.</p>

<p>The barrier is passed from operator to operator. For every operator, it triggers the operator’s state backend to take a snapshot of its state.</p>

<center>
<img src="/img/blog/eo-post-graphic-2.png" width="600px" alt="A sample Flink application - precommit" />
</center>

<p>The data source stores its Kafka offsets, and after completing this, it passes the checkpoint barrier to the next operator.</p>

<p>This approach works if an operator has internal state <em>only</em>. <em>Internal state</em> is everything that is stored and managed by Flink’s state backends - for example, the windowed sums in the second operator. When a process has only internal state, there is no need to perform any additional action during pre-commit aside from updating the data in the state backends before it is checkpointed. Flink takes care of correctly committing those writes in case of checkpoint success or aborting them in case of failure.</p>

<center>
<img src="/img/blog/eo-post-graphic-3.png" width="600px" alt="A sample Flink application - precommit without external state" />
</center>

<p>However, when a process has <em>external</em> state, this state must be handled a bit differently. External state usually comes in the form of writes to an external system such as Kafka. In that case, to provide exactly-once guarantees, the external system must provide support for transactions that integrates with a two-phase commit protocol.</p>

<p>We know that the data sink in our example has such external state because it’s writing data to Kafka. In this case, in the pre-commit phase, the data sink must pre-commit its external transaction in addition to writing its state to the state backend.</p>

<center>
<img src="/img/blog/eo-post-graphic-4.png" width="600px" alt="A sample Flink application - precommit with external state" />
</center>

<p>The pre-commit phase finishes when the checkpoint barrier passes through all of the operators and the triggered snapshot callbacks complete. At this point the checkpoint completed successfully and consists of the state of the entire application, including pre-committed external state. In case of a failure, we would re-initialize the application from this checkpoint.</p>

<p>The next step is to notify all operators that the checkpoint has succeeded. This is the commit phase of the two-phase commit protocol and the JobManager issues checkpoint-completed callbacks for every operator in the application. The data source and window operator have no external state, and so in the commit phase, these operators don’t have to take any action. The data sink does have external state, though, and commits the transaction with the external writes.</p>

<center>
<img src="/img/blog/eo-post-graphic-5.png" width="600px" alt="A sample Flink application - commit external state" />
</center>

<p>So let’s put all of these different pieces together:</p>

<ul>
  <li>Once all of the operators complete their pre-commit, they issue a commit.</li>
  <li>If at least one pre-commit fails, all others are aborted, and we roll back to the previous successfully-completed checkpoint.</li>
  <li>After a successful pre-commit, the commit <em>must</em> be guaranteed to eventually succeed – both our operators and our external system need to make this guarantee. If a commit fails (for example, due to an intermittent network issue), the entire Flink application fails, restarts according to the user’s restart strategy, and there is another commit attempt. This process is critical because if the commit does not eventually succeed, data loss occurs.</li>
</ul>

<p>Therefore, we can be sure that all operators agree on the final outcome of the checkpoint: all operators agree that the data is either committed or that the commit is aborted and rolled back.</p>

<h2 id="implementing-the-two-phase-commit-operator-in-flink">Implementing the Two-Phase Commit Operator in Flink</h2>

<p>All the logic required to put a two-phase commit protocol together can be a little bit complicated and that’s why Flink extracts the common logic of the two-phase commit protocol into the abstract <code>TwoPhaseCommitSinkFunction</code> class<code>. </code></p>

<p>Let’s discuss how to extend a <code>TwoPhaseCommitSinkFunction</code> on a simple file-based example. We need to implement only four methods and present their implementations for an exactly-once file sink:</p>

<ol>
  <li><code>beginTransaction - </code>to begin the transaction, we create a temporary file in a temporary directory on our destination file system. Subsequently, we can write data to this file as we process it.</li>
  <li><code>preCommit - </code>on pre-commit, we flush the file, close it, and never write to it again. We’ll also start a new transaction for any subsequent writes that belong to the next checkpoint.</li>
  <li><code>commit - </code>on commit, we atomically move the pre-committed file to the actual destination directory. Please note that this increases the latency in the visibility of the output data.</li>
  <li><code>abort - </code>on abort, we delete the temporary file.</li>
</ol>

<p>As we know, if there’s any failure, Flink restores the state of the application to the latest successful checkpoint. One potential catch is in a rare case when the failure occurs after a successful pre-commit but before notification of that fact (a commit) reaches our operator. In that case, Flink restores our operator to the state that has already been pre-committed but not yet committed.</p>

<p>We must save enough information about pre-committed transactions in checkpointed state to be able to either <code>abort</code> or <code>commit</code> transactions after a restart. In our example, this would be the path to the temporary file and target directory.</p>

<p>The <code>TwoPhaseCommitSinkFunction</code> takes this scenario into account, and it always issues a preemptive commit when restoring state from a checkpoint. It is our responsibility to implement a commit in an idempotent way. Generally, this shouldn’t be an issue. In our example, we can recognize such a situation: the temporary file is not in the temporary directory, but has already been moved to the target directory.</p>

<p>There are a handful of other edge cases that <code>TwoPhaseCommitSinkFunction</code> takes into account, too. <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/api/java/org/apache/flink/streaming/api/functions/sink/TwoPhaseCommitSinkFunction.html">Learn more in the Flink documentation</a>.</p>

<h2 id="wrapping-up">Wrapping Up</h2>

<p>If you’ve made it this far, thanks for staying with us through a detailed post. Here are some key points that we covered:</p>

<ul>
  <li>Flink’s checkpointing system serves as Flink’s basis for supporting a two-phase commit protocol and providing end-to-end exactly-once semantics.</li>
  <li>An advantage of this approach is that Flink does not materialize data in transit the way that some other systems do–there’s no need to write every stage of the computation to disk as is the case is most batch processing.</li>
  <li>Flink’s new <code>TwoPhaseCommitSinkFunction</code> extracts the common logic of the two-phase commit protocol and makes it possible to build end-to-end exactly-once applications with Flink and external systems that support transactions</li>
  <li>Starting with <a href="https://data-artisans.com/blog/announcing-the-apache-flink-1-4-0-release">Flink 1.4.0</a>, both the Pravega and Kafka 0.11 producers provide exactly-once semantics; Kafka introduced transactions for the first time in Kafka 0.11, which is what made the Kafka exactly-once producer possible in Flink.</li>
  <li>The <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.4/dev/connectors/kafka.html#kafka-011">Kafka 0.11 producer</a> is implemented on top of the <code>TwoPhaseCommitSinkFunction</code>, and it offers very low overhead compared to the at-least-once Kafka producer.</li>
</ul>

<p>We’re very excited about what this new feature enables, and we look forward to being able to support additional producers with the <code>TwoPhaseCommitSinkFunction</code> in the future.</p>

<p><em>This post <a href="https://data-artisans.com/blog/end-to-end-exactly-once-processing-apache-flink-apache-kafka" target="_blank"> first appeared on the data Artisans blog </a>and was contributed to Apache Flink and the Flink blog by the original authors Piotr Nowojski and Mike Winters.</em></p>
<link rel="canonical" href="https://data-artisans.com/blog/end-to-end-exactly-once-processing-apache-flink-apache-kafka" />


      </article>
    </div>

    <div class="row">
      <div id="disqus_thread"></div>
      <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'stratosphere-eu'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
             (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
      </script>
    </div>
  </div>
</div>
      </div>
    </div>

    <hr />

    <div class="row">
      <div class="footer text-center col-sm-12">
        <p>Copyright © 2014-2019 <a href="http://apache.org">The Apache Software Foundation</a>. All Rights Reserved.</p>
        <p>Apache Flink, Flink®, Apache®, the squirrel logo, and the Apache feather logo are either registered trademarks or trademarks of The Apache Software Foundation.</p>
        <p><a href="/privacy-policy.html">Privacy Policy</a> &middot; <a href="/blog/feed.xml">RSS feed</a></p>
      </div>
    </div>
    </div><!-- /.container -->

    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.matchHeight/0.7.0/jquery.matchHeight-min.js"></script>
    <script src="/js/codetabs.js"></script>
    <script src="/js/stickysidebar.js"></script>

    <!-- Google Analytics -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-52545728-1', 'auto');
      ga('send', 'pageview');
    </script>
  </body>
</html>

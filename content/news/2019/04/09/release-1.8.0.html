<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Apache Flink: Apache Flink 1.8.0 Release Announcement</title>
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">

    <!-- Bootstrap -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
    <link rel="stylesheet" href="/css/flink.css">
    <link rel="stylesheet" href="/css/syntax.css">

    <!-- Blog RSS feed -->
    <link href="/blog/feed.xml" rel="alternate" type="application/rss+xml" title="Apache Flink Blog: RSS feed" />

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <!-- We need to load Jquery in the header for custom google analytics event tracking-->
    <script src="/js/jquery.min.js"></script>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>  
    

    <!-- Main content. -->
    <div class="container">
    <div class="row">

      
     <div id="sidebar" class="col-sm-3">
        

<!-- Top navbar. -->
    <nav class="navbar navbar-default">
        <!-- The logo. -->
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <div class="navbar-logo">
            <a href="/">
              <img alt="Apache Flink" src="/img/flink-header-logo.svg" width="147px" height="73px">
            </a>
          </div>
        </div><!-- /.navbar-header -->

        <!-- The navigation links. -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
          <ul class="nav navbar-nav navbar-main">

            <!-- First menu section explains visitors what Flink is -->

            <!-- What is Stream Processing? -->
            <!--
            <li><a href="/streamprocessing1.html">What is Stream Processing?</a></li>
            -->

            <!-- What is Flink? -->
            <li><a href="/flink-architecture.html">What is Apache Flink?</a></li>

            

            <!-- What is Stateful Functions? -->

            <li><a href="/stateful-functions.html">What is Stateful Functions?</a></li>

            <!-- Use cases -->
            <li><a href="/usecases.html">Use Cases</a></li>

            <!-- Powered by -->
            <li><a href="/poweredby.html">Powered By</a></li>


            &nbsp;
            <!-- Second menu section aims to support Flink users -->

            <!-- Downloads -->
            <li><a href="/downloads.html">Downloads</a></li>

            <!-- Getting Started -->
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#">Getting Started<span class="caret"></span></a>
              <ul class="dropdown-menu">
                <li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12/try-flink/index.html" target="_blank">With Flink <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2/getting-started/project-setup.html" target="_blank">With Flink Stateful Functions <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="/training.html">Training Course</a></li>
              </ul>
            </li>

            <!-- Documentation -->
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#">Documentation<span class="caret"></span></a>
              <ul class="dropdown-menu">
                <li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.12" target="_blank">Flink 1.12 (Latest stable release) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://ci.apache.org/projects/flink/flink-docs-master" target="_blank">Flink Master (Latest Snapshot) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://ci.apache.org/projects/flink/flink-statefun-docs-release-2.2" target="_blank">Flink Stateful Functions 2.2 (Latest stable release) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://ci.apache.org/projects/flink/flink-statefun-docs-master" target="_blank">Flink Stateful Functions Master (Latest Snapshot) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
              </ul>
            </li>

            <!-- getting help -->
            <li><a href="/gettinghelp.html">Getting Help</a></li>

            <!-- Blog -->
            <li class="active"><a href="/blog/"><b>Flink Blog</b></a></li>


            <!-- Flink-packages -->
            <li>
              <a href="https://flink-packages.org" target="_blank">flink-packages.org <small><span class="glyphicon glyphicon-new-window"></span></small></a>
            </li>
            &nbsp;

            <!-- Third menu section aim to support community and contributors -->

            <!-- Community -->
            <li><a href="/community.html">Community &amp; Project Info</a></li>

            <!-- Roadmap -->
            <li><a href="/roadmap.html">Roadmap</a></li>

            <!-- Contribute -->
            <li><a href="/contributing/how-to-contribute.html">How to Contribute</a></li>
            

            <!-- GitHub -->
            <li>
              <a href="https://github.com/apache/flink" target="_blank">Flink on GitHub <small><span class="glyphicon glyphicon-new-window"></span></small></a>
            </li>

            &nbsp;

            <!-- Language Switcher -->
            <li>
              
                
                  <!-- link to the Chinese home page when current is blog page -->
                  <a href="/zh">中文版</a>
                
              
            </li>

          </ul>

          <ul class="nav navbar-nav navbar-bottom">
          <hr />

            <!-- Twitter -->
            <li><a href="https://twitter.com/apacheflink" target="_blank">@ApacheFlink <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

            <!-- Visualizer -->
            <li class=" hidden-md hidden-sm"><a href="/visualizer/" target="_blank">Plan Visualizer <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

          <hr />

            <li><a href="https://apache.org" target="_blank">Apache Software Foundation <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

            <li>
              <style>
                .smalllinks:link {
                  display: inline-block !important; background: none; padding-top: 0px; padding-bottom: 0px; padding-right: 0px; min-width: 75px;
                }
              </style>

              <a class="smalllinks" href="https://www.apache.org/licenses/" target="_blank">License</a> <small><span class="glyphicon glyphicon-new-window"></span></small>

              <a class="smalllinks" href="https://www.apache.org/security/" target="_blank">Security</a> <small><span class="glyphicon glyphicon-new-window"></span></small>

              <a class="smalllinks" href="https://www.apache.org/foundation/sponsorship.html" target="_blank">Donate</a> <small><span class="glyphicon glyphicon-new-window"></span></small>

              <a class="smalllinks" href="https://www.apache.org/foundation/thanks.html" target="_blank">Thanks</a> <small><span class="glyphicon glyphicon-new-window"></span></small>
            </li>

          </ul>
        </div><!-- /.navbar-collapse -->
    </nav>

      </div>
      <div class="col-sm-9">
      <div class="row-fluid">
  <div class="col-sm-12">
    <div class="row">
      <h1>Apache Flink 1.8.0 Release Announcement</h1>
      <p><i></i></p>

      <article>
        <p>09 Apr 2019 Aljoscha Krettek (<a href="https://twitter.com/aljoscha">@aljoscha</a>)</p>

<p>The Apache Flink community is pleased to announce Apache Flink 1.8.0.  The
latest release includes more than 420 resolved issues and some exciting
additions to Flink that we describe in the following sections of this post.
Please check the <a href="https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12315522&amp;version=12344274">complete changelog</a>
for more details.</p>

<p>Flink 1.8.0 is API-compatible with previous 1.x.y releases for APIs annotated
with the <code>@Public</code> annotation.  The release is available now and we encourage
everyone to <a href="/downloads.html">download the release</a> and
check out the updated
<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.8/">documentation</a>.
Feedback through the Flink <a href="/community.html#mailing-lists">mailing
lists</a> or
<a href="https://issues.apache.org/jira/projects/FLINK/summary">JIRA</a> is, as always,
very much appreciated!</p>

<p>You can find the binaries on the updated <a href="/downloads.html">Downloads page</a> on the Flink project site.</p>

<div class="page-toc">
<ul id="markdown-toc">
  <li><a href="#new-features-and-improvements" id="markdown-toc-new-features-and-improvements">New Features and Improvements</a></li>
  <li><a href="#important-changes" id="markdown-toc-important-changes">Important Changes</a></li>
  <li><a href="#known-issues" id="markdown-toc-known-issues">Known Issues</a></li>
  <li><a href="#release-notes" id="markdown-toc-release-notes">Release Notes</a></li>
  <li><a href="#list-of-contributors" id="markdown-toc-list-of-contributors">List of Contributors</a></li>
</ul>

</div>

<p>With Flink 1.8.0 we come closer to our goals of enabling fast data processing
and building data-intensive applications for the Flink community in a seamless
way. We do this by cleaning up and refactoring Flink under the hood to allow
more efficient feature development in the future. This includes removal of the
legacy runtime components that were subsumed in the major rework of Flink’s
underlying distributed system architecture
(<a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=65147077">FLIP-6</a>)
as well as refactorings on the Table API that prepare it for the future
addition of the Blink enhancements
(<a href="https://issues.apache.org/jira/browse/FLINK-11439">FLINK-11439</a>).</p>

<p>Nevertheless, this release includes some important new features and bug fixes.
The most interesting of those are highlighted below. Please consult the
<a href="https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12315522&amp;version=12344274">complete changelog</a>
and the <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.8/release-notes/flink-1.8.html">release notes</a>
for more details.</p>

<h2 id="new-features-and-improvements">New Features and Improvements</h2>

<ul>
  <li>
    <p><strong>Finalized State Schema Evolution Story</strong>: This release completes
the community driven effort to provide a schema evolution story for
user state managed by Flink. This has been an effort that spanned 2
releases, starting from 1.7.0 with the introduction of support for
Avro state schema evolution as well as a revamped serialization
compatibility abstraction.</p>

    <p>Flink 1.8.0 finalizes this effort by extending support for schema
evolution to POJOs, upgrading all Flink built-in serializers to use
the new serialization compatibility abstractions, as well as making it
easier for advanced users who use custom state serializers to
implement the abstractions.  These different aspects for a complete
out-of-the-box schema evolution story are explained in detail below:</p>

    <ol>
      <li>
        <p>Support for POJO state schema evolution: The pool of data types
that support state schema evolution has been expanded to include
POJOs. For state types that use POJOs, you can now add or remove
fields from your POJO while retaining backwards
compatibility. For a full overview of the list of data types that
now support schema evolution as well as their evolution
specifications and limitations, please refer to the State Schema
Evolution documentation page.</p>
      </li>
      <li>
        <p>Upgrade all Flink serializers to use new serialization
compatibility asbtractions: Back in 1.7.0, we introduced the new
serialization compatibility abstractions <code>TypeSerializerSnapshot</code>
and <code>TypeSerializerSchemaCompatibility</code>. Besides providing a more
expressible API to reflect schema compatibility between the data
stored in savepoints and the data registered at runtime, another
important aspect about the new abstraction is that it avoids the
need for Flink to Java-serialize the state serializer as state
metadata in savepoints.</p>

        <p>In 1.8.0, all of Flink’s built-in serializers have been upgraded to
use the new abstractions, and therefore the serializers
themselves are no longer Java-serialized into savepoints. This
greatly improves interoperability of Flink savepoints, in terms
of state schema evolvability. For example, one outcome was the
support for POJO schema evolution, as previously mentioned
above. Another outcome is that all composite data types supported
by Flink (such as <code>Either</code>, Scala case classes, Flink Java
<code>Tuple</code>s, etc.) are generally evolve-able as well when they have
a nested evolvable type, such as a POJO. For example, the <code>MyPojo</code>
type in <code>ValueState&lt;Tuple2&lt;Integer, MyPojo&gt;&gt;</code> or
<code>ListState&lt;Either&lt;Integer, MyPojo&gt;&gt;</code>, which is a POJO, is allowed
to evolve its schema.</p>

        <p>For users who are using custom <code>TypeSerializer</code> implementations
for their state serializer and are still using the outdated
abstractions (i.e. <code>TypeSerializerConfigSnapshot</code> and
<code>CompatiblityResult</code>), we highly recommend upgrading to the new
abstractions to be future proof. Please refer to the Custom State
Serialization documentation page for a detailed description on
the new abstractions.</p>
      </li>
      <li>
        <p>Provide pre-defined snapshot implementations for common
serializers: For convenience, Flink 1.8.0 comes with two
predefined implementations for the <code>TypeSerializerSnapshot</code> that
make the task of implementing these new abstractions easier
for most implementations of <code>TypeSerializer</code>s -
<code>SimpleTypeSerializerSnapshot</code> and
<code>CompositeTypeSerializerSnapshot</code>. This section in the
documentation provides information on how to use these classes.</p>
      </li>
    </ol>
  </li>
  <li>
    <p><strong>Continuous cleanup of old state based on TTL
(<a href="https://issues.apache.org/jira/browse/FLINK-7811">FLINK-7811</a>)</strong>: We
introduced TTL (time-to-live) for Keyed state in Flink 1.6
(<a href="https://issues.apache.org/jira/browse/FLINK-9510">FLINK-9510</a>). This
feature enabled cleanup and made keyed state entries inaccessible after a
defined timeout. In addition state would now also be cleaned up when
writing a savepoint/checkpoint.</p>

    <p>Flink 1.8 introduces continuous cleanup of old entries for both the RocksDB
state backend
(<a href="https://issues.apache.org/jira/browse/FLINK-10471">FLINK-10471</a>) and the heap
state backend
(<a href="https://issues.apache.org/jira/browse/FLINK-10473">FLINK-10473</a>). This means
that old entries (according to the TTL setting) are continuously cleaned up.</p>
  </li>
  <li>
    <p><strong>SQL pattern detection with user-defined functions and
aggregations</strong>: The support of the MATCH_RECOGNIZE clause has been
extended by multiple features.  The addition of user-defined
functions allows for custom logic during pattern detection
(<a href="https://issues.apache.org/jira/browse/FLINK-10597">FLINK-10597</a>),
while adding aggregations allows for more complex CEP definitions,
such as the following
(<a href="https://issues.apache.org/jira/browse/FLINK-7599">FLINK-7599</a>).</p>

    <div class="highlight"><pre><code>SELECT *
FROM Ticker
    MATCH_RECOGNIZE (
        ORDER BY rowtime
        MEASURES
            AVG(A.price) AS avgPrice
        ONE ROW PER MATCH
        AFTER MATCH SKIP TO FIRST B
        PATTERN (A+ B)
        DEFINE
            A AS AVG(A.price) &lt; 15
    ) MR;
</code></pre></div>
  </li>
  <li>
    <p><strong>RFC-compliant CSV format (<a href="https://issues.apache.org/jira/browse/FLINK-9964">FLINK-9964</a>)</strong>: The SQL tables can now be read and written in
an RFC-4180 standard compliant CSV table format. The format might also be
useful for general DataStream API users.</p>
  </li>
  <li>
    <p><strong>New KafkaDeserializationSchema that gives direct access to ConsumerRecord
(<a href="https://issues.apache.org/jira/browse/FLINK-8354">FLINK-8354</a>)</strong>: For the
Flink <code>KafkaConsumers</code>, we introduced a new <code>KafkaDeserializationSchema</code> that
gives direct access to the Kafka <code>ConsumerRecord</code>. This now allows access to
all data that Kafka provides for a record, including the headers. This
subsumes the <code>KeyedSerializationSchema</code> functionality, which is deprecated but
still available for now.</p>
  </li>
  <li>
    <p><strong>Per-shard watermarking option in FlinkKinesisConsumer
(<a href="https://issues.apache.org/jira/browse/FLINK-5697">FLINK-5697</a>)</strong>: The Kinesis
Consumer can now emit periodic watermarks that are derived from per-shard watermarks,
for correct event time processing with subtasks that consume multiple Kinesis shards.</p>
  </li>
  <li>
    <p><strong>New consumer for DynamoDB Streams to capture table changes
(<a href="https://issues.apache.org/jira/browse/FLINK-4582">FLINK-4582</a>)</strong>: <code>FlinkDynamoDBStreamsConsumer</code>
is a variant of the Kinesis consumer that supports retrieval of CDC-like streams from DynamoDB tables.</p>
  </li>
  <li>
    <p><strong>Support for global aggregates for subtask coordination
(<a href="https://issues.apache.org/jira/browse/FLINK-10887">FLINK-10887</a>)</strong>:
Designed as a solution for global source watermark tracking, <code>GlobalAggregateManager</code>
allows sharing of information between parallel subtasks. This feature will
be integrated into streaming connectors for watermark synchronization and
can be used for other purposes with a user defined aggregator.</p>
  </li>
</ul>

<h2 id="important-changes">Important Changes</h2>

<ul>
  <li>
    <p><strong>Changes to bundling of Hadoop libraries with Flink
(<a href="https://issues.apache.org/jira/browse/FLINK-11266">FLINK-11266</a>)</strong>:
Convenience binaries that include hadoop are no longer released.</p>

    <p>If a deployment relies on <code>flink-shaded-hadoop2</code> being included in
<code>flink-dist</code>, then you must manually download a pre-packaged Hadoop
jar from the optional components section of the <a href="/downloads.html">download
page</a> and copy it into the
<code>/lib</code> directory.  Alternatively, a Flink distribution that includes
hadoop can be built by packaging <code>flink-dist</code> and activating the
<code>include-hadoop</code> maven profile.</p>

    <p>As hadoop is no longer included in <code>flink-dist</code> by default, specifying
<code>-DwithoutHadoop</code> when packaging <code>flink-dist</code> no longer impacts the build.</p>
  </li>
  <li>
    <p><strong>FlinkKafkaConsumer will now filter restored partitions based on topic
specification
(<a href="https://issues.apache.org/jira/browse/FLINK-10342">FLINK-10342</a>)</strong>:
Starting from Flink 1.8.0, the <code>FlinkKafkaConsumer</code> now always filters out
restored partitions that are no longer associated with a specified topic to
subscribe to in the restored execution. This behaviour did not exist in
previous versions of the <code>FlinkKafkaConsumer</code>. If you wish to retain the
previous behaviour, please use the
<code>disableFilterRestoredPartitionsWithSubscribedTopics()</code> configuration method
on the <code>FlinkKafkaConsumer</code>.</p>

    <p>Consider this example: if you had a Kafka Consumer that was consuming from
topic <code>A</code>, you did a savepoint, then changed your Kafka consumer to instead
consume from topic <code>B</code>, and then restarted your job from the savepoint.
Before this change, your consumer would now consume from both topic <code>A</code> and
<code>B</code> because it was stored in state that the consumer was consuming from topic
<code>A</code>. With the change, your consumer would only consume from topic <code>B</code> after
restore because it now filters the topics that are stored in state using the
configured topics.</p>
  </li>
  <li>
    <p><strong>Change in the Maven modules of Table API
(<a href="https://issues.apache.org/jira/browse/FLINK-11064">FLINK-11064</a>)</strong>: Users
that had a <code>flink-table</code> dependency before, need to update their
dependencies to <code>flink-table-planner</code> and the correct dependency of
<code>flink-table-api-*</code>, depending on whether Java or Scala is used: one of
<code>flink-table-api-java-bridge</code> or <code>flink-table-api-scala-bridge</code>.</p>
  </li>
</ul>

<h2 id="known-issues">Known Issues</h2>

<ul>
  <li><strong>Discarded checkpoint can cause Tasks to fail
(<a href="https://issues.apache.org/jira/browse/FLINK-11662">FLINK-11662</a>)</strong>: There is
a race condition that can lead to erroneous checkpoint failures. This mostly
occurs when restarting from a savepoint or checkpoint takes a long time at the
sources of a job. If you see random checkpointing failures that don’t seem to
have a good explanation you might be affected. Please see the Jira issue for
more details and a workaround for the problem.</li>
</ul>

<h2 id="release-notes">Release Notes</h2>

<p>Please review the <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.8/release-notes/flink-1.8.html">release
notes</a>
for a more detailed list of changes and new features if you plan to upgrade
your Flink setup to Flink 1.8.</p>

<h2 id="list-of-contributors">List of Contributors</h2>

<p>We would like to acknowledge all community members for contributing to this
release.  Special credits go to the following members for contributing to the
1.8.0 release (according to <code>git log --pretty="%an" release-1.7.0..release-1.8.0 | sort | uniq</code> without manual deduplication):</p>

<p>Addison Higham, Aitozi, Aleksey Pak, Alexander Fedulov, Alexey Trenikhin, Aljoscha Krettek, Andrey Zagrebin, Artsem Semianenka, Asura7969, Avi, Barisa Obradovic, Benchao Li, Bo WANG, Chesnay Schepler, Congxian Qiu, Cristian, David Anderson, Dawid Wysakowicz, Dian Fu, DuBin, EAlexRojas, EronWright, Eugen Yushin, Fabian Hueske, Fokko Driesprong, Gary Yao, Hequn Cheng, Igal Shilman, Jamie Grier, JaryZhen, Jeff Zhang, Jihyun Cho, Jinhu Wu, Joerg Schad, KarmaGYZ, Kezhu Wang, Konstantin Knauf, Kostas Kloudas, Lakshmi, Lakshmi Gururaja Rao, Lavkesh Lahngir, Li, Shuangjiang, Mai Nakagawa, Matrix42, Matt, Maximilian Michels, Mododo, Nico Kruber, Paul Lin, Piotr Nowojski, Qi Yu, Qin, Robert, Robert Metzger, Romano Vacca, Rong Rong, Rune Skou Larsen, Seth Wiesman, Shannon Carey, Shimin Yang, Shuyi Chen, Stefan Richter, Stephan Ewen, SuXingLee, TANG Wen-hui, Tao Yang, Thomas Weise, Till Rohrmann, Timo Walther, Tom Goong, Tony Feng, Tony Wei, Tzu-Li (Gordon) Tai, Tzu-Li Chen, Ufuk Celebi, Xingcan Cui, Xpray, XuQianJin-Stars, Xue Yu, Yangze Guo, Ying Xu, Yiqun Lin, Yu Li, Yuanyang Wu, Yun Tang, ZILI CHEN, Zhanchun Zhang, Zhijiang, ZiLi Chen, acqua.csq, alex04.wang, ap, azagrebin, blueszheng, boshu Zheng, chengjie.wu, chensq, chummyhe89, eaglewatcherwb, hequn8128, ifndef-SleePy, intsmaze, jackyyin, jinhu.wjh, jparkie, jrthe42, junsheng.wu, kgorman, kkloudas, kkolman, klion26, lamber-ken, leesf, libenchao, lining, liuzhaokun, lzh3636, maqingxiang, mb-datadome, okidogi, park.yq, sunhaibotb, sunjincheng121, tison, unknown, vinoyang, wenhuitang, wind, xueyu, xuqianjin, yanghua, zentol, zhangzhanchun, zhijiang, zhuzhu.zz, zy, 仲炜, 砚田, 谢磊</p>


      </article>
    </div>

    <div class="row">
      <div id="disqus_thread"></div>
      <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'stratosphere-eu'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
             (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
      </script>
    </div>
  </div>
</div>
      </div>
    </div>

    <hr />

    <div class="row">
      <div class="footer text-center col-sm-12">
        <p>Copyright © 2014-2019 <a href="http://apache.org">The Apache Software Foundation</a>. All Rights Reserved.</p>
        <p>Apache Flink, Flink®, Apache®, the squirrel logo, and the Apache feather logo are either registered trademarks or trademarks of The Apache Software Foundation.</p>
        <p><a href="/privacy-policy.html">Privacy Policy</a> &middot; <a href="/blog/feed.xml">RSS feed</a></p>
      </div>
    </div>
    </div><!-- /.container -->

    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.matchHeight/0.7.0/jquery.matchHeight-min.js"></script>
    <script src="/js/codetabs.js"></script>
    <script src="/js/stickysidebar.js"></script>

    <!-- Google Analytics -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-52545728-1', 'auto');
      ga('send', 'pageview');
    </script>
  </body>
</html>

<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Apache Flink: Apache Flink Roadmap</title>
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">

    <!-- Bootstrap -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css">
    <link rel="stylesheet" href="/css/flink.css">
    <link rel="stylesheet" href="/css/syntax.css">

    <!-- Blog RSS feed -->
    <link href="/blog/feed.xml" rel="alternate" type="application/rss+xml" title="Apache Flink Blog: RSS feed" />

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <!-- We need to load Jquery in the header for custom google analytics event tracking-->
    <script src="/js/jquery.min.js"></script>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>  
    

    <!-- Main content. -->
    <div class="container">
    <div class="row">

      
     <div id="sidebar" class="col-sm-3">
        

<!-- Top navbar. -->
    <nav class="navbar navbar-default">
        <!-- The logo. -->
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <div class="navbar-logo">
            <a href="/">
              <img alt="Apache Flink" src="/img/flink-header-logo.svg" width="147px" height="73px">
            </a>
          </div>
        </div><!-- /.navbar-header -->

        <!-- The navigation links. -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
          <ul class="nav navbar-nav navbar-main">

            <!-- First menu section explains visitors what Flink is -->

            <!-- What is Stream Processing? -->
            <!--
            <li><a href="/streamprocessing1.html">What is Stream Processing?</a></li>
            -->

            <!-- What is Flink? -->
            <li><a href="/flink-architecture.html">What is Apache Flink?</a></li>

            <!-- Use cases -->
            <li><a href="/usecases.html">Use Cases</a></li>

            <!-- Powered by -->
            <li><a href="/poweredby.html">Powered By</a></li>

            <!-- FAQ -->
            <li><a href="/faq.html">FAQ</a></li>

            &nbsp;
            <!-- Second menu section aims to support Flink users -->

            <!-- Downloads -->
            <li><a href="/downloads.html">Downloads</a></li>

            <!-- Quickstart -->
            <li>
              <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.8/quickstart/setup_quickstart.html" target="_blank">Tutorials <small><span class="glyphicon glyphicon-new-window"></span></small></a>
            </li>

            <!-- Documentation -->
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#">Documentation<span class="caret"></span></a>
              <ul class="dropdown-menu">
                <li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.8" target="_blank">1.8 (Latest stable release) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://ci.apache.org/projects/flink/flink-docs-master" target="_blank">1.9 (Snapshot) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
              </ul>
            </li>

            <!-- getting help -->
            <li><a href="/gettinghelp.html">Getting Help</a></li>

            <!-- Blog -->
            <li><a href="/blog/"><b>Flink Blog</b></a></li>

            &nbsp;

            <!-- Third menu section aim to support community and contributors -->

            <!-- Community -->
            <li><a href="/community.html">Community &amp; Project Info</a></li>

            <!-- Roadmap -->
            <li class="active"><a href="/roadmap.html">Roadmap</a></li>

            <!-- Contribute -->
            <li><a href="/how-to-contribute.html">How to Contribute</a></li>

            <!-- GitHub -->
            <li>
              <a href="https://github.com/apache/flink" target="_blank">Flink on GitHub <small><span class="glyphicon glyphicon-new-window"></span></small></a>
            </li>

            &nbsp;

            <!-- Language Switcher -->
            <li>
              
                 
                  <a href="/zh/roadmap.html">中文版</a>   
                
              
            </li>

          </ul>

          <ul class="nav navbar-nav navbar-bottom">
          <hr />

            <!-- Twitter -->
            <li><a href="https://twitter.com/apacheflink" target="_blank">@ApacheFlink <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

            <!-- Visualizer -->
            <li class=" hidden-md hidden-sm"><a href="/visualizer/" target="_blank">Plan Visualizer <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

          </ul>
        </div><!-- /.navbar-collapse -->
    </nav>

      </div>
      <div class="col-sm-9">
      <div class="row-fluid">
  <div class="col-sm-12">
    <h1>Apache Flink Roadmap</h1>

	<!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->

<hr />

<div class="page-toc">
<ul id="markdown-toc">
  <li><a href="#analytics-applications-an-the-roles-of-datastream-dataset-and-table-api" id="markdown-toc-analytics-applications-an-the-roles-of-datastream-dataset-and-table-api">Analytics, Applications, an the roles of DataStream, DataSet, and Table API</a></li>
  <li><a href="#batch-and-streaming-unification" id="markdown-toc-batch-and-streaming-unification">Batch and Streaming Unification</a></li>
  <li><a href="#fast-batch-bounded-streams" id="markdown-toc-fast-batch-bounded-streams">Fast Batch (Bounded Streams)</a></li>
  <li><a href="#stream-processing-use-cases" id="markdown-toc-stream-processing-use-cases">Stream Processing Use Cases</a></li>
  <li><a href="#deployment-scaling-security" id="markdown-toc-deployment-scaling-security">Deployment, Scaling, Security</a></li>
  <li><a href="#ecosystem" id="markdown-toc-ecosystem">Ecosystem</a></li>
  <li><a href="#connectors--formats" id="markdown-toc-connectors--formats">Connectors &amp; Formats</a></li>
  <li><a href="#miscellaneous" id="markdown-toc-miscellaneous">Miscellaneous</a></li>
</ul>

</div>

<p><strong>Preamble:</strong> This is not an authoritative roadmap in the sense of a strict plan with a specific
timeline. Rather, we, the community, share our vision for the future and give an overview of the bigger
initiatives that are going on and are receiving attention. This roadmap shall give users and
contributors an understanding where the project is going and what they can expect to come.</p>

<p>The roadmap is continuously updated. New features and efforts should be added to the roadmap once
there is consensus that they will happen and what they will roughly look like for the user.</p>

<h1 id="analytics-applications-an-the-roles-of-datastream-dataset-and-table-api">Analytics, Applications, an the roles of DataStream, DataSet, and Table API</h1>

<p>Flink views stream processing as a <a href="/flink-architecture.html">unifying paradigm for data processing</a>
(batch and real-time) and event-driven applications. The APIs are evolving to reflect that view:</p>

<ul>
  <li>
    <p>The <strong>Table API / SQL</strong> is becoming the primary API for analytical use cases, in a unified way
across batch and streaming. To support analytical use cases in a more streamlined fashion,
the API is extended with additional functions (<a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=97552739">FLIP-29</a>).</p>

    <p>Like SQL, the Table API is <em>declarative</em>, operates on a <em>logical schema</em>, and applies <em>automatic optimization</em>.
Because of these properties, that API does not give direct access to time and state.</p>
  </li>
  <li>
    <p>The <strong>DataStream API</strong> is the primary API for data-driven applications and data pipelines.
It uses <em>physical data types</em> (Java/Scala classes) and there is no automatic rewriting.
The applications have explicit control over <em>time</em> and <em>state</em> (state, triggers, proc. fun.).</p>

    <p>In the long run, the DataStream API should fully subsume the DataSet API through <em>bounded streams</em>.</p>
  </li>
</ul>

<h1 id="batch-and-streaming-unification">Batch and Streaming Unification</h1>

<p>Flink’s approach is to cover batch and streaming by the same APIs, on a streaming runtime.
<a href="/news/2019/02/13/unified-batch-streaming-blink.html">This blog post</a>
gives an introduction to the unification effort.</p>

<p>The biggest user-facing parts currently ongoing are:</p>

<ul>
  <li>
    <p>Table API restructuring <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-32%3A+Restructure+flink-table+for+future+contributions">FLIP-32</a>
that decouples the Table API from batch/streaming specific environments and dependencies.</p>
  </li>
  <li>
    <p>The new source interfaces <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-27%3A+Refactor+Source+Interface">FLIP-27</a>
generalize across batch and streaming, making every connector usable as a batch and
streaming data source.</p>
  </li>
  <li>
    <p>The introduction of <em>upsert-</em> or <em>changelog-</em> sources <a href="https://issues.apache.org/jira/browse/FLINK-8545">FLINK-8545</a>
will support more powerful streaming inputs to the Table API.</p>
  </li>
</ul>

<p>On the runtime level, the streaming operators are extended to also support the data consumption
patterns required for some batch operations (<a href="https://lists.apache.org/thread.html/cb1633d10d17b0c639c3d59b2283e9e01ecda3e54ba860073c124878@%3Cdev.flink.apache.org%3E">discussion thread</a>).
This is also groundwork for features like efficient <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-17+Side+Inputs+for+DataStream+API">side inputs</a>.</p>

<h1 id="fast-batch-bounded-streams">Fast Batch (Bounded Streams)</h1>

<p>The community’s goal is to make Flink’s performance on bounded streams (batch use cases) competitive with that
of dedicated batch processors. While Flink has been shown to handle some batch processing use cases faster than
widely-used batch processors, there are some ongoing efforts to make sure this the case for broader use cases:</p>

<ul>
  <li>
    <p>Faster and more complete SQL/Table API: The community is merging the Blink query processor which improves on
the current query processor by adding a much richer set of runtime operators, optimizer rules, and code generation.
The new query processor will have full TPC-DS support and up to 10x performance improvement over the current
query processor (<a href="https://issues.apache.org/jira/browse/FLINK-11439">FLINK-11439</a>).</p>
  </li>
  <li>
    <p>Exploiting bounded streams to reduce the scope of fault tolerance: When input data is bounded, it is
possible to completely buffer data during shuffles (memory or disk) and replay that data after a
failure. This makes recovery more fine grained and thus much more efficient
(<a href="https://issues.apache.org/jira/browse/FLINK-10288">FLINK-10288</a>).</p>
  </li>
  <li>
    <p>An application on bounded data can schedule operations after another, depending on how the operators
consume data (e.g., first build hash table, then probe hash table).
We are separating the scheduling strategy from the ExecutionGraph to support different strategies
on bounded data (<a href="https://issues.apache.org/jira/browse/FLINK-10429">FLINK-10429</a>).</p>
  </li>
  <li>
    <p>Caching of intermediate results on bounded data, to support use cases like interactive data exploration.
The caching generally helps with applications where the client submits a series of jobs that build on
top of one another and reuse each others’ results.
<a href="https://issues.apache.org/jira/browse/FLINK-11199">FLINK-11199</a></p>
  </li>
  <li>
    <p>External Shuffle Services (mainly bounded streams) to support decoupling from computation and
intermediate results for better resource efficiency on systems like Yarn.
<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-31%3A+Pluggable+Shuffle+Manager">FLIP-31</a>.</p>
  </li>
</ul>

<p>Various of these enhancements can be taken from the contributed code from the
<a href="https://github.com/apache/flink/tree/blink">Blink fork</a>.</p>

<p>To exploit the above optimizations for bounded streams in the DataStream API, we need
break parts of the API and explicitly model bounded streams.</p>

<h1 id="stream-processing-use-cases">Stream Processing Use Cases</h1>

<p>Flink will get the new modes to stop a running application while ensuring that output and
side-effects are consistent and committed prior to shutdown. <em>SUSPEND</em> commit output/side-effects,
but keep state, while <em>TERMINATE</em> drains state and commits the outputs and side effects.
<a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=103090212">FLIP-34</a> has the details.</p>

<p>The <em>new source interface</em> effort (<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-27%3A+Refactor+Source+Interface">FLIP-27</a>)
aims to give simpler out-of-the box support for event time and watermark generation for sources.
Sources will have the option to align their consumption speed in event time, to reduce the
size of in-flight state when re-processing large data volumes in streaming
(<a href="https://issues.apache.org/jira/browse/FLINK-10886">FLINK-10887</a>).</p>

<p>To make evolution of streaming state simpler, we plan to add first class support for
<a href="https://developers.google.com/protocol-buffers/">Protocol Buffers</a>, similar to the way
Flink deeply supports Avro state evolution (<a href="https://issues.apache.org/jira/browse/FLINK-11333">FLINK-11333</a>).</p>

<h1 id="deployment-scaling-security">Deployment, Scaling, Security</h1>

<p>There is a big effort to design a new way for Flink to interact with dynamic resource
pools and automatically adjust to resource availability and load.
Part of this is  becoming a <em>reactive</em> way of adjusting to changing resources (like
containers/pods being started or removed) <a href="https://issues.apache.org/jira/browse/FLINK-10407">FLINK-10407</a>,
while other parts are resulting in <em>active</em> scaling policies where Flink decides to add
or remove TaskManagers, based on internal metrics.</p>

<p>To support the active resource management also in Kubernetes, we are adding a Kubernetes Resource Manager
<a href="https://issues.apache.org/jira/browse/FLINK-9953">FLINK-9953</a>.</p>

<p>The Flink Web UI is being ported to a newer framework and getting additional features for
better introspection of running jobs <a href="https://issues.apache.org/jira/browse/FLINK-10705">FLINK-10705</a>.</p>

<p>The community is working on extending the interoperability with authentication and authorization services.
Under discussion are general extensions to the <a href="http://apache-flink-mailing-list-archive.1008284.n3.nabble.com/DISCUSS-Flink-security-improvements-td21068.html">security module abstraction</a>
as well as specific <a href="http://apache-flink-mailing-list-archive.1008284.n3.nabble.com/DISCUSS-Flink-Kerberos-Improvement-td25983.html">enhancements to the Kerberos support</a>.</p>

<h1 id="ecosystem">Ecosystem</h1>

<p>The community is working on extending the support for catalogs, schema registries, and
metadata stores, including support in the APIs and the SQL client (<a href="https://issues.apache.org/jira/browse/FLINK-11275">FLINK-11275</a>).
We are adding DDL (Data Definition Language) support to make it easy to add tables and streams to
the catalogs (<a href="https://issues.apache.org/jira/browse/FLINK-10232">FLINK-10232</a>).</p>

<p>There is a broad effort to integrate Flink with the Hive Ecosystem, including
metastore and Hive UDF support <a href="https://issues.apache.org/jira/browse/FLINK-10556">FLINK-10556</a>.</p>

<h1 id="connectors--formats">Connectors &amp; Formats</h1>

<p>Support for additional connectors and formats is a continuous process.</p>

<h1 id="miscellaneous">Miscellaneous</h1>

<ul>
  <li>
    <p>We are changing the build setup to not bundle Hadoop by default, but rather offer pre-packaged Hadoop
libraries for the use with Yarn, HDFS, etc. as convenience downloads
<a href="https://issues.apache.org/jira/browse/FLINK-11266">FLINK-11266</a>.</p>
  </li>
  <li>
    <p>The Flink code base is being updates to support Java 9, 10, and 11
<a href="https://issues.apache.org/jira/browse/FLINK-8033">FLINK-8033</a>,
<a href="https://issues.apache.org/jira/browse/FLINK-10725">FLINK-10725</a>.</p>
  </li>
  <li>
    <p>To reduce compatibility issues with different Scala versions, we are working using Scala
only in the Scala APIs, but not in the runtime. That removes any Scala dependency for all
Java-only users, and makes it easier for Flink to support different Scala versions
<a href="https://issues.apache.org/jira/browse/FLINK-11063">FLINK-11063</a>.</p>
  </li>
</ul>



  </div>
</div>

      </div>
    </div>

    <hr />

    <div class="row">
      <div class="footer text-center col-sm-12">
        <p>Copyright © 2014-2019 <a href="http://apache.org">The Apache Software Foundation</a>. All Rights Reserved.</p>
        <p>Apache Flink, Flink®, Apache®, the squirrel logo, and the Apache feather logo are either registered trademarks or trademarks of The Apache Software Foundation.</p>
        <p><a href="/privacy-policy.html">Privacy Policy</a> &middot; <a href="/blog/feed.xml">RSS feed</a></p>
      </div>
    </div>
    </div><!-- /.container -->

    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.matchHeight/0.7.0/jquery.matchHeight-min.js"></script>
    <script src="/js/codetabs.js"></script>
    <script src="/js/stickysidebar.js"></script>

    <!-- Google Analytics -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-52545728-1', 'auto');
      ga('send', 'pageview');
    </script>
  </body>
</html>

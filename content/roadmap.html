<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Apache Flink: Apache Flink Roadmap</title>
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">

    <!-- Bootstrap -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">
    <link rel="stylesheet" href="/css/flink.css">
    <link rel="stylesheet" href="/css/syntax.css">

    <!-- Blog RSS feed -->
    <link href="/blog/feed.xml" rel="alternate" type="application/rss+xml" title="Apache Flink Blog: RSS feed" />

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <!-- We need to load Jquery in the header for custom google analytics event tracking-->
    <script src="/js/jquery.min.js"></script>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-8ML5TM8Q0M"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-8ML5TM8Q0M');
    </script>

  </head>
  <body>  
    

    <!-- Main content. -->
    <div class="container">
    <div class="row">

      
     <div id="sidebar" class="col-sm-3">
        

<!-- Top navbar. -->
    <nav class="navbar navbar-default">
        <!-- The logo. -->
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <div class="navbar-logo">
            <a href="/">
              <img alt="Apache Flink" src="/img/flink-header-logo.svg" width="147px" height="73px">
            </a>
          </div>
        </div><!-- /.navbar-header -->

        <!-- The navigation links. -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
          <ul class="nav navbar-nav navbar-main">

            <!-- First menu section explains visitors what Flink is -->

            <!-- What is Stream Processing? -->
            <!--
            <li><a href="/streamprocessing1.html">What is Stream Processing?</a></li>
            -->

            <!-- What is Flink? -->
            <li><a href="/flink-architecture.html">What is Apache Flink?</a></li>

            

            <!-- What is Stateful Functions? -->

            <li><a href="/stateful-functions.html">What is Stateful Functions?</a></li>

            <!-- Use cases -->
            <li><a href="/usecases.html">Use Cases</a></li>

            <!-- Powered by -->
            <li><a href="/poweredby.html">Powered By</a></li>


            &nbsp;
            <!-- Second menu section aims to support Flink users -->

            <!-- Downloads -->
            <li><a href="/downloads.html">Downloads</a></li>

            <!-- Getting Started -->
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#">Getting Started<span class="caret"></span></a>
              <ul class="dropdown-menu">
                <li><a href="https://nightlies.apache.org/flink/flink-docs-release-1.14//docs/try-flink/local_installation/" target="_blank">With Flink <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-statefun-docs-release-3.1/getting-started/project-setup.html" target="_blank">With Flink Stateful Functions <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="/training.html">Training Course</a></li>
              </ul>
            </li>

            <!-- Documentation -->
            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#">Documentation<span class="caret"></span></a>
              <ul class="dropdown-menu">
                <li><a href="https://nightlies.apache.org/flink/flink-docs-release-1.14" target="_blank">Flink 1.14 (Latest stable release) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-docs-master" target="_blank">Flink Master (Latest Snapshot) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-statefun-docs-release-3.1" target="_blank">Flink Stateful Functions 3.1 (Latest stable release) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
                <li><a href="https://nightlies.apache.org/flink/flink-statefun-docs-master" target="_blank">Flink Stateful Functions Master (Latest Snapshot) <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>
              </ul>
            </li>

            <!-- getting help -->
            <li><a href="/gettinghelp.html">Getting Help</a></li>

            <!-- Blog -->
            <li><a href="/blog/"><b>Flink Blog</b></a></li>


            <!-- Flink-packages -->
            <li>
              <a href="https://flink-packages.org" target="_blank">flink-packages.org <small><span class="glyphicon glyphicon-new-window"></span></small></a>
            </li>
            &nbsp;

            <!-- Third menu section aim to support community and contributors -->

            <!-- Community -->
            <li><a href="/community.html">Community &amp; Project Info</a></li>

            <!-- Roadmap -->
            <li class="active"><a href="/roadmap.html">Roadmap</a></li>

            <!-- Contribute -->
            <li><a href="/contributing/how-to-contribute.html">How to Contribute</a></li>
            

            <!-- GitHub -->
            <li>
              <a href="https://github.com/apache/flink" target="_blank">Flink on GitHub <small><span class="glyphicon glyphicon-new-window"></span></small></a>
            </li>

            &nbsp;

            <!-- Language Switcher -->
            <li>
              
                
                  <a href="/zh/roadmap.html">中文版</a>
                
              
            </li>

          </ul>

          <style>
            .smalllinks:link {
              display: inline-block !important; background: none; padding-top: 0px; padding-bottom: 0px; padding-right: 0px; min-width: 75px;
            }
          </style>

          <ul class="nav navbar-nav navbar-bottom">
          <hr />

            <!-- Twitter -->
            <li><a href="https://twitter.com/apacheflink" target="_blank">@ApacheFlink <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

            <!-- Visualizer -->
            <li class=" hidden-md hidden-sm"><a href="/visualizer/" target="_blank">Plan Visualizer <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

            <li >
                  <a href="/security.html">Flink Security</a>
            </li>

          <hr />

            <li><a href="https://apache.org" target="_blank">Apache Software Foundation <small><span class="glyphicon glyphicon-new-window"></span></small></a></li>

            <li>

              <a class="smalllinks" href="https://www.apache.org/licenses/" target="_blank">License</a> <small><span class="glyphicon glyphicon-new-window"></span></small>

              <a class="smalllinks" href="https://www.apache.org/security/" target="_blank">Security</a> <small><span class="glyphicon glyphicon-new-window"></span></small>

              <a class="smalllinks" href="https://www.apache.org/foundation/sponsorship.html" target="_blank">Donate</a> <small><span class="glyphicon glyphicon-new-window"></span></small>

              <a class="smalllinks" href="https://www.apache.org/foundation/thanks.html" target="_blank">Thanks</a> <small><span class="glyphicon glyphicon-new-window"></span></small>
            </li>

          </ul>
        </div><!-- /.navbar-collapse -->
    </nav>

      </div>
      <div class="col-sm-9">
      <div class="row-fluid">
  <div class="col-sm-12">
    <h1>Apache Flink Roadmap</h1>

	<!--
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
-->

<hr />

<div class="page-toc">
<ul id="markdown-toc">
  <li><a href="#feature-radar" id="markdown-toc-feature-radar">Feature Radar</a>    <ul>
      <li><a href="#feature-stages" id="markdown-toc-feature-stages">Feature Stages</a></li>
    </ul>
  </li>
  <li><a href="#unified-analytics-where-batch-and-streaming-come-together-sql-and-beyond" id="markdown-toc-unified-analytics-where-batch-and-streaming-come-together-sql-and-beyond">Unified Analytics: Where Batch and Streaming come Together; SQL and beyond.</a>    <ul>
      <li><a href="#a-unified-sql-platform" id="markdown-toc-a-unified-sql-platform">A unified SQL Platform</a></li>
      <li><a href="#deep-batch--streaming-unification-for-the-datastream-api" id="markdown-toc-deep-batch--streaming-unification-for-the-datastream-api">Deep Batch / Streaming Unification for the DataStream API</a></li>
      <li><a href="#subsuming-dataset-with-datastream-and-table-api" id="markdown-toc-subsuming-dataset-with-datastream-and-table-api">Subsuming DataSet with DataStream and Table API</a></li>
    </ul>
  </li>
  <li><a href="#applications-vs-clusters-flink-as-a-library" id="markdown-toc-applications-vs-clusters-flink-as-a-library">Applications vs. Clusters; “Flink as a Library”</a></li>
  <li><a href="#performance" id="markdown-toc-performance">Performance</a>    <ul>
      <li><a href="#faster-checkpoints-and-recovery" id="markdown-toc-faster-checkpoints-and-recovery">Faster Checkpoints and Recovery</a></li>
      <li><a href="#large-scale-batch-applications" id="markdown-toc-large-scale-batch-applications">Large Scale Batch Applications</a></li>
    </ul>
  </li>
  <li><a href="#python-apis" id="markdown-toc-python-apis">Python APIs</a></li>
  <li><a href="#documentation" id="markdown-toc-documentation">Documentation</a></li>
  <li><a href="#miscellaneous-operational-tools" id="markdown-toc-miscellaneous-operational-tools">Miscellaneous Operational Tools</a></li>
  <li><a href="#stateful-functions" id="markdown-toc-stateful-functions">Stateful Functions</a></li>
</ul>

</div>

<p><strong>Preamble:</strong> This roadmap means to provide user and contributors with a high-level summary of ongoing efforts,
grouped by the major threads to which the efforts belong. With so much that is happening in Flink, we
hope that this helps with understanding the direction of the project.
The roadmap contains both efforts in early stages as well as nearly completed
efforts, so that users may get a better impression of the overall status and direction of those developments.</p>

<p>More details and various smaller changes can be found in the
<a href="https://cwiki.apache.org/confluence/display/FLINK/Flink+Improvement+Proposals">FLIPs</a></p>

<p>The roadmap is continuously updated. New features and efforts should be added to the roadmap once
there is consensus that they will happen and what they will roughly look like for the user.</p>

<p><strong>Last Update:</strong> 2021-09-16</p>

<hr />

<h1 id="feature-radar">Feature Radar</h1>

<p>The feature radar is meant to give users guidance regarding feature maturity, as well as which features
are approaching end-of-life. For questions, please contact the developer mailing list:
<a href="&#109;&#097;&#105;&#108;&#116;&#111;:&#100;&#101;&#118;&#064;&#102;&#108;&#105;&#110;&#107;&#046;&#097;&#112;&#097;&#099;&#104;&#101;&#046;&#111;&#114;&#103;">&#100;&#101;&#118;&#064;&#102;&#108;&#105;&#110;&#107;&#046;&#097;&#112;&#097;&#099;&#104;&#101;&#046;&#111;&#114;&#103;</a></p>

<div class="row front-graphic">
  <img src="/img/flink_feature_radar_2.svg" width="700px" />
</div>

<h2 id="feature-stages">Feature Stages</h2>

<ul>
  <li><strong>MVP:</strong> Have a look, consider whether this can help you in the future.</li>
  <li><strong>Beta:</strong> You can benefit from this, but you should carefully evaluate the feature.</li>
  <li><strong>Ready and Evolving:</strong> Ready to use in production, but be aware you may need to make some adjustments to your application and setup in the future, when you upgrade Flink.</li>
  <li><strong>Stable:</strong> Unrestricted use in production</li>
  <li><strong>Reaching End-of-Life:</strong> Stable, still feel free to use, but think about alternatives. Not a good match for new long-lived projects.</li>
  <li><strong>Deprecated:</strong> Start looking for alternatives now</li>
</ul>

<hr />

<h1 id="unified-analytics-where-batch-and-streaming-come-together-sql-and-beyond">Unified Analytics: Where Batch and Streaming come Together; SQL and beyond.</h1>

<p>Flink is a streaming data system in its core, that executes “batch as a special case of streaming”.
Efficient execution of batch jobs is powerful in its own right; but even more so, batch processing
capabilities (efficient processing of bounded streams) open the way for a seamless unification of
batch and streaming applications.</p>

<p>Unified streaming/batch up-levels the streaming data paradigm: It gives users consistent semantics across
their real-time and lag-time applications. Furthermore, streaming applications often need to be complemented
by batch (bounded stream) processing, for example when reprocessing data after bugs or data quality issues,
or when bootstrapping new applications. A unified API and system make this much easier.</p>

<h2 id="a-unified-sql-platform">A unified SQL Platform</h2>

<p>The community has been building Flink to a powerful basis for a unified (batch and streaming) SQL analytics
platform, and is continuing to do so.</p>

<p>SQL has very strong cross-batch-streaming semantics, allowing users to use the same queries for ad-hoc analytics
and as continuous queries. Flink already contains an efficient unified query engine, and a wide set of
integrations. With user feedback, those are continuously improved.</p>

<p><strong>More Connector and Change Data Capture Support</strong></p>

<ul>
  <li>Change-Data-Capture: Capturing a stream of data changes, directly from databases, by attaching to the
transaction log. The community is adding more CDC intrgrations.
    <ul>
      <li>External CDC connectors: <a href="https://flink-packages.org/packages/cdc-connectors">https://flink-packages.org/packages/cdc-connectors</a></li>
      <li>Background: <a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=147427289">FLIP-105</a>
(CDC support for SQL) and <a href="https://debezium.io/">Debezium</a>.</li>
    </ul>
  </li>
  <li>Data Lake Connectors: Unified streaming &amp; batch is a powerful value proposition for Data Lakes: supporting
same APIs, semantics, and engine for streaming real-time processing and batch processing of historic data.
The community is adding deeper integrations with various Data Lake systems:
    <ul>
      <li><a href="https://iceberg.apache.org/">Apache Iceberg</a>: <a href="https://iceberg.apache.org/flink/">https://iceberg.apache.org/flink/</a></li>
      <li><a href="https://hudi.apache.org/">Apache Hudi</a>: <a href="https://hudi.apache.org/blog/apache-hudi-meets-apache-flink/">https://hudi.apache.org/blog/apache-hudi-meets-apache-flink/</a></li>
      <li><a href="https://pinot.apache.org/">Apache Pinot</a>: <a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=177045634">FLIP-166</a></li>
    </ul>
  </li>
</ul>

<p><strong>Platform Infrastructure</strong></p>

<ul>
  <li>To simplify the building of production SQL platforms with Flink, we are improving the SQL client and are
working on SQL gateway components that interface between client and cluster: <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-163%3A+SQL+Client+Improvements">FLIP-163</a></li>
</ul>

<p><strong>Support for Common Languages, Formats, Catalogs</strong></p>

<ul>
  <li>Hive Query Compatibility: <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-152%3A+Hive+Query+Syntax+Compatibility">FLIP-152</a></li>
</ul>

<p>Flink has a broad SQL coverage for batch (full TPC-DS support) and a state-of-the-art set of supported
operations in streaming. There is continuous effort to add more functions and cover more SQL operations.</p>

<h2 id="deep-batch--streaming-unification-for-the-datastream-api">Deep Batch / Streaming Unification for the DataStream API</h2>

<p>The <em>DataStream API</em> is Flink’s <em>physical</em> API, for use cases where users need very explicit control over data
types, streams, state, and time. This API is evolving to support efficient batch execution on bounded data.</p>

<p>DataStream API executes the same dataflow shape in batch as in streaming, keeping the same operators.
That way users keep the same level of control over the dataflow, and our goal is to mix and switch between
batch/streaming execution in the future to make it a seamless experience.</p>

<p><strong>Unified Sources and Sinks</strong></p>

<ul>
  <li>
    <p>The first APIs and implementations of sources were specific to either streaming programs in the DataStream API
(<a href="https://github.com/apache/flink/blob/master/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/source/SourceFunction.java">SourceFunction</a>),
or to batch programs in the DataSet API (<a href="https://github.com/apache/flink/blob/master/flink-core/src/main/java/org/apache/flink/api/common/io/InputFormat.java">InputFormat</a>).</p>

    <p>In this effort, we are creating sources that work across batch and streaming execution. The aim is to give
users a consistent experience across both modes, and to allow them to easily switch between streaming and batch
execution for their unbounded and bounded streaming applications.
The interface for this New Source API is done and available, and we are working on migrating more source connectors
to this new model, see <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-27%3A+Refactor+Source+Interface">FLIP-27</a>.</p>
  </li>
  <li>
    <p>Similar to the sources, the original sink APIs are also specific to streaming
(<a href="https://github.com/apache/flink/blob/master/flink-streaming-java/src/main/java/org/apache/flink/streaming/api/functions/sink/SinkFunction.java">SinkFunction</a>)
and batch (<a href="https://github.com/apache/flink/blob/master/flink-core/src/main/java/org/apache/flink/api/common/io/OutputFormat.java">OutputFormat</a>)
APIs and execution.</p>

    <p>We have introduced a new API for sinks that consistently handles result writing and committing (<em>Transactions</em>)
across batch and streaming. The first iteration of the API exists, and we are porting sinks and refining the
API in the process. See <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-143%3A+Unified+Sink+API">FLIP-143</a>.</p>
  </li>
</ul>

<p><strong>DataStream Batch Execution</strong></p>

<ul>
  <li>
    <p>Flink is adding a <em>batch execution mode</em> for bounded DataStream programs. This gives users faster and simpler
execution and recovery of their bounded streaming applications; users do not need to worry about watermarks and
state sizes in this execution mode: <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-140%3A+Introduce+batch-style+execution+for+bounded+keyed+streams">FLIP-140</a></p>

    <p>The core batch execution mode is implemented with <a href="https://flink.apache.org/news/2020/12/10/release-1.12.0.html#batch-execution-mode-in-the-datastream-api">great results</a>;
there are ongoing improvements around aspects like broadcast state and processing-time-timers.
This mode requires the new unified sources and sinks that are mentioned above, so it is limited
to the connectors that have been ported to those new APIs.</p>
  </li>
</ul>

<p><strong>Mixing bounded/unbounded streams, and batch/streaming execution</strong></p>

<ul>
  <li>
    <p>Support checkpointing when some tasks finished &amp; Bounded stream programs shut down with a final
checkpoint: <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-147%3A+Support+Checkpoints+After+Tasks+Finished">FLIP-147</a></p>
  </li>
  <li>
    <p>There are initial discussions and designs about jobs with mixed batch/streaming execution, so stay tuned for more
news in that area.</p>
  </li>
</ul>

<h2 id="subsuming-dataset-with-datastream-and-table-api">Subsuming DataSet with DataStream and Table API</h2>

<p>We want to eventually drop the legacy Batch-only DataSet API, have batch-and stream processing unified
throughout the entire system.</p>

<p>Overall Discussion: <a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=158866741">FLIP-131</a></p>

<p>The <em>DataStream API</em> supports batch-execution to efficiently execute streaming programs on historic data
(see above). Takes over that set of use cases.</p>

<p>The <em>Table API</em> should become the default API for batch-only applications.</p>

<ul>
  <li>Add more operations to Table API, so support common data manipulation tasks more
   easily: <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-155%3A+Introduce+a+few+convenient+operations+in+Table+API">FLIP-155</a></li>
  <li>Make Source and Sink definitions easier in the Table API.</li>
</ul>

<p>Improve the <em>interplay between the Table API and the DataStream API</em> to allow switching from Table API to
DataStream API when more control over the data types and operations is necessary.</p>

<ul>
  <li>Interoperability between DataStream and Table APIs: <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-136%3A++Improve+interoperability+between+DataStream+and+Table+API">FLIP-136</a></li>
</ul>

<hr />

<h1 id="applications-vs-clusters-flink-as-a-library">Applications vs. Clusters; “Flink as a Library”</h1>

<p>The goal of these efforts is to make it feel natural to deploy (long running streaming) Flink applications.
Instead of starting a cluster and submitting a job to that cluster, these efforts support deploying a streaming
job as a self contained application.</p>

<p>For example as a simple Kubernetes deployment; deployed and scaled like a regular application without extra workflows.</p>

<p>Deploy Flink jobs as self-contained Applications works for all deployment targets since Flink 1.11.0
(<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-85+Flink+Application+Mode">FLIP-85</a>).</p>

<ul>
  <li>
    <p>Reactive Scaling lets Flink applications change their parallelism in response to growing and shrinking
worker pools, and makes Flink compatibel with standard auto-scalers:
<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-159%3A+Reactive+Mode">FLIP-159</a></p>
  </li>
  <li>
    <p>Kubernetes-based HA-services let Flink applications run on Kubernetes without requiring a ZooKeeper dependency:
<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-144%3A+Native+Kubernetes+HA+for+Flink">FLIP-144</a></p>
  </li>
</ul>

<hr />

<h1 id="performance">Performance</h1>

<p>Continuous work to keep improving performance and recovery speed.</p>

<h2 id="faster-checkpoints-and-recovery">Faster Checkpoints and Recovery</h2>

<p>The community is continuously working on improving checkpointing and recovery speed.
Checkpoints and recovery are stable and have been a reliable workhorse for years. We are still
trying to make it faster, more predictable, and to remove some confusions and inflexibility in some areas.</p>

<ul>
  <li>Unaligned Checkpoints, to make checkpoints progress faster when applications cause backpressure:
<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-76%3A+Unaligned+Checkpoints">FLIP-76</a>, available
since Flink 1.12.2.</li>
  <li>Log-based Checkpoints, for very frequent incremental checkpointing:
<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-158%3A+Generalized+incremental+checkpoints">FLIP-158</a></li>
</ul>

<h2 id="large-scale-batch-applications">Large Scale Batch Applications</h2>

<p>The community is working on making large scale batch execution (parallelism in the order of 10,000s)
simpler (less configuration tuning required) and more performant.</p>

<ul>
  <li>
    <p>Introduce a more scalable batch shuffle. First parts of this have been merged, and ongoing efforts are
to make the memory footprint (JVM direct memory) more predictable, see
<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-148%3A+Introduce+Sort-Merge+Based+Blocking+Shuffle+to+Flink">FLIP-148</a></p>

    <ul>
      <li><a href="https://issues.apache.org/jira/browse/FLINK-20740">FLINK-20740</a></li>
      <li><a href="https://issues.apache.org/jira/browse/FLINK-19938">FLINK-19938</a></li>
    </ul>
  </li>
  <li>
    <p>Make scheduler faster for higher parallelism: <a href="https://issues.apache.org/jira/browse/FLINK-21110">FLINK-21110</a></p>
  </li>
</ul>

<hr />

<h1 id="python-apis">Python APIs</h1>

<p>Most functionalities in the Java Table APIs and DataStream APIs are already supported by the Python APIs. 
The community is continuously working on improvements such as improving the checkpoint strategy for Python UDF execution
(<a href="https://issues.apache.org/jira/browse/FLINK-18235">FLINK-18235</a>), introducing more connectors support in both the Python DataStream API 
and Python Table API so that the Python API can be used in for production implementations.</p>

<p>Stateful transformation functions for the Python DataStream API:
<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-153%3A+Support+state+access+in+Python+DataStream+API">FLIP-153</a></p>

<hr />

<h1 id="documentation">Documentation</h1>

<p>There are various dedicated efforts to simplify the maintenance and structure (more intuitive navigation/reading)
of the documentation.</p>

<ul>
  <li>Docs Tech Stack: <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-157+Migrate+Flink+Documentation+from+Jekyll+to+Hugo">FLIP-157</a></li>
  <li>General Docs Structure: <a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-42%3A+Rework+Flink+Documentation">FLIP-42</a></li>
  <li>SQL Docs: <a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=127405685">FLIP-60</a></li>
</ul>

<hr />

<h1 id="miscellaneous-operational-tools">Miscellaneous Operational Tools</h1>

<ul>
  <li>Allow switching state backends with savepoints: <a href="https://issues.apache.org/jira/browse/FLINK-20976">FLINK-20976</a></li>
  <li>Support for Savepoints with more properties, like incremental savepoints, etc.:
<a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-47%3A+Checkpoints+vs.+Savepoints">FLIP-47</a></li>
</ul>

<hr />

<h1 id="stateful-functions">Stateful Functions</h1>

<p>The Stateful Functions subproject has its own roadmap published under <a href="https://statefun.io/">statefun.io</a>.</p>


  </div>
</div>

      </div>
    </div>

    <hr />

    <div class="row">
      <div class="footer text-center col-sm-12">
        <p>Copyright © 2014-2021 <a href="http://apache.org">The Apache Software Foundation</a>. All Rights Reserved.</p>
        <p>Apache Flink, Flink®, Apache®, the squirrel logo, and the Apache feather logo are either registered trademarks or trademarks of The Apache Software Foundation.</p>
        <p><a href="/privacy-policy.html">Privacy Policy</a> &middot; <a href="/blog/feed.xml">RSS feed</a></p>
      </div>
    </div>
    </div><!-- /.container -->

    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="/js/jquery.matchHeight-min.js"></script>
    <script src="/js/bootstrap.min.js"></script>
    <script src="/js/codetabs.js"></script>
    <script src="/js/stickysidebar.js"></script>

    <!-- Google Analytics -->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-52545728-1', 'auto');
      ga('send', 'pageview');
    </script>
  </body>
</html>
